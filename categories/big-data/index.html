<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="generator" content="Hexo 4.2.1"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Category: Big Data - Always Learning</title><meta property="og:type" content="blog"><meta property="og:title" content="Always Learning"><meta property="og:url" content="https://kojunhee.github.io/"><meta property="og:site_name" content="Always Learning"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://kojunhee.github.io/img/og_image.png"><meta property="article:author" content="junhee.ko"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://kojunhee.github.io"},"headline":"Always Learning","image":["https://kojunhee.github.io/img/og_image.png"],"author":{"@type":"Person","name":"junhee.ko"},"description":null}</script><link rel="icon" href="/img/favicon.ico"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/default.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><script data-ad-client="ca-pub-6880109808178384" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js" async></script></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="Always Learning" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a></div><div class="navbar-end"><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/categories">Categories</a></li><li class="is-active"><a href="#" aria-current="page">Big Data</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-04-06T15:00:00.000Z" title="2020-04-06T15:00:00.000Z">2020-04-07</time><span class="level-item"><a class="link-muted" href="/categories/big-data/">Big Data</a></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/04/07/bigdata-chapter-06/">[빅데이터] 6장_일괄처리 계층</a></h1><div class="content"><p>데이터 시스템의 목적은, 데이터에 관한 임의의 질문에 응답하는 것이다. 데이터 집합 전체를 입력으로 받는 함수는 실행 시간이 매우 오래 걸리므로, 질의의 빠르게 응답할 수 있는 다른 전략이 필요하다. </p>
<p>람다 아키텍쳐에서 일괄처리 계층은, 마스터 데이터 집합으로부터 일괄처리 뷰를 사전 계산해서 질의가 빠르게 처리될 수 있도록 한다. </p>
<h4 id="6-1-일괄-처리-구실로-좋은-예제"><a href="#6-1-일괄-처리-구실로-좋은-예제" class="headerlink" title="6.1 일괄 처리 구실로 좋은 예제"></a>6.1 일괄 처리 구실로 좋은 예제</h4><p>각 예제는 마스터 데이터 집합 전체를 입력 받는 함수로, 질의를 어떻게 실행하는지 보여준다. 이 예제는 질의 요청이 들어올 때 즉석으로 실행하는 대신, 사전 계산을 사용하도록 구현이 변경될 것이다.</p>
<h5 id="6-1-1-시간대별-페이지뷰"><a href="#6-1-1-시간대별-페이지뷰" class="headerlink" title="6.1.1 시간대별 페이지뷰"></a>6.1.1 시간대별 페이지뷰</h5><p>지정한 시간대에서 발생한 특정 URL 에 대한 페이지뷰 수의 총계를 구하는 것.</p>
<h5 id="6-1-2-성별-추로"><a href="#6-1-2-성별-추로" class="headerlink" title="6.1.2 성별 추로"></a>6.1.2 성별 추로</h5><p>이름 데이터 집합 레코드를 사용해서 개인의 성별 추론.</p>
<h5 id="6-1-3-영향력-지수"><a href="#6-1-3-영향력-지수" class="headerlink" title="6.1.3 영향력 지수"></a>6.1.3 영향력 지수</h5><p>소셜 네트워크에서 개인의 영향력 지수를 구함.</p>
<h4 id="6-2-일괄-처리-계층에서-계산을-수행하기"><a href="#6-2-일괄-처리-계층에서-계산을-수행하기" class="headerlink" title="6.2 일괄 처리 계층에서 계산을 수행하기"></a>6.2 일괄 처리 계층에서 계산을 수행하기</h4><p><img src="/image/bigdata_batch_layer.png" alt=""></p>
<ol>
<li>일괄 처리 계층은, 마스터 데이터 집합에 대한 함수를 실행해서 일괄 처리 뷰라고 불리는 중간 결과를 사전 계산한다. </li>
<li>일괄 처리 뷰는 서빙 계층에 로딩되고, 서빙 계층은 데이터에 빨리 접근할 수 있도록 이것에 대한 색인을 만들어둔다. </li>
<li>속도 계층은 일괄 처리 계층의 지연시간이 높은 것을 보완한다. 아직 일괄처리 뷰료 사전 계산 되지 않은 데이터에 대해 지연 시간이 낮은 갱신을 실행하는 것이다. </li>
<li>질의는 서빙 계층 뷰와 속도 계층 뷰의 처리 결과를 합쳐서 완료된다.</li>
</ol>
<p>람다 아키텍쳐의 핵심은, 어떤 질의의 대해서도 일괄 처리 계층에서 데이터를 사전계산하여 서빙 계층에서 신속하게 처리할 수 있도록 할 수 있다는 것이다.</p>
<p>모든 질의를 사전계산할 수는 없다. 그 대신, 다음 그림처럼 중간 결과를 사전 계산하고 그 결과들을 사용해서 질의를 즉석으로 처리할 수 있다. </p>
<p><img src="/image/bigdata_batch_layer_pre_cal.png" alt=""></p>
<p>시간대별 페이지뷰 질의 예제에 대해 중관 결과를 사전 계산한다면, URL 개개마다 모든 시각에 대한 페이지뷰를 사전계산 해두는 것이다. 질의 처리를 완료하려면 색인에서 지정한 범위에 속하는 모든 시각에 대한 페이지뷰 수를 얻어서 그 결과를 합치면 된다. </p>
<p><img src="/image/bigdata_batch_layer_pre_cal_ex.png" alt=""></p>
<hr>
<p>빅데이터, 람다 아키텍처로 알아보는 실시간 빅데이터 구축의 핵심 원리와 기법 &lt;네이선 마츠, 제임스 워렌&gt;</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-03-30T15:00:00.000Z" title="2020-03-30T15:00:00.000Z">2020-03-31</time><span class="level-item"><a class="link-muted" href="/categories/big-data/">Big Data</a></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/03/31/bigdata-chapter-05/">[빅데이터] 5장_일괄처리 계층의 데이터 저장소 : 사례</a></h1><div class="content"><p>HDFS  를 사용하는 방법과, 상위 수준 API 를 사용하여 필요한 작업을 자동화하는 방법을 정리한다. 항상 그랬듯이, 도구를 비교하는 것이 아니라 상위 수준의 개념을 보강하는 것이 목적이다.</p>
<h4 id="5-1-하둡-분산-파일-시스템-사용하기"><a href="#5-1-하둡-분산-파일-시스템-사용하기" class="headerlink" title="5.1 하둡 분산 파일 시스템 사용하기"></a>5.1 하둡 분산 파일 시스템 사용하기</h4><p>HDFS 의 동작 방식을 정리하면,</p>
<ol>
<li>파일은 블록으로 쪼개져서 클러스터에  있는 여러 노드로 퍼뜨려진다.</li>
<li>블록은 여러 노드로 복제되어서 장비가 다운되어도 데이터는 여전히 사용 가능하다.</li>
<li>네임노드는 각 파일이 어떤 블록으로 구성되는지와, 그 블록이 어디에 저장되어 있는지를 추적한다.</li>
</ol>
<p>파일과 폴더를 조작하는 HDFS API 사용법을 보자. 서버에 로그인한 정보를 모두 저장한다고 하자.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ cat logins-2020-03-31.txt</span><br><span class="line">jko	192.168.12.125 Thu Mar 31 22:33 - 22:46</span><br><span class="line">jh	192.168.12.125 Thu Mar 31 21:15 - 22:42</span><br><span class="line">ko	192.168.12.125 Thu Mar 31 23:31 - 22:13</span><br><span class="line">jko	192.168.12.125 Thu Mar 31 22:33 - 22:43</span><br></pre></td></tr></table></figure>

<p>이 데이터를 HDFS 에 저장하려면 데이터 집합 저장용 디렉토리를 우선 만들고 올리면 된다. 파일을 올리면 자동으로 블록으로 쪼개져서 여러 데이터 노드 사이에 분산된다.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ haddop fs -mkdir &#x2F;logins</span><br><span class="line">$ haddop fs -put logins-2020-03-31.txt &#x2F;logins</span><br></pre></td></tr></table></figure>

<h5 id="5-1-1-작은-파일-문제"><a href="#5-1-1-작은-파일-문제" class="headerlink" title="5.1.1 작은 파일 문제"></a>5.1.1 작은 파일 문제</h5><p>하둡은 데이터가 HDFS 상의 여러 작은 파일에 저장되어있을 때는, 계산 성능이 떨어지는 특성이 있다. </p>
<p>그 원인은, 맵리듀스 작업이 입력 데이터 집합의 각 블록마다 테스크를 하나씩 실행하기 때문이다. 각 테스크는 실행을 계획하고 조정하는 오버헤드를 소모하는데, 각각의 작은 파일은 독립적인 테스크에서 실행되어야하므로, 그 비용은 반복적으로 발생한다.</p>
<h5 id="5-1-2-상위-수준-추상화를-향하여"><a href="#5-1-2-상위-수준-추상화를-향하여" class="headerlink" title="5.1.2 상위 수준 추상화를 향하여"></a>5.1.2 상위 수준 추상화를 향하여</h5><p>솔루션이란, </p>
<ol>
<li>확장성 있고</li>
<li>내결함성을 지니며</li>
<li>성능이 좋아야하며</li>
<li>우아해야한다. ( = 관심 있는 계산을 간결하게 표현할 수 있는 부분이 있어야한다. )</li>
</ol>
<p>지난 장에서, 마스터 데이터 집합을 조작할 때, 다음 두 중요한 연산을 살펴봤다.</p>
<ol>
<li>새로운 데이터를 데이터 집합에 추가하기</li>
<li>데이터 집합에 수직 분할을 적용하고 기존의 분할이 깨지는 것을 방지하기</li>
</ol>
<p>이제 여기에, HDFS 의 요구사항을 추가하자. <strong>작은 파일을 효율적으로 큰 파일로 통합할 수 있어야 한다</strong>는 것이다.</p>
<p>앞 장에서 봤듯이, 파일과 폴더를 직접 다루어서 작업을 하기에는 불편하고 오류가 발생하기 쉽다. 우아한 방식의 Pail 이란 라이브러리 살펴보자. Pail 을 사용하면, 코드 한 줄로 폴더를 추가하거나 작은 파일들을 통합 할 수 있다.</p>
<blockquote>
<p>[잠깐 뒤돌아 보기] 큰 관점으로 살펴보자. </p>
<p>마스터 데이터 집합은 람다 아키텍쳐에서 모든 정보의 원천이다. </p>
<p>일괄 처리 계층은 거대하고 꾸준히 증가하는 데이터 집합을 문제없이 처리해야한다.</p>
<p>실제 질의에 응답하기 위해서, 데이터를 일괄 처리 뷰로 변환하는 쉽고 효율적인 수단이 있어야한다.</p>
</blockquote>
<h4 id="5-2-페일을-사용하여-일괄처리-계층에-데이터를-저장하기"><a href="#5-2-페일을-사용하여-일괄처리-계층에-데이터를-저장하기" class="headerlink" title="5.2 페일을 사용하여 일괄처리 계층에 데이터를 저장하기"></a>5.2 페일을 사용하여 일괄처리 계층에 데이터를 저장하기</h4><p>페일은 dfs-datasource 라이브러리에 포함된 것으로, 파일과 폴더를 얇게 추상화한것이다. 이 추상화를 통해 일괄처리에 사용할 레코드 집합을 관리하기가 쉬워진다. 페일의 목적은, 우리가 신경써야 할 연산 ( 데이터 집합에 새로운 데이터 추가하기, 수직 분할, 파일 통합 ) 을 안전하고 쉽고 성능 기준에 맞게 수행할 수 있도록 해준다.</p>
<p>내부적으로 페일은, 표준 하둡 API 를 사용하는 자바 라이브러리일 뿐이다. 하위 수준 파일 시스템 상호 작용을 처리하며 하둡 내부 구조의 복잡성을 감추는 API 를 제공한다.</p>
<p>페일을 살펴볼 때는, 어떻게 HDFS 의 장점을 보존하면서 데이터에 대한 연산을 간소화하는지를 기억해두어야한다.</p>
<hr>
<p>빅데이터, 람다 아키텍처로 알아보는 실시간 빅데이터 구축의 핵심 원리와 기법 &lt;네이선 마츠, 제임스 워렌&gt;</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-03-14T15:00:00.000Z" title="2020-03-14T15:00:00.000Z">2020-03-15</time><span class="level-item"><a class="link-muted" href="/categories/big-data/">Big Data</a></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/03/15/bigdata-chapter-04/">[빅데이터] 4장_일괄 처리 계층의 데이터 저장소</a></h1><div class="content"><p>마스터 데이터 집합은하나의 서버에 저장하기에는 너무 크다. 데이터를 여러 장비에 어떻게 분산시킬 것인지기 중요하다.</p>
<p>이번 장은 다음을 정리한다.</p>
<ol>
<li>마스터 데이터 집합을 저장하는데 필요한 요구사항</li>
<li>분산 파일 시스템이 왜 데이터 집합을 저장하는데 적합한지</li>
</ol>
<h4 id="4-1-마스터-데이터-집합-저장소의-요구사항"><a href="#4-1-마스터-데이터-집합-저장소의-요구사항" class="headerlink" title="4.1 마스터 데이터 집합 저장소의 요구사항"></a>4.1 마스터 데이터 집합 저장소의 요구사항</h4><p>“데이터를 한 번만 쓰고, 읽기는 큰 단위로 여러 번 수행된다” 방식에 초점을 두면, 다음과 같이 요구사항을 정리할 수 있다.</p>
<ul>
<li><p>쓰기</p>
<ul>
<li>데이터 추가의 효율성 : 유일한 쓰기 연산은 새로운 데이터를 추가하는 것뿐이다.</li>
<li>확장성 있는 저장소 : 데이터 집합이 커질 때 확장하기 쉬워야한다.</li>
</ul>
</li>
<li><p>읽기</p>
<ul>
<li>병렬 처리 지원 : 거대한 양의 데이터를 확장성 있는 방식으로 다룰 수 있도록 병렬 처리를 지원해야한다.</li>
</ul>
</li>
<li><p>둘 다</p>
<ul>
<li>저장 비용과 처리 비용 조율 : 필요에 따라 데이터를 저장학고 압축하는 방식을 선택하는 유연성이 있어야한다.</li>
<li>불변성 강제</li>
</ul>
</li>
</ul>
<h4 id="4-2-일괄-처리-계층을-위한-저장소-솔루션-선택"><a href="#4-2-일괄-처리-계층을-위한-저장소-솔루션-선택" class="headerlink" title="4.2 일괄 처리 계층을 위한 저장소 솔루션 선택"></a>4.2 일괄 처리 계층을 위한 저장소 솔루션 선택</h4><h5 id="4-2-1-키-값-저장소"><a href="#4-2-1-키-값-저장소" class="headerlink" title="4.2.1 키/값 저장소"></a>4.2.1 키/값 저장소</h5><p>여러 장비에 분산되는 거대하고 영속적인 hash map</p>
<ol>
<li><p>값은 저장할 데이터이다. 키는 무엇일까 ? 우리가 사용하는 데이터 모델에는 데이터 자체가 대량 소비를 전제로 한다. 그래서 원래 키가 없고, 필요하지도 않다. 즉, 처음 부터 데이터 모델과 키/값 저장소의 동작 방식이 맞지 않는 것이다. 유일하게 쓸만한 방법이라면, UUID 를 생성해서 키로 사용하는 것이다.</p>
</li>
<li><p>키/값 저장소는 무작위 읽기와 쓰기를 지원하기 위해 키/값 쌍에 세밀하게 접근해야한다. 그래서, 여러 개의 키/값 쌍을 묶어서 압축하는 것도 불가능하다. </p>
</li>
<li><p>키/값 저장소는 변경 가능한 저장소에 사용하도록 만들어져서, 마스터 데이터 집합에 불변성을 강제하는 게 극히 필요한 경우라면 문제가 된다. </p>
</li>
<li><p>키/값 저장소에는 불필요한 기능이 많다. 무작위 읽기, 쓰기 그리고 이들을 가능하게 하는 모든 장치들이 이에 해당된다.</p>
</li>
<li><p>데이터 색인을 하며 우리에게는 필요 없는 서비스도 제공해서 저장소 비용이 증가하고 데이터를 읽고 쓰는 성능이 저하될 수 있다.</p>
</li>
</ol>
<h5 id="4-2-2-분산-파일-시스템"><a href="#4-2-2-분산-파일-시스템" class="headerlink" title="4.2.2 분산 파일 시스템"></a>4.2.2 분산 파일 시스템</h5><p>파일은 디스크에 순차적으로 저장된다. 파일에 들어있는 바이트는 완전히 제어할 수 있고 압축도 가능하다. 파일 시스템은 딱 필요한 기능만 제공하고 세밀한 권한 시스템으로 구현되어 있어서 불변성을 강제할 수 있다.</p>
<p>보통의 파일시스템의 문제는, 오직 하나의 장비에만 존재한다는 것이다. 그래서, 확장하려고 해도 단일 장비가 제공하는 저장소 크기와 처리 용량에 제한된다. 하지만, <strong>저장소가 컴퓨터 클러스터에 나뉘어져 있는 분산 파일 시스템</strong> 이 있다. 클러스터에 장비를 추가함으로써 규모가 확장된다. 또한, 장비가 한 대 죽더라도 모든 파일과 데이터에 접근할 수 있다. (내결함성)</p>
<p>분산 파일 시스템과 일반적인 파일 시스템은 조금 다르다. 분산 파일시스템에서 수행가능한 연산은 제한적이다. 예를 들어, 파일 중간에 쓸 수 없고, 파일을 만든 후에 변경이 불가능하다. 또, 작은 파일은 비효율적이라서 파일 크기를 상대적으로 크게 유지해야한다. (64MB 정도가 일반적)</p>
<h4 id="4-3-분산-파일시스템의-동작-방식"><a href="#4-3-분산-파일시스템의-동작-방식" class="headerlink" title="4.3 분산 파일시스템의 동작 방식"></a>4.3 분산 파일시스템의 동작 방식</h4><p>하둡 분산 파일 시스템 (HDFS) 를 예로 들자.</p>
<p>HDFS 와 Hadoop MapReduce 는, <strong>대용량 데이터를 저장하고 처리하기 위한 자바 프레임워크인 하둡</strong> 프로젝트의 구성 요소이다. 하둡은 클러스터라고 부르는 여러 서버에 배포되고, HDFS 는 확장성 있는 파일 시스템으로 클러스터에 데이터가 어떻게 저장될지를 관리한다.</p>
<p>HDFS 에는 두 종류의 노드가 있다 : 하나의 네임 노드와 복수 개의 데이터노드</p>
<p>파일을 HDFS 에 올리면, 그 파일은 먼저 고정된 크기의 블록으로 쪼개진다. 블록 크기는 보통 64MB ~ 256MB 이다. 그리고, 각 블록은 임의의 선택된 복수개의 (보통 3개) 데이터 노드로 복제된다. 프로그램이 HDFS 에 저장된 파일에 접근할 때는 파일 내용을 보관하고 있는 데이터 노드를 알아내기 위해 네임노드에 접속한다.</p>
<p>각각의 블록이 추가적으로 여러 노드에 복제되어 있어서, 개별 노드가 오프라인 상태가 되어도 데이터는 여전히 사용 가능하다.</p>
<p><img src="/image/bigdata-hdfs.png" alt=""></p>
<h4 id="4-4-분산-파일-시스템을-사용해서-마스테-데이터-집합을-저장하기"><a href="#4-4-분산-파일-시스템을-사용해서-마스테-데이터-집합을-저장하기" class="headerlink" title="4.4 분산 파일 시스템을 사용해서 마스테 데이터 집합을 저장하기"></a>4.4 분산 파일 시스템을 사용해서 마스테 데이터 집합을 저장하기</h4><p>파일을 한번 생성한 후에 변경할 수 없는 가장 기본적인 분산 파일시스템을 사용해보자.</p>
<p>파일을 변경할 수 없다면 당연히 마스터 데이터 집합 전체를 하나의 파일에 저장할 수 없다. 다른 방법으로, 마스터 데이터 집합을 여러 파일로 나누고 모든 파일을 동일한 폴더에 저장하면 된다. 각 파일에는 직렬화된 데이터 객체가 들어있다.</p>
<p>마스터 데이터 집합에 데이터를 추가하려면, 새로운 데이터 객체를 가지고 있는 새로운 파일을 마스터 데이터 집합 폴더에 추가하면 된다. </p>
<p><img src="/image/bigdata-master-data.png" alt=""></p>
<h4 id="4-5-수직분할"><a href="#4-5-수직분할" class="headerlink" title="4.5 수직분할"></a>4.5 수직분할</h4><p>일괄 처리 계층은 전체 데이터 집합에 대한 함수를 실행하도록 만들어졌다. 하지만, 데이터 전체를 사용할 필요가 없는 계산도 있다. 예를 들면, 지난 두 주 동안 수집된 정보만 필요한 계산도 있을 수 있다.</p>
<p>일괄 처리 저장소는 데이터를 분할하여 <strong>함수가 자신의 계산과 관련있는 데이터에만 접근</strong>하록 해야한다. 이것이 수직분할이다. 일괄 처리 계층을 효율적으로 만든다.</p>
<p>데이터를 개개의 폴더에 저장하는 걸로 구현할 수 있다. 예를 들어, 분산 파일 시스템에 로그인 정보를 저장한다고 하자. 각각의 로그인 정보에는 사용자 이름 / IP / 주소 / 타임스탬프가 포함된다. 날짜를 기준으로 수직분할 하면, 그날 그날의 데이터에 사용할 독립적인 폴더를 만들면 된다. </p>
<p>이제 일부 데이터 집합에만 접근하고 싶으면, 특정 폴더에 있는 파일만 보고 나머지 파일은 무시할 수 있다.</p>
<p><img src="/image/bigdata-columnar.png" alt=""></p>
<h4 id="4-6-분산-파일-시스템의-하위-수준-속성"><a href="#4-6-분산-파일-시스템의-하위-수준-속성" class="headerlink" title="4.6 분산 파일 시스템의 하위 수준 속성"></a>4.6 분산 파일 시스템의 하위 수준 속성</h4><p>분산 파일 시스템 API 를 직접 사용하는 것은 실행해야 하는 작업에 비해, 너무 하위 수준이다.</p>
<p>마스터 데이터 집합에 데이터를 추가하는 예를 보자. 마스터 데이터 집합은 /master 폴더에 있다. 마스터 데이터 집합에 추가하고 싶은 데이터는 /new-data 폴더에 있다. 폴더에 있는 데이터는 파일에 저장된다.</p>
<p><img src="/image/bigdata-low-level.png" alt=""></p>
<p>가장 뻔한 방법은 다음 의사 코드 처럼 하는 것이다.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">foreach file:&quot;&#x2F;new-data&quot;</span><br><span class="line">	mv file &quot;&#x2F;master&quot;</span><br></pre></td></tr></table></figure>

<p>결함이 있다. 만약, 마스터 데이터 집합 폴더에 이름이 같은 파일이 있으면 mv 연산은 실패한다. 파일의 이름을 임의의 이름으로 바꿔서 충돌을 회피해야한다.</p>
<p>또한, /new-data 에 있는 파일과 /master 에 있는 파일의 형식이 다르면, mv 연산은 작동하지 않는다. 그래서, /new-data 에 있는 레코드를 복사해서 /master 에 있는 파일 포맷과 동일한 새로운 파일을 만들어야한다.</p>
<p>수직 분할 된 마스터 데이터 집합에 동일한 작업을 해보자.</p>
<p><img src="/image/bigdata-columnar-master-data.png" alt=""></p>
<p>/master 의 수직 분할을 따르지 않기 때문에, /new-data 에 있는 파일을 /master 의 최상위 경로로 바로 옮기면 안된다. 데이터 추가 연산을 허용하지 않거나, /new-data 에 대해 데이터 추가 연산의  부분으로 수직 분할을 해야한다. </p>
<p>그런데, 여기에 파일 및 폴더용 API 를 직접 사용하면 실수를 저지르기 쉽고 데이터 집합의 수직분할도 쉽게 깨질 수 있다. 이런 작업을 바르게 처리하기 위해 일일히 필요한 연산과 점검을 챙겨야 하는 것은, 파일과 폴더는 데이터 집합을 조작하기에는 추상화 수준이 너무 낮다는 것을 의미한다.</p>
<p>이러한 작업을 자동화해주는 라이브러리들을 다음 장에서 정리하자.</p>
<hr>
<p>빅데이터, 람다 아키텍처로 알아보는 실시간 빅데이터 구축의 핵심 원리와 기법 &lt;네이선 마츠, 제임스 워렌&gt;</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-03-07T15:00:00.000Z" title="2020-03-07T15:00:00.000Z">2020-03-08</time><span class="level-item"><a class="link-muted" href="/categories/big-data/">Big Data</a></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/03/08/bigdata-chapter-03/">[빅데이터] 3장_빅데이터를 위한 데이터 모델: 사례</a></h1><div class="content"><p>Apache Thrift 란 직렬화 프레임워크를 사용해 SuperWebAnalytics.com 데이터 모델을 구현한다.</p>
<h4 id="3-1-어째서-직렬화-프레임워크인가"><a href="#3-1-어째서-직렬화-프레임워크인가" class="headerlink" title="3.1 어째서 직렬화 프레임워크인가"></a>3.1 어째서 직렬화 프레임워크인가</h4><p>많은 개발자들이 원시 데이터를 기록하는 방법으로 JSON 등의 스키마 없는 형식을 고른다. 작업을 쉽게 착수할 수 있는 장점이 있지만, 데이터 오염이 언제든지 터질 수 있는 단점이 있다.</p>
<p>데이터 오염 문제는 그 문제가 어떻게 발생했는지에 대한 전후사정을 거의 손에 넣을 수 없기 때문에 디버깅이 어렵다. 예를 들어, 필수 항목이 누락되어 NPE 가 발생하면 문제의 원인이 누락된 항목이라는 것은 바로 알 수 있지만 애초에 그 데이터가 어떻게 들어왔는지에 대한 정보는 없다.</p>
<p>강제 가능 스키마를 만들었으면, 데이터를 기록하는 시점에 오류가 나므로 데이터가 무효화된 사정과 원인에 대한 전후 사정을 알 수 있다. 그리고, 이때 발생한 오류 덕에 프로그램은 무효 데이터를 기록하지 못하므로 마스터 데이터 집합도 오염되지 않는다.</p>
<p>직렬화 프레임워크를 사용하면 강제가능 스키마를 쉽게 적용 할 수 있다.</p>
<h4 id="3-2-Apache-Thrift"><a href="#3-2-Apache-Thrift" class="headerlink" title="3.2 Apache Thrift"></a>3.2 Apache Thrift</h4><p>Apache Thrift 는 정적 타입의 강제가능 스키마를 정의하는데 쓰이는 도구이다. 이와 유사한 도구로, Protocol Buffers 나 Avro 등이다. </p>
<p>Apache Thrift 의 주요 요소는 구조체 (struct) 와 공용체 (union) 타입 정의이다. 이들은 다음 필드의 조합으로 구성된다.</p>
<ol>
<li>기본 데이터 타입 : 문자열, 정수, long 정수, double 실수</li>
<li>다른 타입의 집합체 (리스트, 맵, 세트)</li>
<li>다른 구조체와 공용체</li>
</ol>
<h5 id="3-2-1-노드"><a href="#3-2-1-노드" class="headerlink" title="3.2.1 노드"></a>3.2.1 노드</h5><p>SuperWebAnalytics.com 의 사용자 노드에서 개인은 사용자ID 나 브라우저 키기로 식별된다. 이 둘이 동시에 함께 식별에 쓰이지는 않는다. 이런 패턴은 노드를 나타날 때 흔히 볼 수 있는데, 공용체 데이터 타입과 일치한다. 하나의 값으로 여러 가지를 나타내는 타입이다. </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">union PersonID &#123;</span><br><span class="line">	1: string cookie;</span><br><span class="line">	2: i64 user_id;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">union PageID &#123;</span><br><span class="line">	1: String url;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h5 id="3-2-2-간선"><a href="#3-2-2-간선" class="headerlink" title="3.2.2 간선"></a>3.2.2 간선</h5><p>간선은 두 개의 노드를 포함하는 구조체로 표현될 수 있다. 간선 구조체의 이름은 그것이 표현하는 관계를 가리킨다. 간선 구조체 내의 필드는 그 관계로 엮인 개체들이다.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">struct EquivEdge &#123;</span><br><span class="line">	1: required PersonID id1;</span><br><span class="line">	2: required PersonID id2;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">struct PageViewEdge &#123;</span><br><span class="line">	1: required PersonID person;</span><br><span class="line">	2: required PageID page;</span><br><span class="line">	3: required i64 nonce;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>스리프트 구조체의 필드는 required 나 optional 로 표시한다. 필드가 required 정의되었는데 값이 없으면 직렬화나 역직렬화할 때 스리프트 자체에서 오류가 난다. 그래프 스키마에서 각 간선은 두개의 노드가 필수이므로 required 필드로 정의된다.</p>
<h5 id="3-2-3-속성"><a href="#3-2-3-속성" class="headerlink" title="3.2.3 속성"></a>3.2.3 속성</h5><p>속성은 노드와 그 속성 대한 값을 가진다. 값은 여러 타입이 될 수 있으므로 공용체를 사용한다.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">union PagePropertyValue &#123;</span><br><span class="line">	1: i32 page_views;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">struct PageProperty &#123;</span><br><span class="line">	1: required PageID id;</span><br><span class="line">	2: required PagePropertyValue property;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">struct Location &#123;</span><br><span class="line">	1: optional string city;</span><br><span class="line">	2: optional string state;</span><br><span class="line">	3: optional string country;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">enum GenderType &#123;</span><br><span class="line">	MALE &#x3D; 1,</span><br><span class="line">	FEMALE &#x3D; 2</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">union PersonPropertyValue &#123;</span><br><span class="line">	1: string full_name;</span><br><span class="line">	2: GenderType gender;</span><br><span class="line">	3: Location location;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">struct PersonProperty &#123;</span><br><span class="line">	1: required PersonID id;</span><br><span class="line">	2: required PersonPropertyValue property;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h5 id="3-2-4-노드-간선-속성을-모두-엮어-데이터-객체로-만들기"><a href="#3-2-4-노드-간선-속성을-모두-엮어-데이터-객체로-만들기" class="headerlink" title="3.2.4 노드, 간선, 속성을 모두 엮어 데이터 객체로 만들기"></a>3.2.4 노드, 간선, 속성을 모두 엮어 데이터 객체로 만들기</h5><p>정보에 접근하는 단일한 인터페이스를 제공하기 좋게 모든 데이터를 함께 저장하고자 한다. 그리고, 단일 데이터 집합에 저장되면 데이터 관리도 쉽다. </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">union DataUnit &#123;</span><br><span class="line">	1: PersonProperty person_property;</span><br><span class="line">	2: PageProperty page_property;</span><br><span class="line">	3: EquivEdge equiv;</span><br><span class="line">	4: PageViewEdge page_view;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">struct Pedigree &#123;</span><br><span class="line">	1: required i32 true_as_of_secs;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">struct Data &#123;</span><br><span class="line">	1: required Pedigree pedigree;</span><br><span class="line">	2: required DataUnit dataunit;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Pedigree 구조체는 정보에 붙을 타임스탬프를 가지고 있다. 필요하면 디버깅 정보나 데이터 출처를 가질 수 있다. Data 구조체는 팩트 기반 모델의 팩트에 해당한다.</p>
<h5 id="3-2-5-스키마-발전시키기"><a href="#3-2-5-스키마-발전시키기" class="headerlink" title="3.2.5 스키마 발전시키기"></a>3.2.5 스키마 발전시키기</h5><p>스리프트는 시시때때로 스키마를 발전시키도록 설계되었다. 스키마를 변경할 때 기존 데이터와의 하위 호솬성을 유지하고자 하면 다음 규칙을 지켜야한다.</p>
<ol>
<li><p>필드의 이름은 변경해도 무방하다.</p>
<p>직렬화된 객체 형식은 필드 식별을 위해 ID 를 사용한다.</p>
</li>
<li><p>필드를 삭제할 수 있지만, 필드 ID 를 재사용하면 안된다.</p>
<p>기존 데이터를 역직렬화할 때 스리프트는 스키마에 포함되지 않은 ID 를 갖는 필드는 모두 무시한다. 삭제된 필드의 ID 를 재사용하면 스리프트는 오래된 데이터를 새로운 필드로 역직렬화할 것이다. 그래서 유효하지 않거나 잘못된 데이터가 만들어질 수 있다.</p>
</li>
<li><p>기존 구조체에는 optional 필드만 추가할 수 있다.</p>
<p>기존 데이터는 그 필드가 없을 것이고 결국 역직렬화가 되지 않을 것이다. (공용체의 경우 required 나 optional 개념이 없다.)</p>
</li>
</ol>
<h4 id="3-3-직렬화-프레임워크의-한계"><a href="#3-3-직렬화-프레임워크의-한계" class="headerlink" title="3.3 직렬화 프레임워크의 한계"></a>3.3 직렬화 프레임워크의 한계</h4><p>직렬화 프레임워크는 required 필드가 모두 존재하고, 타입이 일치하는지만 점검한다. 즉, “나이는 음수가 아니어야한다.”, “참인 시점의 타임스탬프는 미래가 아니어야한다.” 와 같은 다채로운 속성은 점검할 수 없다.</p>
<blockquote>
<p>스키마는 데이터를 받아 유효 여부를 반환하는 하나의 함수로 보는게 좋다. </p>
</blockquote>
<p>그런 이상적인 도구는 현실적으로 세상에 없지만, 한계를 우회할 수 있는 두 가지 방법이 있다.</p>
<ol>
<li><p>생성된 코드를 추가 코드로 감싸고, 추가 코드에서 나이는 음수가 아닌 조건을 체크하는 등의 추가적인 속성을 확인하도록 한다.</p>
<p>여러 언어를 사용한다면 동일한 로직을 여러 언어로 작성하는 중복 작업이 요구된다.</p>
</li>
<li><p>일괄 처리 작업 흐름의 시작점에서 추가 속성을 확인한다.</p>
<p>이 확인 단계에서 데이터 집합을 유효한 데이터와 유효하지 않은 데이터로 나누고 유효한 데이터가 발견되면 알림을 보낸다. 그러면, 작업 흐름의 나머지 부분 구현이 쉬워진다. 유효성 확인을 통과한 데이터이면 엄격한 속성을 일단 가지고 있다고 가정할 수 있다. 그런데, 무효 데이터가 마스터 데이터 집합에 기록되는 것을 막지는 못하며, 데이터 오염이 발생한 전후 사정을 알아낼 수 없다.</p>
</li>
</ol>
<hr>
<p>빅데이터, 람다 아키텍처로 알아보는 실시간 빅데이터 구축의 핵심 원리와 기법 &lt;네이선 마츠, 제임스 워렌&gt;</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-02-24T15:00:00.000Z" title="2020-02-24T15:00:00.000Z">2020-02-25</time><span class="level-item"><a class="link-muted" href="/categories/big-data/">Big Data</a></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/02/25/bigdata-chapter-02/">[빅데이터] 2장_빅데이터를 위한 데이터 모델</a></h1><div class="content"><p>마스터 데이터 집합은 람다 아키텍처에서 반드시 오염으로부터 보호되어야하는 유일한 영역이다.</p>
<p><img src="/image/bigdata_c02_01.png" alt=""></p>
<h4 id="2-1-데이터의-속성"><a href="#2-1-데이터의-속성" class="headerlink" title="2.1 데이터의 속성"></a>2.1 데이터의 속성</h4><p><img src="/image/bigdata_c02_02.png" alt=""></p>
<p>대규모 소셜 네트워크 (페이스스페이스) 를 설계한다고 하자. 각각의 정보 계층은 바로 앞 단계로부터 파생되지만 단방향성이다.</p>
<p>앞으로 사용하게 될 용어들을 정리한다.</p>
<ol>
<li>정보 : 지식의 일반적인 모음</li>
<li>데이터 : 어떤 것으로부터 파싱되지 않은 정보</li>
<li>질의 : 데이터에 물어볼 수 있는 질문</li>
<li>뷰 :  특정 타입의 질의에 응답하는데 도움을 주기 위해 만들어 지는 것</li>
</ol>
<p><img src="/image/bigdata_c02_03.png" alt=""></p>
<p>어떤 사람의 데이터는 또 다른 사람의 뷰각 될 수 있다. 어떤 광고 회사가 페이스스페이스 사용자 프로필로부터 인구 통계학 정보를 긁어 가는 수집기를 만들었다. 톰의 출생월일은 생년월일로부터 도출될 수 있기 때문에 페이스스페이스에게는 뷰 이지만, 광고 회사 입장에서는 톰에 대한 제한된 정보를 가지는 것으로 시작하므로 데이터이다.</p>
<p>데이터의 핵심 속성을 살펴보자 : 원시성 / 불변성 / 영원성</p>
<h5 id="2-1-1-데이터는-원시적이다"><a href="#2-1-1-데이터는-원시적이다" class="headerlink" title="2.1.1 데이터는 원시적이다"></a>2.1.1 데이터는 원시적이다</h5><p>가공되지 않은 데이터일수록 더 많은 질문을 그 데이터에 대해 던질 수 있다.</p>
<h5 id="2-1-2-데이터는-불변이다"><a href="#2-1-2-데이터는-불변이다" class="headerlink" title="2.1.2 데이터는 불변이다."></a>2.1.2 데이터는 불변이다.</h5><p>관계형 데이터메이스 갱신은 없어서는 안 될 연산이다. 그러나 불변성을 다루기 위해서는 데이터를 갱신하거나 삭제하면 안되고 추가만 해야한다. 빅데이터 시스템에서 불변 스키마를 사용하면 다음 두 가지 이점이 있다.</p>
<ol>
<li><p>인적 내결함성 </p>
<p>실수로 인해 데이터가 손실되지 않는다. 잘못된 데이터가 쓰여도 이전에 있던 데이터는 그대로 남는다.</p>
</li>
<li><p>단순성</p>
<p>마스터 데이터 집함에 새 데이터를 추가할 수 있으면 된다. 데이터에 대한 색인이 필요하지 않아 단순하다.</p>
</li>
</ol>
<p>데이터의 불변성을 유지하는 것의 장점은 가변 스키마와 비교하면 명확하다.</p>
<p><img src="/image/bigdata_c02_04.png" alt=""></p>
<p>톰이 LA 로 이사했다. 그러면 톰의 현재 주거지를 반영하기 위해 갱신을 해야하는데, 톰이 샌프란시스코에 살았다는 지식은 완전히 손실된다.</p>
<p>불변 스키마를 사용하면 상황이 다르다. 사용자 정보가 바뀔 때마다 독립된 레코드를 생성한다. 이렇게 하려면 두 가지를 바꿔야한다.</p>
<ol>
<li>사용자 정보의 각 항목을 독립된 레코드에 저장한다.</li>
<li>각 데이터 단위에 그 정보가 알려진 시간을 붙인다.</li>
</ol>
<p><img src="/image/bigdata_c02_05.png" alt=""></p>
<p>톰이 새 주거지로 이사를 하면, 주거지 테이블에 새 래코드를 추가한다. 이제 톰의 주거지를 저장하는 레코드가 두 개가 된다. 관련된 모든 주거지 정보를 훑으면서 타임스태프가 가장 최신인 것을 골라내, 현재 주거지를 알 수 있다. </p>
<p>불변 방식을 사용하는 방법으로 감당해야하는 것은 가변 스키마보다 공간을 많이 사용한다는 것이다. 사용자 ID 는 가변 방식에서처럼 로우마다 한 번 나오는게 아니라 모든 속성에 나온다. 게다가 현재 상태 뿐만 아니라 이벤트 기록을 전부 저장한다.</p>
<p>하지만, 빅데이터 기술을 통해 막대한 데이터의 저장 능력을 이용해서 불변성의 헤택을 끌어내야한다. 마스터 데이터 집합을 구축하는 일은 정말 중요하다.</p>
<h5 id="2-1-3-데이터는-영원히-참이다"><a href="#2-1-3-데이터는-영원히-참이다" class="headerlink" title="2.1.3 데이터는 영원히 참이다."></a>2.1.3 데이터는 영원히 참이다.</h5><p>데이터의 불변성으로 인해 만들어지는 중요한 결과는, 데이터가 영원히 참이 된다는 것이다.</p>
<h4 id="2-2-데이터-표현을-위한-팩트-기반-모델"><a href="#2-2-데이터-표현을-위한-팩트-기반-모델" class="headerlink" title="2.2 데이터 표현을 위한 팩트 기반 모델"></a>2.2 데이터 표현을 위한 팩트 기반 모델</h4><p>마스터 데이터 집합 안에서 데이터를 표현하는 방법은 여러가지다. </p>
<ol>
<li>전통적인 관계형 데이터베이스의 테이블</li>
<li>구조화된 XML</li>
<li>반구조화된 JSON</li>
<li>팩트 기반 모델 (fact-based model) : 데이터를 fact 라고 불리는 기본 단위로 분해</li>
</ol>
<h5 id="2-2-1-팩트의-예와-속성"><a href="#2-2-1-팩트의-예와-속성" class="headerlink" title="2.2.1 팩트의 예와 속성"></a>2.2.1 팩트의 예와 속성</h5><p><img src="/image/bigdata_c02_06.png" alt=""></p>
<p>팩트 기반 모델은,</p>
<ol>
<li>원시 데이터를 원자적인 팩트로 저장한다.</li>
<li>타임스탬프로 인해 팩트는 불변성을 지니며 영원히 참이다.</li>
<li>질의 처리 과정 중에 중복 식별이 가능하도록 각 팩트의 식별 가능성을 보장한다.</li>
</ol>
<p>팩트는 유일하게 식별할 수 있는 데이터와 연관되어야한다. 페이스스페이스에 페이지뷰에 대한 데이터를 저장하는 경우를 생각해보자. </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">struct PageView:</span><br><span class="line">	DateTime timestamp</span><br><span class="line">	String url</span><br><span class="line">	String ip_address</span><br></pre></td></tr></table></figure>

<p>이 구조체를 사용한 팩트는 특정한 페이지뷰 이벤트로 유일하게 식별되지 않는다. 동일한 IP 주소에서 동일한 URL 에 대한 여러개의 페이지뷰가 동시에 발생하면, 이 때 생겨난 각각의 페이지뷰는 정확히 같은 데이터 레코드이다. </p>
<p>서로 다른 페이지뷰를 구분하기 위해 스키마에 nonce (임시값), 각 페이지뷰마다 난수 생성법을 써서 만든 64 비트 숫자를 추가해보자.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">struct PageView:</span><br><span class="line">	DateTime timestamp</span><br><span class="line">	String url</span><br><span class="line">	String ip_address</span><br><span class="line">	Long nonce</span><br></pre></td></tr></table></figure>

<p>임시값을 추가하면 페이지뷰 이벤트를 서로 구별할 수 있고, 두 개의 페이지뷰 데이터 단위가 동일하면 이벤트도 동일하다는 것을 알 수 있다.</p>
<h5 id="2-2-2-팩트-기반-모델이-주는-혜택"><a href="#2-2-2-팩트-기반-모델이-주는-혜택" class="headerlink" title="2.2.2 팩트 기반 모델이 주는 혜택"></a>2.2.2 팩트 기반 모델이 주는 혜택</h5><ol>
<li><p>과거의 어느 시점에 대한 질의도 받을 수 있다.</p>
<p>팩트에 타임스탬프가 붙어있고 불변성을 지녀 생기는 결과이다.</p>
</li>
<li><p>사람의 실수에 대해 내성을 가진다.</p>
<p>톰이 샌프란시스코에서 로스앤잴래스로 이사한 것을 실수로 저장했다. 톰이 로스엔제렐스에 산다는 팩트를 지우면, 톰의 주거지가 자동으로 이전의 것으로 재설정된다.</p>
</li>
<li><p>부분 정보를 처리할 수 있다.</p>
<p>톰이 나이와 성별은 입력했지만 주거지나 직업은 입력하지 않으면, 데이터 집합은 알려진 정보에 대한 팩트만 보관한다. 팩트가 존재하지 않는다는 것은, 논리적으로 null 과 동일하다. </p>
</li>
<li><p>데이터 저장소의 질의 처리 계층이 분리된다.</p>
<p>batch layer 와 serving layer 모두에 정보가 저장되기 때문에 데이터가 정규화된 형태와 비정규화된 형태로 있게 되고, 양쪽의 모든 장점을 뽑을 수 있다.</p>
</li>
</ol>
<p>데이터 정규화를 다루는 관계형 테이블 예를 보자. 관계형 테이블을 사용할 때는 질의 효율성과 데이터 일관성 중 어떤 것이 중요하냐에 따라 정규화 스키마와 비정규화 스키마 중 하나를 선택한다.</p>
<p><img src="/image/bigdata_c02_07.png" alt=""></p>
<ol>
<li><p>비정규화된 스키마</p>
<p>동일한 이름이 여러 로우에 저장 될 수 있다. 이것은 각 회사의 직원수를 빨리 알아 낼 수 있도록 하지만, 회사가 이름을 바꾸면 많은 로우를 갱신해야한다. 정보를 여러 위치에 저장하는 것은 일관성이 깨질 위험이 있다.</p>
</li>
<li><p>정규화된 스키마</p>
<p>오직 하나의 위치에만 저장된다. 일관성이 깨질 위험은 없지만, 질의에 응답하려면 테이블을 조인해야하고 계산 비용이 커질 수 있다.</p>
</li>
</ol>
<p>람다 아키텍쳐에서는 질의 처리와 데이터 저장 목적이 분리되어 있다. </p>
<p><img src="/image/bigdata_c02_08.png" alt=""></p>
<ol>
<li><p>마스터 데이터 집합</p>
<p>완전히 정규화되어 있다. 어떤 데이터도 중복 되지 않는다. 현재 타임스템프를 붙여 새 팩트를 추가하면 과거 팩트는 무효화되어 갱신이 쉽다.</p>
</li>
<li><p>일괄처리 뷰</p>
<p>데이터 집합의 데이터 하나가 여러 뷰로 생성될수 있다는 점에서 비정규화된 테이블과 같다. 큰 차이는, 일괄 처리 뷰는 마스터 데이터 집합에 대한 함수로 정의된다는 것이다. 마스터 데이터 집합으로부터 계속 재생성 되므로 일괄 처리 뷰를 갱신할 필요가 없다.</p>
</li>
</ol>
<h4 id="2-3-그래프-스키마"><a href="#2-3-그래프-스키마" class="headerlink" title="2.3 그래프 스키마"></a>2.3 그래프 스키마</h4><p>팩트 그 자체만으로는, 데이터 집합에 저장된 팩트의 형식에 대한 기술도 없고, 그들 사이의 관계에 대한 설명도 없다. 그래서, 그래프 스키마가 필요하다.</p>
<h5 id="2-3-1-그래프-스키마의-요소"><a href="#2-3-1-그래프-스키마의-요소" class="headerlink" title="2.3.1 그래프 스키마의 요소"></a>2.3.1 그래프 스키마의 요소</h5><p>세 가지 핵심 요소는, </p>
<ol>
<li>노드 : 시스템 내의 개체</li>
<li>간선 : 노드 사이의 관계</li>
<li>속성 : 개체에 대한 정보</li>
</ol>
<p><img src="/image/bigdata_c02_09.png" alt=""></p>
<h5 id="2-3-2-강제-기능-스키마는-왜-필요한가"><a href="#2-3-2-강제-기능-스키마는-왜-필요한가" class="headerlink" title="2.3.2 강제 기능 스키마는 왜 필요한가"></a>2.3.2 강제 기능 스키마는 왜 필요한가</h5><p>팩트를 저장할 때 어떤 형식으로 저장해야할까.  JSON 처럼, 반구조화된 텍스트 형식을 사용한다고 하자. 실질적으로 어떤 것도 마스터 데이터 집합에 기록할 수 있어서 단순하고 유연하다. 하지만 문제가 있다.</p>
<p>톰의 나이를 JSON 으로 나타내면,</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&quot;id&quot; : 3, &quot;field&quot; : &quot;age&quot;, &quot;value&quot; : 29, &quot;timestamp&quot; : 133589484&#125;</span><br></pre></td></tr></table></figure>

<p>사람의 실수로 데이터 집합에 아래와 같은 팩트가 들어 갈 수 있다.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&quot;id&quot; : 3, &quot;field&quot; : &quot;age&quot;, &quot;value&quot; : 29&#125;</span><br></pre></td></tr></table></figure>

<p>JSON 자체는 유효하지만, 형식의 일관성을 지키지 못했고 데이터도 누락되었다. 텍스트 형식으로는 이 부분을 강제할 수 없다. </p>
<p>대안으로, 팩트의 구조를 엄격히 정의하는 강제 기능 스키마를 사용하면 된다. 처음에는 해줄게 많지만, 필요한 필드가 모두 존재하고 모든 값이 기대한 형식에 맞게 한다는 조건이 보장된다. 중요한 것은, 데이터 생성 중에 실수가 있을 때 강제 기능 스키마가 바로 그 시점에 오류를 낸다.</p>
<hr>
<p>빅데이터, 람다 아키텍처로 알아보는 실시간 빅데이터 구축의 핵심 원리와 기법 &lt;네이선 마츠, 제임스 워렌&gt;</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-02-24T15:00:00.000Z" title="2020-02-24T15:00:00.000Z">2020-02-25</time><span class="level-item"><a class="link-muted" href="/categories/big-data/">Big Data</a></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/02/25/bigdata-chapter-01/">[빅데이터] 1장_빅데이터를 위한 새로운 패러다임</a></h1><div class="content"><h4 id="1-1-이-책의-구성"><a href="#1-1-이-책의-구성" class="headerlink" title="1.1 이 책의 구성"></a>1.1 이 책의 구성</h4><p>이론을 다루는 장과 사례를 다루는 장으로 나뉜다. 이론을 다루는 장은 빅데이터 시스템을 구축하는 방법을 다루고, 사례를 다루는 장에서는 이론을 구체적인 도구에 연관시킨다.</p>
<h4 id="1-2-전통적인-데이터베이스를-사용해-확장하기"><a href="#1-2-전통적인-데이터베이스를-사용해-확장하기" class="headerlink" title="1.2 전통적인 데이터베이스를 사용해 확장하기"></a>1.2 전통적인 데이터베이스를 사용해 확장하기</h4><p>간단한 웹 분석 어플리케이션을 개발한다고 하자. 고객의 웹 페이지는 페이지뷰가 발생할 때마다 애플리케이션의 웹서버에 URL 정보를 보내야한다. 웹 서버는 데이터베이스에 페이지뷰에 해당하는 row 의 값을 증가시킨다. 이제 애플리케이션에 개선되며 어떤 문제가 생기는지 살펴본다.</p>
<h5 id="1-2-1-큐를-사용해-확장하기"><a href="#1-2-1-큐를-사용해-확장하기" class="headerlink" title="1.2.1 큐를 사용해 확장하기"></a>1.2.1 큐를 사용해 확장하기</h5><p>백엔드의 데이터베이스가 부하를 견디지 못해 페이지 뷰를 증가시키는 쓰기 요청을 신속히 처리하지 못해 타임 아웃이 나고 있다고 하자. </p>
<p>웹 서버가 데이터베이스에 직접 접근하도록 하는 대신, 웹 서버와 데이터베이스 사이에 큐를 넣는다. 그래서, 페이지뷰 이벤트를 받을 때마다 이벤트는 큐에 추가된다. 그리고, 큐에서 한 번에 100개씩 이벤트를 꺼내 하나의 데이터베이스 갱신 요청으로 일괄 처리하는 작업자 프로세스를 추가한다.</p>
<h5 id="1-2-2-데이터베이스를-샤딩하여-확장하기"><a href="#1-2-2-데이터베이스를-샤딩하여-확장하기" class="headerlink" title="1.2.2 데이터베이스를 샤딩하여 확장하기"></a>1.2.2 데이터베이스를 샤딩하여 확장하기</h5><p>이 웹 분석 애플리케이션이 계속 인기가 높아져, 데이터베이스에 과부하가 다시 걸렸다고 하자. 기존의 작업자 프로세스로는 쓰기 요청을 감당할 수 없어 갱신을 병렬 처리 하기 위해 작업자 프로세스의 수를 늘렸보았지만 도움이 되지 않았다.</p>
<p>그래서, 데이터베이스 서버를 여러 대 사용하고 테이블을 여러 서버에 분산시키는 수평 분할, 또는 샤딩이라고 불리는 방법을 사용한다. 즉, 각 서버는 전체 테이블의 일부를 가지는 것이다. 쓰기 부하를 여러 서버, 즉 샤드로 분산 시키게 되는 것이다.</p>
<p>이 애플리케이션의 인기가 높어져, 데이터베이스를 더 많은 샤드로 나누었다고 하자. 샤드 개수가 변경되어서 기존의 애플리케이션 코드에도 반영을 해야하고 이것을 깜빡하면 의도하지 않은 샤드에 기록된다. </p>
<h5 id="1-2-3-내결함성-문제-발생-시작"><a href="#1-2-3-내결함성-문제-발생-시작" class="headerlink" title="1.2.3 내결함성 문제 발생 시작"></a>1.2.3 내결함성 문제 발생 시작</h5><p>어쨌든 샤드를 늘렸는데, 이제 데이터베이스 장비에서 디스크 장애가 발생하는 상황이 왔다. 디스크 장애가 발생한 장비가 다운된 동안엔 그 디스크에 저장된 데이터를 사용할 수 없다. 해결책으로는,</p>
<ol>
<li><p>큐 / 작업자 시스템을 수정해서, 사용 불능 상태의 샤드로 들어오는 증가 이벤트는 별도의 대기 큐에 넣고 이를테면 5분 마다 한 번씩 큐의 쌓여 있는 이벤트를 일괄 처리한다.</p>
</li>
<li><p>데이터베이스의 자체 복제 기능을 사용해 마스터가 다운됐을 때 백업으로 사용할 수 있는 슬레이브를 각 샤드에 추가한다. 슬레이브는 쓰기가 불가능하지만, 적어도 고객이 애플리케이션 상태를 조회할 수 있도록은 한다.</p>
</li>
</ol>
<h5 id="1-2-4-데이터-오염-문제"><a href="#1-2-4-데이터-오염-문제" class="headerlink" title="1.2.4 데이터 오염 문제"></a>1.2.4 데이터 오염 문제</h5><p>큐 / 작업자 코드를 수정하는 도중, 실수로 모든 URL 에 대한 페이지 뷰를 1이 아니라 2씩 증가 시키는 버그를 만들었다고 하자. 데이터가 오염된다.</p>
<h5 id="1-2-5-어디서부터-잘못된-건가"><a href="#1-2-5-어디서부터-잘못된-건가" class="headerlink" title="1.2.5 어디서부터 잘못된 건가 ?"></a>1.2.5 어디서부터 잘못된 건가 ?</h5><p>여러분이 사용하는 데이터베이스는 스스로 데이터가 어떻게 분산되어 있는지 모른다. 이런 복잡함이 모두 데이터베이스 운영 작업과, 애플리케이션 코드 개발 작업에 더해진다. </p>
<p>시스템이 복잡해질수록 실수할 가능성은 커진다. 인적 내결함성 (human fault-tolerance) 는 필수 사항이다.</p>
<h5 id="1-2-6-빅데이터-기술이-어떻게-되움이-되는가"><a href="#1-2-6-빅데이터-기술이-어떻게-되움이-되는가" class="headerlink" title="1.2.6 빅데이터 기술이 어떻게 되움이 되는가 ?"></a>1.2.6 빅데이터 기술이 어떻게 되움이 되는가 ?</h5><p>빅데이터용 데이터베이스 및 계산 시스템은 데이터 어떤 식으로 분산되어 있는지를 자체적으로 알고 있다. 그래서, 샤딩이나 복제본 생성 작업을 알아서 처리한다.</p>
<p>또 다른 핵심 기술은, 데이터를 변경 불가 형태로 만든다는 것이다. 정상 데이터를 파괴하지 않아, 전통적인 데이터베이스보다 강력한 human fault-tolerance 을 제공한다.</p>
<h4 id="1-3-NoSQL-은-만병-통치약이-아니다"><a href="#1-3-NoSQL-은-만병-통치약이-아니다" class="headerlink" title="1.3 NoSQL 은 만병 통치약이 아니다"></a>1.3 NoSQL 은 만병 통치약이 아니다</h4><p>하둡과 같은 대용량 계산 시스템은, 대용량 일괄 처리식 계산은 병렬로 처리할 수 있지만 계산의 latency 가 오래 걸린다.</p>
<p>카산드라 같은 NoSQL 데이터베이스는 SQL 보다 훨씬 제한된 모델을 제공해서 확작성을 얻는다. 하지만, 이러한 제한된 데이터 모델에 애플리케이션을 끼워 넣는 것은 매우 복잡할 수 있다. 그리고 가변성을 전제로 하기 때문에 인적 내결함성을 갖추지 못하고 있다.</p>
<p>이 도구들을 현명하게 잘 결합하면 인적 내결함성을 갖추고 복잡성을 최소하해 확장성 있는 시스템을 만들 수 있다.</p>
<h4 id="1-4-기본-원칙"><a href="#1-4-기본-원칙" class="headerlink" title="1.4 기본 원칙"></a>1.4 기본 원칙</h4><p>데이터 시스템은 여러 조각 정보들을 조합해서 응답을 만든다. 예를 들어, 은행 계좌 잔고는 그 계좌에서 발생한 모든 거래에 대한 정보를 바탕으로 만들어진다. 더 중요한 것은, 모든 정보의 조각들이 동등한 성격이 아니라는 것이다. 어떤 정보는 다른 정보로부터 유래된다. 은행 계좌 잔고는 거래 내력을 가지고 만들어진다.</p>
<p>정보가 만들어진 재료가 되는 원래의 정보를 거꾸로 추적해가면 결국 다른 어떤 정보로부터도 파생되지 않은 정보에 다다른다. 이 정보를 데이터라고 한다. 데이터 시스템을 정의하면 다음과 같다. 데이터로 할 수 있는 모든 일은 현재 갖고 있는 모든 데이터를 입력으로 받는 함수로 표현할 수 있다.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">query &#x3D; function(all data)</span><br></pre></td></tr></table></figure>

<h4 id="1-5-빅데이터-시스템에-요구되는-속성"><a href="#1-5-빅데이터-시스템에-요구되는-속성" class="headerlink" title="1.5 빅데이터 시스템에 요구되는 속성"></a>1.5 빅데이터 시스템에 요구되는 속성</h4><ol>
<li><p>견고성과 내결함성<br>복잡성을 회피해서 시스템에 대해 쉽게 생각할 수 있도록 하는 것도 빅데이터 시스템을 견고하게 만다는 작업이다. 그리고 빅데이터 시스템의 핵심에 불변성과 재계산 체계를 구축해놓으면, 복구 매커니즘이 쉽고 간결해져 사람의 실수에 대한 회복력을 지니게 된다.</p>
</li>
<li><p>짧은 읽기 / 갱신 지연 시간<br>시스템의 견고성을 해치지 않고 짧은 읽기 / 갱신 지연 시간을 얻을 수 있어야한다.</p>
</li>
<li><p>확장성<br>데이터나 부하가 늘어났을 때 시스템에 자원을 더 투입하는 것만으로 원래의 성능을 유지할수 있는 능력이다.</p>
</li>
<li><p>일반성<br>일반적인 시스템은 폭넓은 분야의 애플리케이션에 쓰일 수 있다.</p>
</li>
<li><p>유연성<br>대규모 데이터 이전을 용이하게 만다는 것은 시스템에 유연성을 부여하는 방법 중 하나이다.</p>
</li>
<li><p>ad hoc query<br>데이터에 대해 즉석 질의를 수행하는 것은 중요하다. </p>
</li>
<li><p>최소한의 유지 보수<br>유지보수를 최소화하기 위해, 가능하면 구현 복잡도를 낮게 만들어주는 구성 요소가 필요하다.</p>
</li>
<li><p>디버깅 가능성<br>빅데이터 시스템은 뭔가 잘못되었을 때 디버깅하는 데 필요한 정보를 제공해야한다. </p>
</li>
</ol>
<h4 id="1-6-완전-증분-아키턱쳐의-문제점"><a href="#1-6-완전-증분-아키턱쳐의-문제점" class="headerlink" title="1.6 완전 증분 아키턱쳐의 문제점"></a>1.6 완전 증분 아키턱쳐의 문제점</h4><p>완전 증분 아키턱쳐의 특징은, 데이터베이스를 읽고 쓴다는 것과 새로운 데이터가 들어왔을 때 데이터베이스의 상태를 증분식으로 변경한다는 것이다. 예를 들어, 페이지뷰를 셀 때 새로운 페이지뷰가 발생할 때마다 해당 URL 의 페이지 뷰 수에 1을 더한다. </p>
<p>이제 완전 증분 아키텍처로 인해 생기는 일반적인 복잡성을 살펴본다. </p>
<h5 id="1-6-1-운영-복잡성"><a href="#1-6-1-운영-복잡성" class="headerlink" title="1.6.1 운영 복잡성"></a>1.6.1 운영 복잡성</h5><p>읽기 / 쓰기를 지원하는 데이터베이는, 디스크 색인이 증분식으로 추가 및 변경되기 때문에 색인 일부가 사용되지 않은채로 남는다. 이들 미사용 영역은 공간만 차지할 뿐이고 디스크를 다 채워버리는 것을 막기 위해 회수되어야한다. 색인이 필요 없을 때 바로 회수하는 것은 너무 비용이 비싸기 때문에, 미사용 영역이 차지하는 공간은 가끔 실행되는 <strong>압밀화</strong> 과정을 통해 큰 단위로 회수된다.</p>
<p>서버는 압밀화를 수행하는 동안 CPU 와 디스크에 상당한 부담을 주게 되어 수행중에는 장비의 성능이 극적으로 떨어진다. 만약 동시에 너무 많은 장비가 압밀화를 수행하면 그들이 담당하고 있던 부하는 클러스터에 있는 다른 장비에 의해 처리되어야하고 이는 잠재적으로 클러스터의 나머지 부분에 과부하를 유발하여 전체 클러스터에 장애가 발생할 수 있다.</p>
<p>압밀화를 잘 관리하려면 한 번에 영향을 받는 노드가 너무 많아지지 않게 각 노드의 스케쥴링을 잡아줘야 한다. 운영 담당 직원이 처리할 수 있게 할 수 있지만, 어떤 성격의 복잡성이든 가장 좋은 대처 방법은 그 복잡성 자체를 아예 제거하는 것이다.</p>
<p>온라인 압밀화에 신경써야하는것은 완전 증분 아키텍쳐에 내재된 복잡성이다.</p>
<h5 id="1-6-2-최종적-일관성을-달성할-때-수반되는-극심한-복잡성"><a href="#1-6-2-최종적-일관성을-달성할-때-수반되는-극심한-복잡성" class="headerlink" title="1.6.2 최종적 일관성을 달성할 때 수반되는 극심한 복잡성"></a>1.6.2 최종적 일관성을 달성할 때 수반되는 극심한 복잡성</h5><p>고가용성 시스템은 장비에 장애가 발생하거나 네트워크에 부분적인 장애가 발생할 때도 질의와 갱신을 실행할수 있게 한다. 일관성이라는 키워드와 직접 경쟁한다. CAP 정리에 의하면, 네트워크가 분단된 상황에서는 같은 시스템 안에서 고가용성과 일관성을 동시에 달성할 수 없다고 한다. 그래서, 고가용성 시스템에서는 네트워크 분단이 발생하면 오래된 결과를 반환하는 경우도 있다.</p>
<p>네트워크 분단이 해소되면, 고가용성 시스템이 언젠가는 일관성 있는 결과를 반환하도록 하려면 (== 최종적 일관성), 애플리케이션의 도움이 필요하다. 예를 들어, 데이터베이스에 숫자를 저장하고 개수를 증가 시키는 이벤트를 받을 때마다 그 숫자의 값을 증가시키는 것이다. 이 경우, 네트워크 분단이 발생하면 대량의 데이터 손실이 발생할 수 있다.</p>
<p>그 원인은, 분산 데이터베이스는 모든 정보가 저장된 복제본을 여러 개 유지함으로써 고가용성을 얻고 있기 때문이다. 10을 저장하고 있는 두 대의 복제 서버가 있을 때 네트워크 분단이 발생했다고 해보자. 첫 번째 복제서버에서는 2가 증가했고, 두번째 서버에서는 1이 증가했다. 각각 12와 11을 저장하고 있는 이 서버들의 상태를 합쳐야할 때 어떤 값을 써야할까? 정답은 13 이지만, 12와 11을 봐서는 알 수 없다. 상태가 달라지기 전에 11을 저장하고 이있을 수도 있고 0을 저장하고 있을 수도 있다.</p>
<p>고가용성을 갖춘 상태에서 개수를 올바르게 세려면, 개수만 저장하는 것으로 부족하다. 서로 달라지는 값을 합치는데 적합한 자료구조를 사용해야하고 네트워크 분단이 해소되었을 때 올바른 값을로 수정하는 코드를 구현해야한다. 단순한 개수를 저장하는 것인데, 이렇게 복잡하다.</p>
<h5 id="1-6-3-인적-내결함성-결여"><a href="#1-6-3-인적-내결함성-결여" class="headerlink" title="1.6.3 인적 내결함성 결여"></a>1.6.3 인적 내결함성 결여</h5><p>증분 시스템에 데이터베이스에 저장된 상태를 지속적으로 변경한다는 것은 실수로 데이터베이스의 상태를 바꿀 수 있는 것을 의미한다. 실수는 불가피하기 때문에 언젠가 오염될 수 있다.</p>
<p>이를 해결하기 위해, </p>
<ol>
<li>애프리케이션이 데이터베이스를 직접 갱신하는 동기식 아키텍쳐 말고, </li>
<li>이벤트를 큐에 모아 두었다가 백그라운드로 데이터베이스를 갱신하는 비동기식 아키텍쳐를 사용하면 해결할 수 있다.</li>
</ol>
<p>모든 이벤트를 저장해 놓았기 때문에 사람이 실수로 데이터베이스를 오염시켜도 이벤트 저장소를 참조해 데이터베이스를 올바른 상태로 되돌릴 수 있다.</p>
<h4 id="1-7-람다-아키텍쳐"><a href="#1-7-람다-아키텍쳐" class="headerlink" title="1.7 람다 아키텍쳐"></a>1.7 람다 아키텍쳐</h4><p>람다 아키텍쳐의 핵심 아이디어는 빅데이터 시스템을 일련의 계층을로 구축하는 것이다 : 속도 계층 / 서빙 계층 / 일괄 처리 계층</p>
<p>모든 것은 다음 식으로부터 시작한다.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">query &#x3D; function(all data)</span><br></pre></td></tr></table></figure>

<p>하지만, 너무 많은 양의 자원이 소모되며 불합리하게 많은 비용이 든다. 누군가의 현재 위치를 찾을 때마다 페타바이트의 데이터 집합으 읽어야된다고 생각해보자.</p>
<p>가장 쉬운 대안은, 사전 계산하는 것이다. 질의 함수를 사전 계산한 결과를 batch view (일괄 처리 뷰) 라고 한다.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">batch view &#x3D; function(all data)</span><br><span class="line">query &#x3D; function(batch view)</span><br></pre></td></tr></table></figure>

<p>모든 데이터에 대해 함수를 실행해서 일괄처리 뷰를 생성해 놓는다. 그 후 어떤 질의의 결과가 필요할 때 일괄 처리 뷰에 대해 함수를 실행한다. </p>
<p>일괄처리 뷰를 생성할 때는 모든 데이터에 대해 함수를 실행해야하므로 그 시간이 오래 걸린다. 일괄처리 뷰 생성이 끝나면 일괄처리 뷰에 없는 데이터가 그동안 쌓였을 것이고, 질의는 몇 시간 전의 결과를 반환한다. 이 문제를 고치는 방법을 곧 설명한다.</p>
<h5 id="1-7-1-일괄처리-계층"><a href="#1-7-1-일괄처리-계층" class="headerlink" title="1.7.1 일괄처리 계층"></a>1.7.1 일괄처리 계층</h5><p>일과처리 계층은 마스터 복제본 ( 거대한 양의 레코드 목록 ) 을 저장하며 그 마스터 데이터 집합에 대한 일괄처리 뷰를 사전 계산한다.</p>
<p>일과처리 계층은은 두 가지를 할 수 있어야한다.</p>
<ol>
<li>불변성을 지니며 증가만 하는 마스터 데이터 집합을 저장</li>
<li>그 데이터 집합에 대해 임의의 함수를 계산</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">function runBatchLayer() :</span><br><span class="line">	while(true) : </span><br><span class="line">		recomputeBatchViews()</span><br></pre></td></tr></table></figure>

<p>일괄처리 계층은 while(tue) 루프 내에서 실행되며 지속적으롤 일괄처리 뷰를 만들어낸다. </p>
<h5 id="1-7-2-서빙-계층"><a href="#1-7-2-서빙-계층" class="headerlink" title="1.7.2 서빙 계층"></a>1.7.2 서빙 계층</h5><p>서빙 계층은 일괄처리 뷰를 로딩해서 무작위 읽기를 수행할 수 있도록 하는 특수한 분산 데이터베이스이다. 새로운 일괄 처리 뷰가 생기면 서빙 계층은 자동으로 일괄처리 뷰를 교체해서 더 새로운 결과를 얻을 수 있도록 한다.</p>
<p>일괄 갱신과 무작위 읽기를 모두 지원한다. 주목할 점은, 무작위 쓰기는 지원할 필요가 없다. 데이터베이스에서 대부분의 복잡성은 무작위 쓰기에 의해 유발되므로 이 점은 아주 중요하다.</p>
<h5 id="1-7-3-속도-계층"><a href="#1-7-3-속도-계층" class="headerlink" title="1.7.3 속도 계층"></a>1.7.3 속도 계층</h5><p>속도 계층은 애플리케이션에 필요한 만큼 빠르게 새로운 데이터가 질의 함수에 반영되로록 보장한다. 일괄처리 계층은 한 번에 모든 데이터를 대상으로 하지만, 속도 계층은 최근 데이터만을 대상으로 한다. 새로운 데이터를 받을 때마다 실시간 뷰를 갱신한다. </p>
<p>즉, 람다 아키텍쳐는 다음과 같다.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">batch view &#x3D; function(all data)</span><br><span class="line">realtime view &#x3D; function(realtime view, all data)</span><br><span class="line">query &#x3D; function(batch view, realtime view)</span><br></pre></td></tr></table></figure>

<p>속도 계층은 무작위 읽기와 무작위 쓰기를 지원하는 데이터베이스를 사용한다. 무작위 쓰기를 지원하기 때문에 다른 계층의 데이터베이스보다 복잡하다.</p>
<p>하지만, 람다 아키텍쳐에서는 데이터가 일괄처리 계층을 거쳐 서빙 계층에 도착하면 실시간 뷰에 있던 해당 데이터의 결과는 더 이상 필요없어진다. 즉, 실시간 뷰가 필요없어지면 버릴 수 있다. 이것이 복잡성 고립이다. 그 처리 결과가 그냥 일시적으로 쓰이고 마는 계층에만 복잡성이 가해진다는 것이다.</p>
<p>일괄 처리 계층에서는 정확한 결과를 얻는 알고리즘을 사용하고, 속도 계층에서는 근사 알고리즘 ( ex : 하이퍼로그로그 ) 을 사용하는 유연성을 얻는다. 일괄 처리 계층은 속도 계층을 무효화하므로 근사치는 정확한 값으로 고쳐지게 된다. 시스템은 최종적 정확성 이라는 속성을 지니게 된다.</p>
<hr>
<p>빅데이터, 람다 아키텍처로 알아보는 실시간 빅데이터 구축의 핵심 원리와 기법 &lt;네이선 마츠, 제임스 워렌&gt;</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-01-04T15:00:00.000Z" title="2020-01-04T15:00:00.000Z">2020-01-05</time><span class="level-item"><a class="link-muted" href="/categories/big-data/">Big Data</a></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/01/05/big-data-chapter5/">[빅데이터를 지탱하는 기술] 5장_빅데이터 파이프라인</a></h1><div class="content"><h2 id="1-워크-플로우-관리"><a href="#1-워크-플로우-관리" class="headerlink" title="1. 워크 플로우 관리"></a>1. 워크 플로우 관리</h2><h5 id="기초-지식"><a href="#기초-지식" class="headerlink" title="기초 지식"></a>기초 지식</h5><ol>
<li><p>워크 플로우 관리 도구</p>
<p>워크 플로우 관리 도구의 주요 역할은, 정기적으로 태스크를 실행하고 비정상적인 상태를 감지하여 해결을 돕는 것이다.</p>
<p>ex) Airflow, Azkaban, Digdag, Luigi, Oozie</p>
</li>
<li><p>태스크</p>
<p>데이터 파이프라인의 실행 과정에서 데이터를 잇달아 이동하면서 정해진 처리를 반복하는데, 이때 실행되는 개별 처리이다.</p>
</li>
<li><p>기본 기능</p>
<ul>
<li><p>테스크를 정기적인 스케쥴로 실행하고 결과 통지</p>
</li>
<li><p>테스크 간의 의존 관계를 정하고 순서대로 빠지없이 실행</p>
</li>
<li><p>테스크의 실행 결과를 보관하고, 오류 발생하면 재실행 할 수 있도록 하기</p>
</li>
</ul>
</li>
<li><p>선언 형과 스크립트 형</p>
<ul>
<li>선언형 : XML 이나 YAML 등의 서식으로 워크플로우 기술</li>
<li>스크립트형 : 스크립트 언어로 워크플로우 정의</li>
</ul>
</li>
</ol>
<h5 id="오류로부터-복구-방법"><a href="#오류로부터-복구-방법" class="headerlink" title="오류로부터 복구 방법"></a>오류로부터 복구 방법</h5><p>모든 오류를 사전에 예상하는 것은 불가능하기 때문에, 오류 발생 가능성을 고려하여 대처 방법을 결정해야한다.</p>
<ol>
<li><p>Retry</p>
<p>재시도를 반복해도 문제가 없는 태스크라면, 1회나 2회의 재시도를 실행해도 좋다.</p>
<p>그러나, 그 이상은 재시도가 아니라 올바른 문제 해결 방법을 찾아야한다.</p>
</li>
<li><p>Backfill</p>
<p>플로우 전체를 처음부터 다시 실행한다. 다음 상황에 사용한다.</p>
<ul>
<li>태스크의 실패가 며칠 동안이나 계속된 후에 이를 모아서 재시도 하고 싶을 때</li>
<li>새롭게 만든 워크 플로우를 과거로 거슬라 올라가 실행하고 싶을 때</li>
</ul>
</li>
</ol>
<h5 id="재실행의-안정성을-위한-두가지-방법"><a href="#재실행의-안정성을-위한-두가지-방법" class="headerlink" title="재실행의 안정성을 위한 두가지 방법"></a>재실행의 안정성을 위한 두가지 방법</h5><ol>
<li><p>원자성 조작 (Atomic Operation)</p>
<p>예를 들어, INSERT 문 2회를 호출하는 태스크가 있다고 하자.</p>
<p>첫 번째의 INSERT 가 종료되고 오류가 발생하면 태스크를 재실행하면 동일한 데이터가 다시 쓰이게 될 수 있다.</p>
<p>이 문제를 회피하기 위해, 각 태스크가 <code>시스템에 변경을 가하는 것을 한 번만 할 수 있도록</code> 하는 것이다.</p>
<p>쓰기가 필요한 수 만큼 테스크를 나누는 것이다. </p>
<p>하지만, 태스크 구현상의 버그 등으로 원자성 조작 직후에 문제가 발생하면 원자성 조작 자체는 성공했어도 워크 플로우 관리 도구에서는 오류로 여길 수 있다.</p>
</li>
<li><p>멱등한 조작</p>
<p>더 확실한 방법은, <code>동일한 태스크를 여러 번 실행해도 동일한 결과</code>가 되도록 하는 것이다.</p>
<p>예를 들어 분산 스토리지에 파일을 업로드할 때, </p>
<ul>
<li>매번 새로운 파일명을 만들 경우 데이터를 추가 (append) 하는 것이고, </li>
<li>동일 파일명으로 덮어쓰면 치환 (replace)하는 것이다. 치환은 반복해도 결과가 변하지 않으므로 멱등하다.</li>
</ul>
</li>
</ol>
<h5 id="데이터-추가"><a href="#데이터-추가" class="headerlink" title="데이터 추가"></a>데이터 추가</h5><ol>
<li><p>멱등한 추가</p>
<p>과거의 모든 데이터를 치환하면 멱등하지만 부하가 커진다. 그래서, Table Partitioning 이 필요하다.</p>
<p>예를 들면 테이블을 1일마다 또는 1시간 마다 파티션으로 분할하고 파티션 단위로 치환하는 것이다.</p>
<p>파티션의 모든 데이터를 삭제할 때, TRUNCATE 문이나 INSESRT OVERWRITER 문 등을 사용할 수 있다.</p>
<p>ex) Hive 는 파티셔닝 지원, Amazon Redshift 는 파티셔닝을 지원하지 않아 UNION ALL 사용</p>
</li>
<li><p>원자성을 지닌 추가</p>
<p>하나의 테이블에 여러번 데이터를 써넣는 경우, 중간 테이블을 이용해 마지막에 목적 테이블에 한 번 추가한다.</p>
<p>즉, 전반 부분에서는 중간 테이블을 만들기 위해 테이블을 치환하므로 멱등하다.</p>
<p>그러나 마지막에 INSESRT 는 단순히 추가이므로 전체로서는 멱등하지 않다.</p>
<p>단, 마지막에 쓰기를 1회만 실시하므로 이것은 원자성을 지닌 조작이다. </p>
<p>그래서 플로우가 실패해도 아무것도 쓰이지 않아 실패한 태스크를 재실행해도 복구가 완료된다.</p>
</li>
</ol>
<h5 id="워크-플로우-전체를-멱등하게-하기"><a href="#워크-플로우-전체를-멱등하게-하기" class="headerlink" title="워크 플로우 전체를 멱등하게 하기"></a>워크 플로우 전체를 멱등하게 하기</h5><p>재실행의 안정성을 위해서는, 멱등하게 구현해야한다.</p>
<p><img src="/image/big_data_workflow_idemponent.png" alt=""></p>
<h5 id="Task-Queue-자원의-소비량-컨트롤"><a href="#Task-Queue-자원의-소비량-컨트롤" class="headerlink" title="Task Queue : 자원의 소비량 컨트롤"></a>Task Queue : 자원의 소비량 컨트롤</h5><p>대량의 테스크를 동시 실행하면 서버에 과부하가 걸리므로 어느 정도 제한 해야한다.</p>
<p>워크 플로우 관리 도구는, 태스크의 크기나 동시 실행 수를 변화시켜 자원의 소비량을 조정해 모든 태스크가 원활하게 실행되도록 할 수 있다. </p>
<p>이 때, Job Queue 또는 Task Queue 를 사용할 수 있다. </p>
<p>모든 태스크는 큐에 저장되고 일정 수의 워커 프로세스가 순서대로 꺼내며 병렬화가 실현된다.</p>
<h2 id="2-배치-형-데이터-플로우"><a href="#2-배치-형-데이터-플로우" class="headerlink" title="2. 배치 형 데이터 플로우"></a>2. 배치 형 데이터 플로우</h2><h5 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h5><p><img src="/image/big_data_workflow_mapreduce.png" alt=""></p>
<p>데이터 처리 첫 번째 단계를 Map, 그 결과를 모아서 집계하는 두 번째 단계를 Reduce 라고 한다.</p>
<p>이렇게 Map 과 Reduce 를 반복하면서 목적하는 결과를 얻을 때 까지 계속 데이터를 변화하는 구조가 MapReduce 이다.</p>
<p>MapReduce 는 Map 과 Reduce 의 하나의 사이클이 끝나지 않으면 다음 처리로 이동하지 않는다. 즉, 하나의 사이클에서 다음 사이클로 이동할 때 까지 대기 시간이 발생한다.</p>
<h5 id="데이터-플로우"><a href="#데이터-플로우" class="headerlink" title="데이터 플로우"></a>데이터 플로우</h5><p>이전의 MapReduce 를 사용한 데이터 처리에서는, MapReduce 프로그램을 워크플로우의 태스크로 등록해 다단계의 복잡한 데이터 처리를 할 수 있었다.</p>
<p>현재는, 다단계의 데이터 처리를 분산 시스템 내부에서 실행할 수 있다. 이것을 데이터 플로우라고 한다. </p>
<p>ex) 데이터 플로우를 위한 프레임워크 :  Google Cloud Dataflow, Apache Spark, Apache Flick</p>
<h5 id="MapReduce-를-대신할-세로운-프레임워크"><a href="#MapReduce-를-대신할-세로운-프레임워크" class="headerlink" title="MapReduce 를 대신할 세로운 프레임워크"></a>MapReduce 를 대신할 세로운 프레임워크</h5><p>세로운 프레임워크의 공통 특징은 DAG (Direct Acyclic Graph) 이다.</p>
<p>다음 두 가지 성질이 있다.</p>
<ol>
<li>방향성 : 노드와 노드가 화살표로 연결</li>
<li>비순환 : 화살표를 따라가도 동일 노드로 돌아오지 않음</li>
</ol>
<p>DAG 관점에서 MapReduce 와 데이터 플로우의 차이는,</p>
<ol>
<li><p>MapReduce</p>
<p>MapReduce 도 Map 과 Reduce 의 두 종류 노드로 이루어진 DAG 라 생각할 수 있다. </p>
<p>하지만, 하나의 노드에서 처리가 끝나지 않으면 다음 처리로 진행할 수 없다.</p>
</li>
<li><p>데이터플로우</p>
<p>DAG 를 구성하는 노드가 모두 동싱 병행으로 실행된다.</p>
<p>처리가 끝난 데이터는 네트워크를 거쳐 차례대로 전달된다. </p>
<p>먼저 데이터 파이프라인 전체를 DAG 로 조립한 뒤 실행해서, 내부 스캐쥴러가 분산 시스템에 효과적인 실행 계획을 세운다.</p>
</li>
</ol>
<h5 id="데이터-플로우와-워크플로우-조합하기"><a href="#데이터-플로우와-워크플로우-조합하기" class="headerlink" title="데이터 플로우와 워크플로우 조합하기"></a>데이터 플로우와 워크플로우 조합하기</h5><p>테스크를 정기적으로 실행하거나 실패한 테스크를 기록하여 복구하는 것은, 데이터플로우가 아니라 워크 플로우의 관리가 필요하다. 따라서, 데이터 플로우의 프로그램도 워크 플로우의 일부로 실행되는 하나의 태스크로 고려될 수 있다.</p>
<ol>
<li><p>데이터를 읽어들이는 플로우</p>
<p><img src="/image/big_data_workflow_store.png" alt=""></p>
<p>데이터 플로우로부터 읽어 들일 데이터는 성능적으로 안정된 분산 스토리지에 배치해야한다. 외부의 데이터 소스에서 데이터를 읽어들일 때는 읽기 속도에 한계가 있으므로 데이터 플로우를 사용한다고 해도 빨라진다고 단언할 수 없다.</p>
<p><img src="/image/big_data_workflow_after_store.png" alt=""></p>
<p>분산스토리지로 데이터 복사가 완료되면 데이터 플로우로 처리한다.</p>
</li>
<li><p>데이터를 써서 내보내는 워크플로우</p>
<p>데이터 플로우 안에서 대량의 데이터를 외부에 전송해서는 안된다. 왜냐하면,</p>
<ul>
<li><p>쓰기 작업에 오래 걸리면, 실행이 완료되지 않아 자원을 계속해서 소비 할 수 있다.</p>
</li>
<li><p>최악의 경우, 쓰기 작업이 실패해 처음부터 다시 데이터 처리를 재실행 해야 할 수 있다.</p>
</li>
</ul>
<p>그래서, 데이터 플로우는 CSV 파일과 같이 취합하기 쉬운 형식으로 분산 스토리지에 넣는 것 까지한다. </p>
<p>외부 시스템에 데이터를 전송하는 것은 워크 플로우의 역할이다. </p>
<ul>
<li><p>벌크 형 전송 도구를 사용해 태스크를 구현하거나</p>
</li>
<li><p>외부 시스템쪽에 파일을 읽어들이도록 지시한다.</p>
</li>
</ul>
<p><img src="/image/big_data_workflow_write.png" alt=""></p>
</li>
</ol>
<h5 id="데이터-플로우와-SQL-을-나누어-사용하기"><a href="#데이터-플로우와-SQL-을-나누어-사용하기" class="headerlink" title="데이터 플로우와 SQL 을 나누어 사용하기"></a>데이터 플로우와 SQL 을 나누어 사용하기</h5><p><img src="/image/big_data_workflow_sql.png" alt=""></p>
<ol>
<li><p>SQL을 MPP 데이터베이스에서 실행</p>
<p>데이터웨어하우스의 파이프라인 </p>
<p>로드되는 데이터를 만드는 부분까지가 데이터 플로의 역할</p>
</li>
<li><p>SQL을 분산 시스템 상의 쿼리 엔진에서 실행 </p>
<p>데이터마트의 파이프라인</p>
<p>구조화된 데이터를 만드는 부분까지가 데이터플로우의 역할</p>
</li>
</ol>
<h2 id="3-스트리밍-형-데이터-플로우"><a href="#3-스트리밍-형-데이터-플로우" class="headerlink" title="3. 스트리밍 형 데이터 플로우"></a>3. 스트리밍 형 데이터 플로우</h2><h5 id="배치-처리와-스트림-처리"><a href="#배치-처리와-스트림-처리" class="headerlink" title="배치 처리와 스트림 처리"></a>배치 처리와 스트림 처리</h5><p><img src="/image/big_data_workflow_stream.png" alt=""></p>
<ol>
<li><p>배치 처리</p>
<p>도달한 데이터를 우선 분산 스토리지에 보관한다.</p>
<p>데이터가 영속적으로 보관되기 때문에 몇 번이고 재실행 가능하다. </p>
<p>집계 효율이 높은 열 지향 스토리지를 구축할 수 있다. </p>
<p>실행 시에 데이터 양이 정해지기 때문에 유한 데이터 (bounded data)</p>
</li>
<li><p>스트림 처리</p>
<p>데이터 도달과 동시에 처리가 시작된다.</p>
<p>재실행하는 것은 고려하지 않는다.</p>
<p>처리한 결과는 시계열 데이터에 적합한 데이터 스토어에 보관하거나 실시간 시스템에 전송한다.</p>
<p>제한 없이 데이터가 보내지기 때문에 무한 데이터 (unbounded data)</p>
<p>ex) Spark Streaming</p>
</li>
</ol>
<h5 id="스트림-처리에-의한-1차-집계"><a href="#스트림-처리에-의한-1차-집계" class="headerlink" title="스트림 처리에 의한 1차 집계"></a>스트림 처리에 의한 1차 집계</h5><p><img src="/image/big_data_workflow_stream_first.png" alt=""></p>
<p>분산 스토리지에도 성능 상이나 비용 상의 한계가 있다.</p>
<p>데이터 양이 많아 한계를 넘어서면, 스트림 처리를 사용해 흐름량을 줄일 수 있다.</p>
<h5 id="스트림-처리의-두-가지-문제에-대한-대처"><a href="#스트림-처리의-두-가지-문제에-대한-대처" class="headerlink" title="스트림 처리의 두 가지 문제에 대한 대처"></a>스트림 처리의 두 가지 문제에 대한 대처</h5><p>스트림 처리의 문제 두 가지가 있다.</p>
<ol>
<li><p>틀린 결과를 어떻게 수정할 것인가</p>
<p>새롭게 도달한 데이터만 처리한다.</p>
</li>
<li><p>늦게 전송된 데이터 취급을 어떻게 할 것인가</p>
<p>집계가 종료된 후에 도착한 데이터가 있어서, 스트림 처리의 결과가 부정확해질 수 있다.</p>
</li>
</ol>
<p>이 문제 해결을 위해, 스트림 처리와 별개로 배치 처리를 실행시켜 배치 처리의 결과가 옳다고 할 수 있다.</p>
<p>예를 들어, 일별 보고서를 속보 값으로 하고 월별 보고서를 확정값으로 분류하는 것이다.</p>
<p>이를 발전 시킨 방법이 람다 아키텍쳐, 람다 아키텍쳐를 단순화한 카파 아키텍쳐가 있다.</p>
<ol>
<li><p>람다</p>
<p><img src="/image/big_data_workflow_lamda.png" alt=""></p>
<p>세 레이어로 구성된다.</p>
<ul>
<li><p>배치 레이어</p>
<p>모든 데이터는 배치 레이어에서 처리한다. 대규모 배치 처리를 위해 실행하며 1회 처리가 오래 걸린다.</p>
</li>
<li><p>서빙 레이어</p>
<p>배치 처리 결과는 서빙 레이어를 통해 접근한다. 응답이 빠른 데이터베이스를 설치해서 집계 결과를 바로 추출한다. </p>
<p>서빙 레이어에서 얻어진 결과를 배치 뷰 라고 한다. 정기적으로 업데이트 되지만 실시간 정보는 얻을 수 없다.</p>
</li>
<li><p>스피드 레이어</p>
<p>스피드 레이어에서 얻은 결과를 실시간 뷰라고 한다. 배치 뷰가 업데이트 될 동안에만 이용되고 오래된 데이터를 순서대로 삭제된다.</p>
</li>
</ul>
<p>배치뷰와 실시간 뷰를 조합시키는 형태로 쿼리를 실행한다. 최근 24시간 집계 결과는 실시간 뷰를 참고하고 그 이전 데이터는 배치뷰를 이용할 수 있다. </p>
<p>실시간 뷰의 결과는 나중에 배치 뷰로 치환된다. 그래서 스트림 처리가 정확하지 않아도 길게 보면 문제가 없다.</p>
</li>
<li><p>카파</p>
<p>람다 아키텍쳐는 스피드 레이어와 배치 레이어가 모두 같은 처리를 구현하고 있으므로 번거롭다.</p>
<p>그래서, 카파 아키테쳐는 스피드 레이어만 남긴다. 대신, 메세지 브로커의 데이터 보관 기한을 길게하여 문제 발생시 메세지 배송 시간을 과거로 다시 설정한다. 그러면 과거의 데이터가 다시 스트림 처리로 흘러 들어 실질적으로 재실행이 이루어진다.</p>
<p>문제점은, 부하가 높아진다는 것이다. 대량의 과거 데이터를 흘려보내면 평상시와 비교해 몇 배의 자원을 소비하기 때문이다. 클라우드 서비스 보급에 그런 자원을 확보하는 것이 어렵지 않으므로 필요에 따라 스트림 처리를 다시 하는것이 간단하는 것이 카파 아키텍쳐의 주장이다.</p>
</li>
</ol>
<h5 id="Out-of-Order-의-데이터-처리"><a href="#Out-of-Order-의-데이터-처리" class="headerlink" title="Out of Order 의 데이터 처리"></a>Out of Order 의 데이터 처리</h5><p><img src="/image/big_data_workflow_out_of_order.png" alt=""></p>
<p>스트림 처리를 할때 늦게 도달한 메세지, 즉 프로세스 시간과 이벤트 시간의 차이는, 이벤트 시간 윈도윙으로 해결한다.</p>
<p>즉, 이벤트 시간에 의해 윈도우를 나누는 것이다. </p>
<p>메세지가 배송된 데이터는 무작위 순이기 때문에 적절히 순서를 바꿔 집계 결과를 업데이트해야한다.</p>
<p>데이터가 도달할 때마다 해당하는 윈도우를 재집계한다. 데이터를 무한히 계속 보관할 수 없으므로 일정 이상 늦게 온 데이터는 무시한다.</p>
<hr>
<p>빅데이터를 지탱하는 기술 &lt;니시다 케이스케&gt;</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-01-01T15:00:00.000Z" title="2020-01-01T15:00:00.000Z">2020-01-02</time><span class="level-item"><a class="link-muted" href="/categories/big-data/">Big Data</a></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/01/02/big-data-chapter4/">[빅데이터를 지탱하는 기술] 4장_빅데이터 축적</a></h1><div class="content"><h2 id="1-벌크-형과-스트리밍-형의-데이터-수집"><a href="#1-벌크-형과-스트리밍-형의-데이터-수집" class="headerlink" title="1. 벌크 형과 스트리밍 형의 데이터 수집"></a>1. 벌크 형과 스트리밍 형의 데이터 수집</h2><p>데이터 수집 방법으로 두 가지 방법이 있다.<br>이 챕터에서는 각각의 방법으로, 분산 스토리지에 데이터가 저장되기까지의 흐름을 정리한다.</p>
<ol>
<li>벌크 형</li>
<li>스트리밍 형</li>
</ol>
<h5 id="객체-스토리지와-데이터-수집"><a href="#객체-스토리지와-데이터-수집" class="headerlink" title="객체 스토리지와 데이터 수집"></a>객체 스토리지와 데이터 수집</h5><p>빅데이터는 확장성이 높은 분산 스토리지에 저장된다. 분산 스토리지로,</p>
<ol>
<li><p>분산형 데이터베이스</p>
</li>
<li><p>객체 스토리지<br>객체 스토리지는 다수의 컴퓨터를 사용해 파일을 여러 디스크에 복사해서 데이터 중복화 및 부하 분산을 실현한다.<br>객체 스토리지의 구조는 데이터 양이 많을 때는 우수하지만, 소량의 데이터에 대해서는 비효율적이다.<br>하둡의 HDFS, 클라우드 서비스의 Amazon S3 가 대표적이다.</p>
</li>
</ol>
<h5 id="데이터-수집"><a href="#데이터-수집" class="headerlink" title="데이터 수집"></a>데이터 수집</h5><p>데이터 수집이란, 수집한 데이터를 가공해 집계 효율이 좋은 분산 스토리지를 만드는 일련의 프로세스이다.<br>작은 데이터는 적당히 모아서 하나의 큰 파일로 만들어 효율을 높이는데 도움이 된다.<br>파일이 지나치게 크면, 네트워크 전송 시간이 오래 걸려 오류 발생률이 높다. </p>
<h5 id="벌크-형-데이터-전송"><a href="#벌크-형-데이터-전송" class="headerlink" title="벌크 형 데이터 전송"></a>벌크 형 데이터 전송</h5><p><img src="/image/big_data_bulk_data.png" alt=""></p>
<p>전통적인 데이터 웨어하우스에서는 주로 벌크 형 방식으로 데이터베이스나 파일 서버 또는 웹 서비스 등에서 각각의 방식 (SQL, API …) 으로 정리해 데이터를 추출한다.<br>처음부터 분산 스토리지에 데이터가 저장되어 있지 않으면 데이터 전송을 위한 ETL 서버를 설치한다.<br><code>데이터 전송의 신뢰성이 중요하면 벌크형 도구를 사용하는 것이 좋다.</code></p>
<h5 id="파일-사이즈의-적정화"><a href="#파일-사이즈의-적정화" class="headerlink" title="파일 사이즈의 적정화"></a>파일 사이즈의 적정화</h5><p>ETL 프로세스는 하루마다 또는 한시간 마다의 간격으로 정기적인 실행을 하므로 그 동안 축적된 데이터는 하나로 모인다.<br>데이터 양이 많을 때는 한 달씩이나 하루 단위로 전송하도록 작은 태스크로 분해해 한 번의 태스크 실행이 커지지 않도록 조정해야한다.<br>워크 플로우 관리 도구를 사용하면 쉽게 관리 할 수 있다.</p>
<h5 id="스트리밍-형의-데이터-전송"><a href="#스트리밍-형의-데이터-전송" class="headerlink" title="스트리밍 형의 데이터 전송"></a>스트리밍 형의 데이터 전송</h5><p><img src="/image/big_data_message_delivery.png" alt=""></p>
<p><code>계속해서 전송되어 오는 작은 데이터를 취급하기 위한 데이터 전송</code>이다.<br>이러한 데이터 전송은 다수의 클라이언트에서 계속 작은 데이터가 전송된다. 이러한 데이터 전송 방식이 메세지 배송 (Message Delivery) 이다.<br>보내온 메세지를 저장하는 방법으로,</p>
<ol>
<li><p>NoSQL 데이터베이스<br>Hive 와 같은 쿼리 엔진으로 NoSQL 데이터베이스에 연결해 데이터를 읽을 수 있다. </p>
</li>
<li><p>Message Queue<br>데이터를 일정 간격으로 꺼내고 모아서 분산 스토리지에 저장한다.</p>
</li>
</ol>
<h5 id="웹-브라우저에서-메세지-배송"><a href="#웹-브라우저에서-메세지-배송" class="headerlink" title="웹 브라우저에서 메세지 배송"></a>웹 브라우저에서 메세지 배송</h5><p><img src="/image/big_data_message_web_browser.png" alt=""></p>
<ol>
<li><p>상주형 로그 수집 소프트웨어<br>자체 개발한 웹 애플리케이션 등에서는 웹 서버 안에서 메세지를 만들어서 배송한다. <code>전송 효율을 높이기 위해 서버상에서 일단 데이터를 축적해 놓고 나중에 모아서 보내는 경우</code>가 있다.<br>이 때, Fluentd 나 Logstash 같은 상주형 로그 수집 소프트웨어가 자주 사용된다.</p>
</li>
<li><p>웹 이벤트 추적<br>자바스크립트를 이용해 웹 브라우에서 직접 메세지를 보내는 경우도 있다.</p>
</li>
</ol>
<h5 id="모바일-앱에서-메세지-배송"><a href="#모바일-앱에서-메세지-배송" class="headerlink" title="모바일 앱에서 메세지 배송"></a>모바일 앱에서 메세지 배송</h5><p><img src="/image/big_data_message_mobile.png" alt=""></p>
<ol>
<li><p>MBaaS<br>모바일 앱에서는 서버를 직접 마련하는 것이 아니라, MBaaS (Mobile Backend as a Serivce) 라는 백엔드의 각종 서비스를 이용할 수 있다. </p>
</li>
<li><p>SDK<br>모바일 앱이 오프라인이 되었을 때는 발생한 이벤트를 SDK 내부에 축적하고 온라인 상태 되었을 때 모아서 보낼 수 있다.</p>
</li>
</ol>
<h5 id="디바이스에서-메세지-배송"><a href="#디바이스에서-메세지-배송" class="headerlink" title="디바이스에서 메세지 배송"></a>디바이스에서 메세지 배송</h5><p><img src="/image/big_data_message_device.png" alt=""></p>
<p>MQTT (MQ Telemetry Transport) 는 TCP/IP 를 이용하여 데이터 전송하는 프로토콜 중 하나이다. 일반적으로 Pub/Sub 메세지 배송 구조이다. </p>
<h5 id="메세지-배송의-공통화"><a href="#메세지-배송의-공통화" class="headerlink" title="메세지 배송의 공통화"></a>메세지 배송의 공통화</h5><p>메세지가 처음 생성되는 기기를 클라이언트, 해당 메세지를 먼저 받는 서버를 프론트엔드라고 한다.<br>프론트 엔드는 단지 데이터를 받는 것에 전념하고, 그 이후의 문제는 백엔드의 공통 시스템에 맡길 수 있다.</p>
<h2 id="2-성능-신뢰성-메세지-배송의-트레이드오프"><a href="#2-성능-신뢰성-메세지-배송의-트레이드오프" class="headerlink" title="2. 성능, 신뢰성 : 메세지 배송의 트레이드오프"></a>2. 성능, 신뢰성 : 메세지 배송의 트레이드오프</h2><p>이 챕터는 메세지 브로커를 중심으로 메세지 배송 구조와 한계를 정리한다.</p>
<h5 id="메세지-브로커"><a href="#메세지-브로커" class="headerlink" title="메세지 브로커"></a>메세지 브로커</h5><p>메세지 배송에 의해 보내진 데이터를 분산 스토리지에 저장할 때, 데이터 양이 적을 때는 문제가 되지 않지만 쓰기의 빈도가 증가하면 디스크 성능의 한계에 도달해 더 쓸 수 없게 될 우려가 있다.<br><code>대량의 메세지를 안정적으로 받기 위해서는 빈번한 쓰기에도 견딜 수 있는 성능이 높고, 필요에 따라 성능을 얼마든지 올릴 수 있는 스토리지가 필요</code>하다.<br><code>분산 스토리지가 반드시 이 성격을 가질 수 있다고 할 수 없기 때문에, 메세지를 일시적으로 축적하는 중산층이 설치</code>된다. 이것이 메세지 브로커이다.<br>ex) Apache Kafka, Amazon Kinesis</p>
<h5 id="push-형-pull-형"><a href="#push-형-pull-형" class="headerlink" title="push 형, pull 형"></a>push 형, pull 형</h5><p>송신 측의 제어로 데이터를 보내는 방식을 push 형, 수신 측 주도로 데이터를 가져오는 것을 pull 형이라고 한다.<br>메세지 브로커에 데이터를 push 하는 것을 producer, pull 하는 것을 consumer 라고 한다.<br>push 형의 메세지 배송은 모두 메세지 브로커에 집중 시키고 거기에서 일정한 빈도로 꺼낸 데이터를 분산 스토리지에 기록한다.<br>또한, pull 형의 메세지 배송은 파일 사이즈 적정화에도 도움이 된다. consumer 는 메세지 브로커로부터 일정한 간격으로 데이터를 취해 적당히 모아진 데이터를 분산 스토리지에 저장한다.</p>
<h5 id="메세지-라우팅"><a href="#메세지-라우팅" class="headerlink" title="메세지 라우팅"></a>메세지 라우팅</h5><p>메세지 브로커에 써넣은 데이터는 다수의 다른 consumer 에서 읽을 수 있다. 이를 통해 메세지가 복사되어 데이터를 여러 경로로 분기 시킬 수 있다. 이것이 메세지 라우팅이다.<br>예를 들어, 메세지 일부를 실시간 장애 감지를 사용하면서, 같은 메세지를 장기적인 데이터 분석을 위한 분산 스토리지에 저장하는 것도 가능하다.</p>
<h5 id="메세지-배송-신뢰성-문제와-세-가지-설계-방식"><a href="#메세지-배송-신뢰성-문제와-세-가지-설계-방식" class="headerlink" title="메세지 배송 신뢰성 문제와 세 가지 설계 방식"></a>메세지 배송 신뢰성 문제와 세 가지 설계 방식</h5><p>대부분의 경우 다음 중 하나를 보장하도록 설계된다.</p>
<ol>
<li><p>at most once<br>기껏해야 한 번.<br>메세지는 한 번만 전송된다. 도중에 전송 실패로 사라질 가능성이 있다.</p>
</li>
<li><p>exactly once<br>정확히 한 번.<br>메세지는 손실 되거나 중복 없이 한 번만 전달된다.<br>네트워크 상에 두 개의 노드가 있는 경우 양쪽의 통신 내용을 보장하기 위해 coorninator 가 필요하다. 문제가 생기면 송신 측과 수신 측 모두 서로의 정보를 코디네이터에게 전달해서 문제가 발생하면 코디네이터의 지시에 따라 해결할 수 있다.<br>그러나 분산 시스템에서는 코디네이터와의 통신이 끊길 수 있고 코데네이터가 정지될 수도 있다. 따라서 코디네이터의 부재 시에 어덯게 할 것인지에 대한 consensus 가 필요하다. 보통, 단시간 장애 가능성은 받아 들인다.<br>또한, 코디네이터의 판단에만 따르고 있으면 시간이 너무 소요된다.<br>그래서 메세지 배송 시스템에서는 코디네이터를 도입하지 않고 at least once 를 따른다. </p>
</li>
<li><p>at least once<br>최소한 한 번.<br>메세지는 확실히 전달된다. 단, 같은 것이 여러번 전달될 가능성이 있다.<br>메세지가 재전송되어도 그것을 없앨 수 있는 구조가 있으면 보기에 중복이 없는 것처럼 할 수 있다. 이러한 구조를 ‘중복 제거’ 라고 한다.<br>예를 들어, TCP 는 메세지 수신 확인을 위해 ‘ack’ 플래그를 도입했다. 메세지 재전송에 의한 중복이 발생하지만, 모든 TCP 패킷에서는 이것을 식별하는 시퀀스 번호를 이용해 중복 제거가 이뤄진다.<br>대부분의 메세지 배송 시스템은 at least once 를 보장하는 한편, 중복 제거는 이용자에게 맡기고 있어서 TCP/IP 처럼 자동으로 중복을 제거해주지 않는다. (ex) Apache Kafka, Apache Flume, Logstash</p>
</li>
</ol>
<h5 id="중복-제거는-높은-비용의-오퍼레이션"><a href="#중복-제거는-높은-비용의-오퍼레이션" class="headerlink" title="중복 제거는 높은 비용의 오퍼레이션"></a>중복 제거는 높은 비용의 오퍼레이션</h5><p>중복 제거 방법으로 다음과 같은 방법이 있다.</p>
<ol>
<li><p>오프셋 이용<br>각 메세지에는 파일 안의 시작 위치 (오프셋) 를 붙인다.<br>메세지가 중복되어도 같은 파일의 같은 장소를 덮어쓸 뿐이므로 문제되지 않는다.<br>벌 크형 데이터 전송과 같이 데이터양이 고정된 경우에 사용한다.</p>
</li>
<li><p>고유 ID 이용<br>모든 메세지에 UUID 등의 고유 ID 를 지정한다.<br>메세지가 늘어남에 따라 ID 가 증가하므로 그것을 어떻게 관리하느냐가 문제이다.<br>스트리밍 형의 메세지 배송에서 자주 사용된다. </p>
</li>
</ol>
<h5 id="End-to-End-신뢰성"><a href="#End-to-End-신뢰성" class="headerlink" title="End to End 신뢰성"></a>End to End 신뢰성</h5><p>클라이언트가 생성한 메세지를 최종 도달 지점인 분산 스토리지에 기록하는 단계에서 중복 없는 상태로 해야한다.<br>중간에 한 부분이라도 at most once 가 있으면 메세지를 빠뜨릴 가능성이 있고, at least once 가 있으면 중복될 수 있다.<br>신뢰성이 높은 메세지 배송을 실현하려면 중간 경로를 모두 at least once 로 통일한 후 클라이언트 상에서 모든 메세지에 고유 ID 를 포함하도록 하고 경로의 말단에서 중복 제거를 실행해야한다.</p>
<h5 id="고유-ID-를-사용한-중복-제거-방법"><a href="#고유-ID-를-사용한-중복-제거-방법" class="headerlink" title="고유 ID 를 사용한 중복 제거 방법"></a>고유 ID 를 사용한 중복 제거 방법</h5><p>두가지 방법이 있다.</p>
<ol>
<li><p>분산 스토리지로 NoSQL 데이터베이스 사용<br>Cassandra 나 Elasticsearch 등은 데이터를 쓸 대 고유 ID 를 지정하게 되어 있어 동일한 ID 의 데이터는 덮어쓴다.</p>
</li>
<li><p>SQL<br>보내온 데이터는 일단 그대로 객체 스토리지 등에 저장하고, 나중에 읽어 들이는 단계에서 중복을 제거한다.<br>Hive 와 같은 배치형 쿼리 엔진에서 실행할 수 있다.</p>
</li>
</ol>
<h5 id="데이터-수집-파이프라인"><a href="#데이터-수집-파이프라인" class="headerlink" title="데이터 수집 파이프라인"></a>데이터 수집 파이프라인</h5><p><img src="/image/big_data_stream_pipeline.png" alt=""></p>
<p>일련의 프로세스를 거쳐 마지막으로 데이터를 구조화해서 열 지향 스토리지로 변환함으로써, 장기간의 데이터 분석에 적합한 스토리가 완성된다. 이것인 데이터 수집 파이프라인이다.<br>실제로 어떤 파이프라인을 만들지는 요구사항에 따라 다르므로, 필요에 따라 시스템을 조합한다.<br>예를 들어, 쓰기 성능에 불안감이 없으면 메세지 브로커가 불필요 하므로 클라이언트에서 직접 NoSQL 데이터베이스에 데이터를 써도 된다. 중복이 허용된다면 중복 제거를 생략할 수 있다.</p>
<h5 id="중복을-고려한-시스템-설계"><a href="#중복을-고려한-시스템-설계" class="headerlink" title="중복을 고려한 시스템 설계"></a>중복을 고려한 시스템 설계</h5><p><code>스트리밍 형의 메세지 배송 방식에서는 중간에 중복 제거 방식을 도입하지 않으면 중복 가능성이 있다고 생각하면 된다.</code><br>신뢰성이 중시되는 경우에는 스트리밍 형의 메세지 배송을 피하는 것이 좋다.<br>예를 들어, 과금 데이터같은 오차가 불허용 되는 경우 트랜잭션 처리를 지원하는 데이터베이스에 직접 애플리케이션이 기록해야한다. 그 후에 벌크 형의 데이터 전송을 함으로써 중복도 결손도 확실히 피해야한다.</p>
<h2 id="3-시계열-데이터의-최적화"><a href="#3-시계열-데이터의-최적화" class="headerlink" title="3. 시계열 데이터의 최적화"></a>3. 시계열 데이터의 최적화</h2><p>스티밍형의 메세지 배송에서는 ‘메세지가 도착할 때까지의 시간 지연’ 이 문제다. 늦게 도달하는 데이터가 집계 속도에 미치는 영향을 정리한다.</p>
<h5 id="프로세스-시간과-이벤트-시간"><a href="#프로세스-시간과-이벤트-시간" class="headerlink" title="프로세스 시간과 이벤트 시간"></a>프로세스 시간과 이벤트 시간</h5><p>다음 두 시간의 차이가 성가신 문제를 일으킨다.</p>
<ol>
<li><p>이벤트 시간<br>클라이언트 상에서 메시지가 생성된 시간. 데이터 분석의 대상은 주로 이벤트 시간</p>
</li>
<li><p>프로세스 시간<br>서버가 처리하는 시간</p>
</li>
</ol>
<h5 id="프로세스-시간에-의한-분할과-문제점"><a href="#프로세스-시간에-의한-분할과-문제점" class="headerlink" title="프로세스 시간에 의한 분할과 문제점"></a>프로세스 시간에 의한 분할과 문제점</h5><p>늦게 도달하는 데이터가 있다는 것은, 과거의 집계 결과가 매일 조금씩 바뀐다는 것을 의미한다. 보다 실제에 가까운 데이터를 얻기 위해서는 ‘이벤트 시간’ 보다 며칠 정도 지난 시점에서 집계해야한다.<br>분산 스토리지에 데이터를 넣는 단계에서는 이벤트 시간이 아니라 프로세스 시간 사용하는 것이 보통이다.<br>예를 들어, 2017년 1월 1일에 도착한 데이터는 ‘20170101’ 과 같은 이름으로 지정한다. 그리고 그 파일에는 이벤트 시간으로 보면 다수의 과거 데이터가 포함된 상태다. 다음 그림과 같다.</p>
<p><img src="/image/big_data_c4_01.png" alt=""></p>
<p>이 상태에서 과거 특정 일에 발생한 이벤트를 집계하고 싶다고 하자. 예를 들어, 1월 1일에 발생한 이벤트면, 그 이후에 만들어진 모든 파일에 포함되어 있을 수 있다.<br>다수의 파일을 모두 검색하는 쿼리를 Full Scan 이라고 한다. 이것이 시스템의 부하를 높이는 요인이다.</p>
<h5 id="시계열-인덱스-이벤트-시간에-의한-집계-효율화-01"><a href="#시계열-인덱스-이벤트-시간에-의한-집계-효율화-01" class="headerlink" title="시계열 인덱스 : 이벤트 시간에 의한 집계 효율화 01"></a>시계열 인덱스 : 이벤트 시간에 의한 집계 효율화 01</h5><p>이벤트 시간 취급을 효율화하기 위해 데이터를 정렬해보자.</p>
<ol>
<li><p>이벤트 시간에 대해 인덱스 만들기<br>RDB 에서 익덴스를 만든것 처럼.<br>Cassandra 와 같은 시계열 인덱스 (time-series index) 에 대응하는 분산 데이터베이스를 이용하면 처음부터 이벤트 시간으로 된 테이블을 만들 수 있다.<br>시계열 인덱스를 사용하면, 매우 짧은 범위의 특정 시간에 맞춘 데이터 집계를 빠르게 실행할 수 있다.<br>정해진 시간에 발생한 이벤트를 조사하거나, 실시간 대시보드를 만드는 경우에 유용하다.</p>
</li>
<li><p>열 지향 스토리지<br>장기간에 걸쳐 대량에 데이터를 집계하는 경우에는 분산 데이터베이스가 효율적이지 않다.<br>장기적인 데이터 분석에는 집계 효율이 높은 열지향 스토리지를 지속적으로 만들어야한다.</p>
</li>
</ol>
<h5 id="조건절-푸쉬다운-이벤트-시간에-의한-집계-효율화-02"><a href="#조건절-푸쉬다운-이벤트-시간에-의한-집계-효율화-02" class="headerlink" title="조건절 푸쉬다운 : 이벤트 시간에 의한 집계 효율화 02"></a>조건절 푸쉬다운 : 이벤트 시간에 의한 집계 효율화 02</h5><p>매일 한 번씩 새로 도착한 데이터를 배치 처리로 변환해보자.<br>열 지향 스토리지에서는 RDB 와 동등한 인덱스를 만들 수 없지만, 처음에 데이터를 정렬할 수 있다. 그래서 다음 그림처럼, 이벤트 시간으로 데이터를 정렬하고 열지향 스토리지로 변환하자.</p>
<p><img src="/image/big_data_c4_02.png" alt=""></p>
<p>열 지향 스토리지는 ‘칼럼 단위의 통계 정보’ 를 이용해 최적화가 이뤄진다. 예를 들어, 시간이면 각 칼럼의 최솟값과 최댓값 등이 모든 파일에 메타 정보로 저장되어 있다. 그런 정보를 참고해 어떤 파일의 어떤 부분에 원하는 데이터가 포함되어 있는지 알 수 있다.</p>
<p>조건절 푸쉬 다운이란, 이 통계를 이용해 필요한 최소한의 데이터를 읽도록 최적화 하는 것이다. 열 지향 스토리지를 만들 때, 가급적 <code>읽어 들이는 데이터 양을 최소화하기 위해 데이터를 정렬해서 조건절 푸쉬다운에 의한 최적화로 풀 스캔을 피한다.</code></p>
<p><img src="/image/big_data_c4_03.png" alt=""></p>
<h5 id="이벤트-시간에-의한-분할"><a href="#이벤트-시간에-의한-분할" class="headerlink" title="이벤트 시간에 의한 분할"></a>이벤트 시간에 의한 분할</h5><p>앞 장에서 테이블을 물리적으로 분리하는 테이블 파티셔닝을 설명했다. 그 중에서도 <code>시간을 이용해 분할된 테이블을 시계열 테이블 이라고 한다.</code> 여기에서는 다음 그림과 같이 이벤트 발생 시간을 파티션의 이름에 포함되도록 한다.</p>
<p><img src="/image/big_data_c4_04.png" alt=""></p>
<p>과거의 이벤트 시간을 갖는 데이터를 드물지만, 몇년에 걸쳐서 보내올 가능성이 있다. 따라서, 시계열 테이블을 구성하는 각 파티션에는 조금씩 데이터가 추가된다.</p>
<p>결과적으로, 분산 스토리지에는 대량의 작은 파일이 만들어지고 점차 쿼리의 성능이 악화된다. 그래서, 이벤트 시간으로부터 시계열 테이블을 만든다면</p>
<ol>
<li>작은 데이터를 효율적으로 추가할 수 있는 데이터베이스를 사용하거나</li>
<li>너무 오래된 데이터는 버리는 아이디어가 필요하다.</li>
</ol>
<h5 id="데이터-마트를-이벤트-시간으로-정렬하기"><a href="#데이터-마트를-이벤트-시간으로-정렬하기" class="headerlink" title="데이터 마트를 이벤트 시간으로 정렬하기"></a>데이터 마트를 이벤트 시간으로 정렬하기</h5><p><img src="/image/big_data_c4_05.png" alt=""></p>
<ol>
<li>데이터 수집 단계에서는 이벤트 시간을 따지지 않고 프로세스 시간만을 사용하여 데이터를 저장한다.</li>
<li>그리고 데이터 마트를 만드는 단계에서 이벤트 시간에 의한 정렬을 한다.</li>
</ol>
<p>그러면, 파일이 조각나는 일이 없고, 항상 최적의 데이터 마트를 유지할 수 있다.</p>
<h2 id="4-비구조화-데이터의-분산-스토리지"><a href="#4-비구조화-데이터의-분산-스토리지" class="headerlink" title="4. 비구조화 데이터의 분산 스토리지"></a>4. 비구조화 데이터의 분산 스토리지</h2><h5 id="NoSQL-데이터베이스에-의한-데이터-활용"><a href="#NoSQL-데이터베이스에-의한-데이터-활용" class="headerlink" title="NoSQL 데이터베이스에 의한 데이터 활용"></a>NoSQL 데이터베이스에 의한 데이터 활용</h5><p>빅데이터를 위한 분산 스토리이지는, 다음이 요구된다.</p>
<ol>
<li><p>확장성<br>필요에 따라 얼마든지 확장할 수 있어야한다.</p>
</li>
<li><p>유연성<br>데이터를 구조화하지 않고도 저장할 수 있어야한다.</p>
</li>
</ol>
<p>기본이 되는 객체 스토리지는,</p>
<ol>
<li><p>장점<br>임의의 파일을 저장할 수 있다.</p>
</li>
<li><p>단점<br>파일을 교체하기 어렵다. 일단 파일으 써넣으면 통째로 교체할 방법이 없다. 로그 파일처럼 나중에 변경할 일이 없는 것은 상관 없지만, 데이터베이스처럼 수시로 변경하는 용도는 적합하지 않다. 특히 중요한 데이터는 트랜잭션 처리가 가능한 데이터베이스에 기록해야한다.</p>
<p>그리고, 객체 스토리지에 저장된 데이터를 집계할 수 있게 되기까지는 시간이 걸린다. 열지향 스토리지를 만듦으로써 집게는 고속화 되지만, 그 작성에 시간이 걸린다. 데이터를 기록하고 바로 활용할 경우 실시간 집계와 검색에 적합한 데이터 저장소가 필요하다.</p>
</li>
</ol>
<p>객체 스토리지의 단점을 해결하기 위한 데이터 저장소를 일컬어 NoSQL 데이터베이스이다. NoSQL 데이터베이스의 예로,</p>
<ol>
<li>분산 KVS</li>
<li>와이드 칼럼 스토어</li>
<li>도큐먼트 스토어</li>
</ol>
<h5 id="분산-KVS"><a href="#분산-KVS" class="headerlink" title="분산 KVS"></a>분산 KVS</h5><p><img src="/image/big_data_c4_06.png" alt=""></p>
<p>모든 데이터를 키값 쌍으로 저장하도록 설게된 데이터 저장소이다.</p>
<p><code>키가 정해지면, 그 값을 클러스터 내의 어느 노드에 배치할 것인지 결정한다. 이 구조에 의해 노드 간에 부하를 균등하게 분산하고 노드를 증감하는 것만으로 클러스터의 성능을 변경할 수 있다.</code></p>
<p>예를 들어, 아마존의 DynamoDB 가 있다. </p>
<ol>
<li><p>분산 아키텍쳐<br>P2P 형의 분산 아키텍쳐를 가지고 있으며, 미리 설정한 초 단위의 요청 수에 따라 노드가 증감되는 특징이 있다. 따라서, 데이터의 읽기 및 쓰기에 지연이 발생하면 곤라한 애플리케이션에 유용하다.</p>
</li>
<li><p>데이터 분석<br>DynamoDB 데이터를 분석하려면, 아마존 EMR, Redshift 등과 결합하여 Hive 에 의한 배치 처리를 실행하거나 데이터 웨어하우스에 데이터를 전송하도록 한다. </p>
</li>
<li><p>스트림 처리<br>DynamoDB 고유 기능인 DynamoDB Streams 를 상요하면 데이터 변경을 이벤트로 외부에 전송해 실시간 스트림 처리가 가능하다.</p>
</li>
</ol>
<p><img src="/image/big_data_c4_066.png" alt=""></p>
<p>일반적으로 NoSQL 데이터베이스는 애플리케이션에서 처음에 데이터를 기록하는 장소로 이용된다. <code>NoSQL 데이터베이스 자체는 대량의 데이터를 집계하는 기능이 없는 것이 많아 데이터 분석을 위해서는 외부로 데이터를 추출</code>해야한다.</p>
<p>단, RDB 등과 비교하면 읽기 성능이 높기 때문에 <code>쿼리 엔진에서 접속해도 성능상의 문제가 발생하기 어렵다.</code> 그래서 애드 혹 분석에서는 데이터를 복사하지 않고 필요시에 직접 연결해서 사용할 수 있다.</p>
<blockquote>
<p>[기초지식] ACID 특성과 CAP 정리</p>
<p>ACID 란 트랜잭션 4 가지 성질로 ‘원시성, 일관성, 독립성, 내구성’이다. 일반적인 RDB 는 이것을 충족하고 있어서 신뢰성있는 트랜잭션 처리를 하고 있다.</p>
<p>하지만, ACID 를 만족하면서 분산 시스템을 구축하기는 어려워서 CAP 정리가 나왔다. 일반적으로 분산 시스템에서는 다음 세가지를 동시에 충족시킬 수 없어 하나가 희생될 수 있다.</p>
<p>CAP 정리 : 일관성, 가용성, 분단내성</p>
<p>NoSQL 데이터베이스의 일부는 CAP 정리의 일관성이나 가용성 중 하나를 선택한다. 즉, 일관성을 우선하고 가용성을 포기하면 단시간의 장애 발생을 수용하는 것이고, 가용성을 우선하고 일관성을 포기하는 것은 오래된 데이터를 읽을 수 있는 것이다. 그 중에서도 결과 일관성이란, ‘써 넣은 데이터를 바로 읽을 수 있다고는 말할 수없다’ 이다.</p>
</blockquote>
<h5 id="와이드-칼럼-스토어"><a href="#와이드-칼럼-스토어" class="headerlink" title="와이드 칼럼 스토어"></a>와이드 칼럼 스토어</h5><p>KVS 를 발전시켜, 2개 이상의 임의의 키에 데이터를 저장할 수 있도록 한 것이다.<br>ex ) Google Cloud Bigtable, Apache HBase, Apache Cassandra<br>하나의 테이블에 가로와 세로의 2차원에 데이터를 쓸 수 있도록 한 것이 특징이다.</p>
<p><img src="/image/big_data_c4_07.png" alt=""></p>
<p>예를 들어, Apache Cassandra 를 살펴보자. </p>
<ol>
<li><p>CQL<br>내부적으로 데이터 저장소로 와이드 칼럼 스토어를이용하면서, CQL 이라는 높은 수준의 쿼리 언어가 구현되어 있다.<br>SQL 동일한 감각으로 테이블을 조작할 수 있다</p>
</li>
<li><p>구조화된 데이터만 취급<br>먼저 테이블의 스키마를 결정할 필요가 있기 때문에, 구조화 데이터만 취급한다.</p>
</li>
<li><p>분산 아키텍쳐<br>P2P 형의 분산 아키텍쳐를 갖고 있으며, 지정한 키에 의해 결정한 노드에 해당 키와 관련된 모든 값을 저장한다.<br>사용자 id 를 키로 사용하는 경우, 그 사용자에 대한 기록은 하나의 노드에 모이고 그 노드 안에서 쿼리가 실행된다.<br>따라서 다수의 독립적인 키가 있는 경우에 처리를 잘 분산 할 수 있다.</p>
</li>
</ol>
<p>와이드 칼럼 스토어에도 데이터를 집계하는 데는 적합하지 않다. 집계를 위해서는 분산된 모든 노드에서 데이터를 모아야하기 때문이다. Hive, Presto, Spark 등의 쿼리 엔진을 이용해 데이터를 추출해야한다.</p>
<p><img src="/image/big_data_c4_08.png" alt=""></p>
<h5 id="도큐먼트-스토어"><a href="#도큐먼트-스토어" class="headerlink" title="도큐먼트 스토어"></a>도큐먼트 스토어</h5><p>와이드 칼럼 스토어가 성능 향상을 목표로 하는 반면, 도큐먼트 스토어는 데이터 처리읭 유연성을 목적으로 한다. 구체적으로는, JSON 처럼 복잡한 스키마리스 에이터를 그대로의 형태로 저장하고 쿼리를 실행할 수 있도록 한다.<br>물론 간단한 분산 KVS도 JSON 텍스트로 저장할 수 있다. 하지만, 그에 대한 복작한 쿼리를 실행할 수 없다. </p>
<p>도큐먼트 스토어의 장점은, 스키마를 정하지 안혹 데이터 처리를 할수 잇다는 것이다. 그래서 외부에서 들여온 데이터를 저장하는데 특히 적합하다. </p>
<p>예를 들어, MongoDB를 살펴보자. 여러 노드에 데이터를 분산할 수 있지만, 그 자체는 대량의 데이터를 집계하는데 적합하지 않다. 데이터 분석이 목정니 경우 역시 쿼리 엔진으로부터 접속하는 등 데이터를 추출할 필요가 있다.</p>
<h5 id="검색-엔진"><a href="#검색-엔진" class="headerlink" title="검색 엔진"></a>검색 엔진</h5><p>NoSQL 데이터베이스와는 성격이 다르지만, 저장된 데이터를 쿼리로 찾아낸다는 점에서는 유사한 부분이 있다. 특히 텍스트 데이터 및 스키마리스 데이터를 집계하는데 자주 사용된다.</p>
<p>검색 엔진의 특징은 텍스트 데이터를 전문 검색하기 위해 역색인을 만드는 부분이다. 따라서, 기록하는 시스템 부하 및 디스크 소비량은 커지지만, 키워드 검색이 고속화된다.</p>
<p>검색 엔진은 텍스트 데이터를 검색하기 위해 역색인을 만든다. 즉, 텍스트에 포함된 단어를 분해하고 어떤 단어가 어떤 레코드에 포함되어 있는가에 대한 인덱스를 먼저 만들어서 검색을 고속화한다.</p>
<p>예전이라면, 검색 엔진을 사용하지 않고도 전체 스캔을 하는것은 생각할 수 없었지만, 빅데이터 기술의 발전으로 그것도 가능하다. 예를들어, Google BigQuery 를 사용하면 대량의 계산 자원을 이용해 몇 초 만에 빅데이터의 전체 스캔이 가능하다. 쿼리를 실행시킬 때마다 모든 데이터를 로드하기 때문에 매우 비효율적이지만, 실행 빈도가 높지 않다면 문제가 없다.</p>
<p>검색엔진은 데이터의 집계에 적합하며, 민첩성이 요구되는 용도에 최근의 데이터를 보기위해 사용된다. 장기적인 데이터를 축적하기 보다, 실시간 집계 시스템의 읠부로 이용된다. 예를 들어, 메세지가 배송된 데이터를 분산 스토리지에 저장하고, 같은 데이터를 검색 엔진에 전송해 실시간성이 높은 데이터 처리를 위해 활용된다.</p>
<p><img src="/image/big_data_c4_09.png" alt=""></p>
<p>에를들어,  Elasticsserach 가 있다. 임의의 JSON 데이터를 저장할수 있어서 도큐먼트 스토어와 비슷하지만, 아무것도 지정하지 않으면ㅌ 모든필드에 색인이 만들어진다. </p>
<p>Splunk 도 있다. 자신하는 분야는 비정형 데이터로, 주로 웹서버나 네트워키 기기 등으로부터 출력되는 로그 파일이나 JSON 파일으 다루어 텍스트 처리를 해야만 분석할 수 잇는 데이터이다.에를 들어,  검색 엔진이므로 키워드를 입력하면 그것을 포함하는 로그를 찾을 수 있다. 최근의 데이터부터 순서대로 검색되므로 매일 발생하는 각종 이벤트를 빠르게 찾거나 보고서 작성에 유용하다. </p>
<hr>
<p>빅데이터를 지탱하는 기술 &lt;니시다 케이스케&gt;</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2019-12-29T15:00:00.000Z" title="2019-12-29T15:00:00.000Z">2019-12-30</time><span class="level-item"><a class="link-muted" href="/categories/big-data/">Big Data</a></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2019/12/30/big-data-chapter1/">[빅데이터를 지탱하는 기술] 1장_빅데이터 기초 지식</a></h1><div class="content"><h2 id="1-빅데이터의-정착"><a href="#1-빅데이터의-정착" class="headerlink" title="1.빅데이터의 정착"></a>1.빅데이터의 정착</h2><h5 id="빅데이터-기술의-요구-Hadoop-과-NoSQL-의-대두"><a href="#빅데이터-기술의-요구-Hadoop-과-NoSQL-의-대두" class="headerlink" title="빅데이터 기술의 요구 : Hadoop 과 NoSQL 의 대두"></a>빅데이터 기술의 요구 : Hadoop 과 NoSQL 의 대두</h5><p>세계 곳곳에서 엑세스 되는 시스템 증가로, 전통적인 관계형 데이터베이스로는 취급 할 수 없는 데이터가 쌓이게 되었다.</p>
<p>그래서 다른 구조가 필요했다.</p>
<ol>
<li><p>Hadoop </p>
<p>다수의 컴퓨터에서 대량의 데이터 처리</p>
</li>
<li><p>NoSQL Database </p>
<p>빈번한 읽기/ 쓰기 및 분산처리가 강점</p>
</li>
</ol>
<h5 id="분산-시스템의-비즈니스-이용-개척-데이터-웨어하우스와의-공존"><a href="#분산-시스템의-비즈니스-이용-개척-데이터-웨어하우스와의-공존" class="headerlink" title="분산 시스템의 비즈니스 이용 개척 : 데이터 웨어하우스와의 공존"></a>분산 시스템의 비즈니스 이용 개척 : 데이터 웨어하우스와의 공존</h5><p><img src="/image/bigdata_datawarehouse.png" alt=""></p>
<p>위 그림처럼, 확장성이 뛰어난 Hadoop 에 데이터 처리를 맡겨 데이터 웨어하우스의 부하를 줄이고 있다.</p>
<h5 id="직접-할-수-있는-데이터-분석-폭-확대"><a href="#직접-할-수-있는-데이터-분석-폭-확대" class="headerlink" title="직접 할 수 있는 데이터 분석 폭 확대"></a>직접 할 수 있는 데이터 분석 폭 확대</h5><p>‘여러 컴퓨터에서 분산 처리한다’ 는 빅데이터의 특징으로 하드웨어를 준비하고 관리하는게 어려웠다. </p>
<p>하지만, 클라우드 시대에서는 필요한 자원 확보가 쉬워서 얼마든지 빅데이터를 이용할 수 있다.</p>
<h5 id="데이터-디스커버리의-기초-지식"><a href="#데이터-디스커버리의-기초-지식" class="headerlink" title="데이터 디스커버리의 기초 지식"></a>데이터 디스커버리의 기초 지식</h5><ol>
<li><p>데이터 디스커버리</p>
<p>대화형으로 데이터를 시각화하여 가치있는 정보를 찾으려고하는 프로세스</p>
</li>
<li><p>BI 도구</p>
<p>데이터 디스커버리를 위한 셀프 서비스용 시각화 시스템</p>
</li>
</ol>
<h2 id="2-빅데이터-시대의-데이터-분석-기반"><a href="#2-빅데이터-시대의-데이터-분석-기반" class="headerlink" title="2. 빅데이터 시대의 데이터 분석 기반"></a>2. 빅데이터 시대의 데이터 분석 기반</h2><p>빅데이터 기술이 기존 데이터 웨어하우스와 다른 점은,</p>
<p>다수의 분산 시스템을 조합하여 확장성이 뛰어난 데이터 처리 구조를 만든다는 것이다.</p>
<h5 id="데이터-파이프라인"><a href="#데이터-파이프라인" class="headerlink" title="데이터 파이프라인"></a>데이터 파이프라인</h5><p><img src="/image/bigdata_data_pipeline.png" alt=""></p>
<p>차례대로 전달해다가는 데이터로 구성된 시스템이다. 데이터 파이프라인의 기본적인 흐름은,</p>
<ol>
<li>데이터를 모아서 축적</li>
<li>데이터 마트 구성</li>
<li>시각화 도구</li>
</ol>
<h5 id="데이터-수집"><a href="#데이터-수집" class="headerlink" title="데이터 수집"></a>데이터 수집</h5><p>데이터 파이프라인은 데이터를 모으는 부분부터 시작한다. 수집 방법은,</p>
<ol>
<li><p>벌크형</p>
<p>이미 어딘가에 있는 데이터를 정리해서 추출</p>
<p>ex ) 데이터베이스와 파일 서버 등에서 정기적으로 데이터 수집</p>
</li>
<li><p>스트리밍형</p>
<p>차례대로 생성되는 데이터를 끊임없이 보냄</p>
<p>ex) 모바일 어플리케이션, 임베디드 장비</p>
</li>
</ol>
<h5 id="스트림-처리와-배치처리"><a href="#스트림-처리와-배치처리" class="headerlink" title="스트림 처리와 배치처리"></a>스트림 처리와 배치처리</h5><ol>
<li><p>스트림 처리</p>
<p>스트리밍 형 방법으로 받은 데이터를 실시간으로 처리.</p>
<p>장기적인 데이터 분석에는 적합하지 않음.</p>
</li>
<li><p>배치 처리</p>
<p>정리된 데이터를 효율적으로 가공하기 위한 처리.</p>
<p>장기적인 데이터 분석을 위해 대량의 데이터를 저장하고 처리하는데 적합한 분산 시스템이 필요.</p>
</li>
</ol>
<h5 id="분산-스토리지"><a href="#분산-스토리지" class="headerlink" title="분산 스토리지"></a>분산 스토리지</h5><p>여러 컴퓨터와 디스크로 구성된 스토리지 시스템이다. 데이터 저장 방법으로,</p>
<ol>
<li><p>객체 스토리지</p>
<p>한 덩어리로 모인 데이터에 이름을 부여해서 파일로 저장.</p>
<p>ex ) Amazon S3</p>
</li>
<li><p>NoSQL 데이터베이스</p>
<p>많은 데이터를 읽고 쓰기에 유리.</p>
</li>
</ol>
<h5 id="분산-데이터-처리"><a href="#분산-데이터-처리" class="headerlink" title="분산 데이터 처리"></a>분산 데이터 처리</h5><p>분산 스토리지에 저장된 데이터를 처리하기 위해, 분산 데이터 처리 프레임워크가 필요하다. ex) MapReduce</p>
<p>주 역할은, 나중에 분석하기 쉽도록 데이터를 가공해서 그 결과를 외부 데이터베이스에 저장하는 것이다.</p>
<p>빅데이터를 SQL 로 집계하는 방법으로,</p>
<ol>
<li><p>쿼리 엔진</p>
<p>Hive, 대화형 쿼리엔진</p>
</li>
<li><p>데이터 웨어하우스 제품</p>
<p>ETL. </p>
<p>데이터를 추출하고 가공한후, 데이터 웨어하우스에 로드한다.</p>
</li>
</ol>
<h5 id="워크플로우-관리"><a href="#워크플로우-관리" class="headerlink" title="워크플로우 관리"></a>워크플로우 관리</h5><p>데이터파이프라인이 복잡해지면, 한곳에서 제어하지 않으면 전체 움직임 파악이 어렵다.</p>
<h5 id="데이터-웨어하우스와-데이터-마트"><a href="#데이터-웨어하우스와-데이터-마트" class="headerlink" title="데이터 웨어하우스와 데이터 마트"></a>데이터 웨어하우스와 데이터 마트</h5><p><img src="/image/bigdata_data_pipeline_warehouse.png" alt=""></p>
<ol>
<li><p>데이터 소스</p>
<p>RDB 나 로그 등을 저장하는 파일 서버</p>
</li>
<li><p>ETL 플로세스</p>
<p>데이터 소스에 보존된 raw data 를 추출하고 필요에 따라 가공한 후 데이터 웨어하우스에 저장하기까지의 흐름</p>
</li>
<li><p>데이터 마트</p>
<p>데이터웨어 하우스에서 필요한 데이터만을 추출하여 데이터마트를 구축</p>
</li>
</ol>
<h5 id="데이터-레이크"><a href="#데이터-레이크" class="headerlink" title="데이터 레이크"></a>데이터 레이크</h5><p><img src="/image/bigdata_data_pipeline_lake.png" alt=""></p>
<p>모든 데이터를 원래의 형태로 추적해두고 나중에 필요에 따라 가공하는 구조가 필요하다.</p>
<p>이 데이터 축적 장소가 데이터 레이크이다. 분산 스토리지가 데이터 레이크로 이용된다. </p>
<p>데이터 레이크의 데이터를 가공하기 위해 MapReduce 같은 분산 데이터 처리 기술이 필요하다.</p>
<h5 id="데이터-분석-기반을-단계적으로-발전시키기"><a href="#데이터-분석-기반을-단계적으로-발전시키기" class="headerlink" title="데이터 분석 기반을 단계적으로 발전시키기"></a>데이터 분석 기반을 단계적으로 발전시키기</h5><ol>
<li><p>데이터 엔지니어</p>
<p>시스템의 구축 및 운용, 자동화</p>
</li>
<li><p>데이터 분석가</p>
<p>데이터에서 가치있는 정보 추출</p>
</li>
</ol>
<h5 id="확증적-데이터-분석과-탐색적-데이터-분석"><a href="#확증적-데이터-분석과-탐색적-데이터-분석" class="headerlink" title="확증적 데이터 분석과 탐색적 데이터 분석"></a>확증적 데이터 분석과 탐색적 데이터 분석</h5><ol>
<li><p>확증적 데이터 분석</p>
<p>가설을 세우고 검증.</p>
<p>통계학적 모델링에 의한 데이터 분석.</p>
</li>
<li><p>탐색적 데이터 분석</p>
<p>데이터를 보며 의미를 읽어냄.</p>
<p>데이터를 시각화하여 사람의 힘으로 의미를 읽어냄</p>
</li>
</ol>
<hr>
<p>빅데이터를 지탱하는 기술 &lt;니시다 케이스케&gt;</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2019-12-29T15:00:00.000Z" title="2019-12-29T15:00:00.000Z">2019-12-30</time><span class="level-item"><a class="link-muted" href="/categories/big-data/">Big Data</a></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2019/12/30/big-data-chapter2/">[빅데이터를 지탱하는 기술] 2장_빅데이터 탐색</a></h1><div class="content"><h2 id="1-크로스-집계"><a href="#1-크로스-집계" class="headerlink" title="1. 크로스 집계"></a>1. 크로스 집계</h2><h5 id="크로스-집계"><a href="#크로스-집계" class="headerlink" title="크로스 집계"></a>크로스 집계</h5><p><img src="/image/bigdata_cross_table.png" alt=""></p>
<ol>
<li><p>크로스 테이블</p>
<p>행과 열이 교차하는 부분에 숫자 데이터가 들어감</p>
</li>
<li><p>트랜젝션 테이블</p>
<p>행방향으로만 증가하고, 열방향으로는 데이터가 증가하지 않음</p>
</li>
<li><p>크로스 집계</p>
<p>트레젝션 테이블에서 크로스 테이블로 변환하는 과정. </p>
<p>피봇 테이블을 이용해서 할 수 있다.</p>
</li>
</ol>
<h5 id="룩업-테이블"><a href="#룩업-테이블" class="headerlink" title="룩업 테이블"></a>룩업 테이블</h5><p>트랜젝션 테이블의 ‘상품 ID’ 를 사용해서 ‘상품명’ 과 ‘상품 카테고리’ 참고할 때 사용되는 것이, 룩업 테이블이다.</p>
<p>상품 정보를 하나의 테이블로 정리해두면 나중에 속성을 추가하거나 변경하는 것도 간단하다.</p>
<h2 id="2-열-지향-스토리지"><a href="#2-열-지향-스토리지" class="headerlink" title="2. 열 지향 스토리지"></a>2. 열 지향 스토리지</h2><h5 id="처리량과-지연-시간"><a href="#처리량과-지연-시간" class="headerlink" title="처리량과 지연 시간"></a>처리량과 지연 시간</h5><ol>
<li><p>처리량 ( throughput )</p>
<p>일정 시간에 처리할 수 있는 데이터의 양.</p>
<p>배치 처리 등 대규모 데이터 처리에서 중요시.</p>
</li>
<li><p>지연 ( latency )</p>
<p>데이터 처리가 끝날 때 까지의 대기 시간.</p>
<p>애드 혹 데이터 분석에서 중요시.</p>
</li>
</ol>
<h5 id="데이터-처리의-지연"><a href="#데이터-처리의-지연" class="headerlink" title="데이터 처리의 지연"></a>데이터 처리의 지연</h5><p>데이터 처리의 응답이 빠르면, ‘지연이 적다’ 라고 한다. </p>
<ol>
<li><p>메모리</p>
<p>모든 데이터를 메모리에 올리는 것이다.</p>
</li>
<li><p>RDB</p>
<p>만일, 한 레코드의 크기가 500 바이트라고 하면, 천만 레코드의 경우 5 GB 가 된다. </p>
<p>이 정도면, MySQL 이나 PostgreSQL 같은 일반적인 RDB 가 데이터 마트로 적합하다. </p>
<p>RDB는 원래 지연이 적고 많은 클라이언트가 접속해도 성능이 나빠지지 않으므로 많은 사용자가 사용하는 실제 운영 환경의 데이터 마트로 적합하다.</p>
<p>하지만, RDB 는 메모리가 부족하면 급격히 성능이 저하된다.</p>
</li>
</ol>
<h5 id="‘압축’-‘분산’-에-의해-지연-줄이기"><a href="#‘압축’-‘분산’-에-의해-지연-줄이기" class="headerlink" title="‘압축’, ‘분산’ 에 의해 지연 줄이기"></a>‘압축’, ‘분산’ 에 의해 지연 줄이기</h5><p>데이터를 가능한 작게 ‘압축’ 하고 여러 디스크에 ‘분산’ 함으로써 데이터 로드에 따른 지연을 줄일 수 있다. </p>
<p>분산된 데이터를 읽기 위해서는 멀티 코어를 활용해 디스크 I/O 를 병렬 처리하는 것이 효과적이다. </p>
<p>이런 아키텍쳐를 MPP (Massive Parallel Processing) 라고 한다. </p>
<p>대량 데이터를 분석하기 위해 데이터베이스에 널리 사용되고 있다. </p>
<p>ex ) Amazon Redshift, Google BigQuery</p>
<h5 id="행-지향-열-지향-데이터베이스"><a href="#행-지향-열-지향-데이터베이스" class="headerlink" title="행 지향, 열 지향 데이터베이스"></a>행 지향, 열 지향 데이터베이스</h5><ol>
<li><p>행 지향 데이터베이스</p>
<p>레코드 단위로 읽고 쓰기에 최적화.</p>
<p>테이블의 각 행을 하나의 덩어리로 디스크에 저장.</p>
<p>새 레코드 추가할 때마다 파일의 끝에 데이터를 쓸 뿐이여서 빠르게 추가 가능.</p>
<p>데이터 검색을 고속화하기 위해 인덱스 사용.</p>
<p>데이터 분석에서는 어떤 칼럼 사용될지 미리 알 수 없으므로, 인덱스를 작성해도 도움이 되지 않음.</p>
<p>ex ) Oracble, MySQL</p>
</li>
<li><p>열 지향 데이터베이스</p>
<p>칼럼 단위의 집계에 최적화.</p>
<p>데이터를 미리 칼럼 단위로 정리해서 필요한 칼럼만을 로드하여 디스크 I/O 를 줄임.</p>
<p>같은 칼럼에는 종종 유사한 데이터가 나열되어서 데이터 압축 효율도 우수.</p>
<p>ex ) Teradata, Amazon Redshift</p>
</li>
</ol>
<h5 id="MPP-데이터베이스"><a href="#MPP-데이터베이스" class="headerlink" title="MPP 데이터베이스"></a>MPP 데이터베이스</h5><ol>
<li><p>행 지향 데이터베이스</p>
<p>하나의 쿼리는 하나의 스레드에서 실행.</p>
<p>하나의 쿼리가 충분히 짧은 시간에 끝나는 것으로 가정하므로 하나의 쿼리를 분산 처리하는 상황은 가정하지 않음.</p>
</li>
<li><p>열 지향 데이터베이스</p>
<p>디스크에서 대량의 데이터를 읽기 때문에 한 번의 쿼리 실행 시간이 길다.</p>
<p>멀티 코어를 활용해서 고속화 하는것이 좋음.</p>
</li>
</ol>
<p>MPP 에서는 하나의 쿼리를 다수의 태스크로 분해하고, 이를 가능한 한 병렬로 수행한다.</p>
<p>예를 들어,</p>
<ol>
<li>1억 래코드로 이루어진 테이블의 합계를 계산하기 위해</li>
<li>10만 레코드로 구분하여 1000 개의 테스크로 나눈다.</li>
<li>각 테스크는 각각 독립적으로 10 만 레코드의 합계를 집계해서 </li>
<li>마지막 모든 결과를 모아 총 합계를 계산한다.</li>
</ol>
<p>MPP 를 사용한 데이터 집계는 CPU 코어수에 비례해서 고속화된다.</p>
<p>단, 디스크로부터의 로드가 병목 현상이 발생하지 않도록 데이터가 고르게 분산되어 있어야한다. </p>
<h2 id="3-애드-혹-분석과-시각화-도구"><a href="#3-애드-혹-분석과-시각화-도구" class="headerlink" title="3. 애드 혹 분석과 시각화 도구"></a>3. 애드 혹 분석과 시각화 도구</h2><ol>
<li>Jupyter Notebook</li>
<li>Redash</li>
<li>Superset</li>
<li>Kibana</li>
</ol>
<h2 id="4-데이터-마트의-기본-구조"><a href="#4-데이터-마트의-기본-구조" class="headerlink" title="4. 데이터 마트의 기본 구조"></a>4. 데이터 마트의 기본 구조</h2><h5 id="다차원-모델과-OLAP-큐브"><a href="#다차원-모델과-OLAP-큐브" class="headerlink" title="다차원 모델과 OLAP 큐브"></a>다차원 모델과 OLAP 큐브</h5><ol>
<li><p>RDB</p>
<p>표 형식으로 모델링된 데이터를 SQL 로 집계한다.</p>
</li>
<li><p>OLAP</p>
<p>다차원 모델의 데이터 구조를, MDX (Multidimensional Exrepssions) 등의 쿼리 언어로 집계한다.</p>
</li>
</ol>
<p>데이터 분석을 위해 만들어진 다차원의 데이터를 OLAP 큐브라고 한다. OLAP 큐브를 크로스 집계하는 구조가 OALP 이다.</p>
<p>컴퓨터 성능이 높지 않을 때는, 크로스 집계의 모든 조합을 데이터 베이스 안에 캐쉬해두고, 쿼리가 실행되면 이미 집계된 결과를 반환하는 구조였다.</p>
<p>최근에는 MPP 데이터베이스와 인 메모리 데이터베이스로, 사전에 계산해 둘 필요가 없다. MPP 데이터베이스에 다차원 모델의 개념이 없기 때문에, 이를 대신해 ‘비정규화 테이블’ 을 준비한다. 비정규화 테이블을 BI 도구에서 열어서 기존의 OLAP 과 동등한 시각화를 실현할 수 있다.</p>
<h5 id="트렌젝션-마스터-테이블"><a href="#트렌젝션-마스터-테이블" class="headerlink" title="트렌젝션, 마스터 테이블"></a>트렌젝션, 마스터 테이블</h5><p><img src="/image/bigdata_rdb_table.png" alt=""></p>
<ol>
<li><p>트랜젝션 테이블</p>
<p>시간과 함께 생성되는 데이터들을 기록</p>
</li>
<li><p>마스터 테이블</p>
<p>트랜젝션에서 참고되는 각종 정보를 기록</p>
</li>
</ol>
<h5 id="팩트-디맨젼-테이블"><a href="#팩트-디맨젼-테이블" class="headerlink" title="팩트, 디맨젼 테이블"></a>팩트, 디맨젼 테이블</h5><ol>
<li><p>팩트 테이블</p>
<p>트랜젝션 테이블 처럼, 사실이 기록된 것.</p>
<p>집계의 기반이 되는 숫자 데이터 등.</p>
</li>
<li><p>디멘젼 테이블</p>
<p>마스터 테이블 처럼, 참고되는 마스터 데이터.</p>
<p>데이터를 분류하기 위한 속성 값.</p>
</li>
</ol>
<h5 id="스타-스키마"><a href="#스타-스키마" class="headerlink" title="스타 스키마"></a>스타 스키마</h5><p><img src="/image/bigdata_star_scheme.png" alt=""></p>
<p>데이터 마트를 만들때는, 팩트 테이블을 중심으로 여러 디멘젼 테이블을 결합하는 것이 좋다.</p>
<p>스타 스키마를 사용하는 이유는,</p>
<ol>
<li><p>단순하고 이해하기 쉬워 데이터 분석이 쉽다.</p>
</li>
<li><p>성능 상의 이유</p>
<p>데이터 양이 증가하면 팩트 테이블은 디멘젼 테이블보다 훨씬 커져, 팩트 테이브이 메모리 용량을 초과한 시점에 디스크 I/O 가 발생하고 그 대기 시간으로 쿼리의 지연으로 이어진다. </p>
<p>그래서, 팩트 테이블에는 id 와 같은 키만을 남겨두고 그 이외의 나머지는 디멘젼 테이블로 옮긴다.</p>
</li>
</ol>
<h5 id="비정규화-테이블"><a href="#비정규화-테이블" class="headerlink" title="비정규화 테이블"></a>비정규화 테이블</h5><p>스타 스키마는 과거의 이야기이다. 성능 상의 문제는 열 지향 스토리지에 의해 해결된다.</p>
<p>MPP 데이터베이스와 같은 열 지향 스토리지의 보급으로, 칼럼의 수가 아무리 늘어나도 성능에 영향이 없다. </p>
<p>그래서, 처음부터 팩트 테이블에 모든 칼럼을 포함하고 쿼리의 실행 시에는 테이블 결합을 하지 않는 것이 간단하다. </p>
<p>스타 스키마에 비정규화를 진행해 모든 테이블을 결합한 팩트 테이블을 비정규화 테이블이라고 한다.</p>
<h5 id="테이블-추상화"><a href="#테이블-추상화" class="headerlink" title="테이블 추상화"></a>테이블 추상화</h5><p><img src="/image/bigdata_dimension.png" alt=""></p>
<p>비정규화 테이블을 준비했으면, 다차원 모델에 의해 추상화한다.</p>
<p>다차원 모델은 칼럼을 디멘젼과 측정값으로 분류한다. </p>
<ol>
<li><p>디멘젼</p>
<p>주로 날짜 및 문자열. </p>
<p>크로스 집계의 행이나 열로 사용</p>
</li>
<li><p>측정값</p>
<p>주로 숫자값.</p>
</li>
</ol>
<hr>
<p>빅데이터를 지탱하는 기술 &lt;니시다 케이스케&gt;</p>
</div></article></div><nav class="pagination is-centered mt-4" role="navigation" aria-label="pagination"><div class="pagination-previous is-invisible is-hidden-mobile"><a href="/categories/big-data/page/0/">Previous</a></div><div class="pagination-next"><a href="/categories/big-data/page/2/">Next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link is-current" href="/categories/big-data/">1</a></li><li><a class="pagination-link" href="/categories/big-data/page/2/">2</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="https://www.gravatar.com/avatar/e6a876d587c47e3ce358b830fe131aae?s=128" alt="Junhee Ko"></figure><p class="title is-size-4 is-block line-height-inherit">Junhee Ko</p><p class="is-size-6 is-block">Always Learning</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Incheon</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">301</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">14</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">0</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/kojunhee" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/kojunhee"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://www.facebook.com/kojunheee/"><i class="fab fa-facebook"></i></a></div></div></div><!--!--><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/categories/algorithm/"><span class="level-start"><span class="level-item">Algorithm</span></span><span class="level-end"><span class="level-item tag">180</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/big-data/"><span class="level-start"><span class="level-item">Big Data</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/boost-course/"><span class="level-start"><span class="level-item">Boost Course</span></span><span class="level-end"><span class="level-item tag">15</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/git/"><span class="level-start"><span class="level-item">Git</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/jpa/"><span class="level-start"><span class="level-item">JPA</span></span><span class="level-end"><span class="level-item tag">14</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/java/"><span class="level-start"><span class="level-item">Java</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/kafka/"><span class="level-start"><span class="level-item">Kafka</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/oop/"><span class="level-start"><span class="level-item">OOP</span></span><span class="level-end"><span class="level-item tag">18</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/os/"><span class="level-start"><span class="level-item">OS</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/spark/"><span class="level-start"><span class="level-item">Spark</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/spring/"><span class="level-start"><span class="level-item">Spring</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/tdd/"><span class="level-start"><span class="level-item">TDD</span></span><span class="level-end"><span class="level-item tag">32</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/test-code/"><span class="level-start"><span class="level-item">Test Code</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/etc/"><span class="level-start"><span class="level-item">etc</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><h3 class="menu-label">Recent</h3><article class="media"><div class="media-content size-small"><p><time dateTime="2020-06-28T15:00:00.000Z">2020-06-29</time></p><p class="title is-6"><a class="link-muted" href="/2020/06/29/unit-test-ch-06/">[실용주의 단위 테스트] 6장_무엇을 테스트할 것인가?</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/test-code/">Test Code</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-06-27T15:00:00.000Z">2020-06-28</time></p><p class="title is-6"><a class="link-muted" href="/2020/06/28/logback/">Logback</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/spring/">Spring</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-06-26T15:00:00.000Z">2020-06-27</time></p><p class="title is-6"><a class="link-muted" href="/2020/06/27/spring-expert-ch-01/">[전문가를 위한 스프링 5] 3장_Spring IoC 와 DI</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/spring/">Spring</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-06-23T15:00:00.000Z">2020-06-24</time></p><p class="title is-6"><a class="link-muted" href="/2020/06/24/unit-test-ch-05/">[실용주의 단위 테스트] 5장_좋은 테스트의 FIRST 속성</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/test-code/">Test Code</a></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-06-21T15:00:00.000Z">2020-06-22</time></p><p class="title is-6"><a class="link-muted" href="/2020/06/22/unit-test-ch-04/">[실용주의 단위 테스트] 4장_테스트 조직</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/test-code/">Test Code</a></p></div></article></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Advertisement</h3><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-6880109808178384" data-ad-slot="3347750970" data-ad-format="auto" data-full-width-responsive="true"></ins><script>(adsbygoogle = window.adsbygoogle || []).push({});</script></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="Always Learning" height="28"></a><p class="size-small"><span>&copy; 2020 junhee.ko</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            site: {
                url: 'https://kojunhee.github.io',
                external_link: {"enable":true,"exclude":[]}
            },
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to Top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>