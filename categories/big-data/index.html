
<!DOCTYPE html>
<html lang="en">
    
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="junhee.ko">
    <title>Category: Big Data - junhee.ko</title>
    <meta name="author" content="junhee.ko">
    
    
    
    <script type="application/ld+json">{}</script>
    <meta name="description" content="always learning">
<meta property="og:type" content="blog">
<meta property="og:title" content="junhee.ko">
<meta property="og:url" content="https://kojunhee.github.io/categories/big-data/index.html">
<meta property="og:site_name" content="junhee.ko">
<meta property="og:description" content="always learning">
<meta property="og:locale" content="en">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="junhee.ko">
<meta name="twitter:description" content="always learning">
    
    
        
    
    
        <meta property="og:image" content="https://kojunhee.github.io/assets/images/profile.jpg"/>
    
    
    
    
    <!--STYLES-->
    <link rel="stylesheet" href="/assets/css/all.css">
    <link rel="stylesheet" href="/assets/css/jquery.fancybox.css">
    <link rel="stylesheet" href="/assets/css/thumbs.css">
    <link rel="stylesheet" href="/assets/css/tranquilpeak.css">
    <!--STYLES END-->
    

    
</head>

    <body>
        <div id="blog">
            <!-- Define author's picture -->


    
        
            
        
    

<header id="header" data-behavior="2">
    <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
    <div class="header-title">
        <a class="header-title-link" href="/ ">junhee.ko</a>
    </div>
    
        
            <a  class="header-right-picture "
                href="#about">
        
        
            <img class="header-picture" src="/assets/images/profile.jpg" alt="Author&#39;s picture"/>
        
        </a>
    
</header>

            <!-- Define author's picture -->



        
    

<nav id="sidebar" data-behavior="2">
    <div class="sidebar-container">
        
            <div class="sidebar-profile">
                <a href="/#about">
                    <img class="sidebar-profile-picture" src="/assets/images/profile.jpg" alt="Author&#39;s picture"/>
                </a>
                <h4 class="sidebar-profile-name">junhee.ko</h4>
                
                    <h5 class="sidebar-profile-bio"><p>Always Learning</p>
</h5>
                
            </div>
        
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link "
                             href="/ "
                            
                            title="Home"
                        >
                    
                        <i class="sidebar-button-icon fa fa-home" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Home</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link "
                             href="/all-categories"
                            
                            title="Categories"
                        >
                    
                        <i class="sidebar-button-icon fa fa-bookmark" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Categories</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link "
                             href="/all-archives"
                            
                            title="Archives"
                        >
                    
                        <i class="sidebar-button-icon fa fa-archive" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Archives</span>
                    </a>
            </li>
            
        </ul>
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link " href="https://github.com/kojunhee" target="_blank" rel="noopener" title="GitHub">
                    
                        <i class="sidebar-button-icon fab fa-github" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">GitHub</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link " href="https://facebook.com/kojunheee" target="_blank" rel="noopener" title="Facebook">
                    
                        <i class="sidebar-button-icon fab fa-facebook" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Facebook</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link " href="https://www.linkedin.com/in/junheeko" target="_blank" rel="noopener" title="LinkedIn">
                    
                        <i class="sidebar-button-icon fab fa-linkedin" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">LinkedIn</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link " href="mailto:junheee.ko@gmail.com" target="_blank" rel="noopener" title="Mail">
                    
                        <i class="sidebar-button-icon fa fa-envelope" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Mail</span>
                    </a>
            </li>
            
        </ul>
        
    </div>
</nav>

            
            <div id="main" data-behavior="2"
                 class="
                        hasCoverMetaIn
                        ">
                
    <section class="postShorten-group main-content-wrap">
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a class="link-unstyled" href="/2020/01/05/big-data-chapter5/">
                            [빅데이터를 지탱하는 기술] 5장_빅데이터 파이프라인
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2020-01-05T00:00:00+09:00">
	
		    Jan 05, 2020
    	
    </time>
    
        <span>in </span>
        
    <a class="category-link" href="/categories/big-data/">Big Data</a>


    
</div>

            </div>
            
                <div class="postShorten-content">
                    <h2 id="1-워크-플로우-관리"><a href="#1-워크-플로우-관리" class="headerlink" title="1. 워크 플로우 관리"></a>1. 워크 플로우 관리</h2><h5 id="기초-지식"><a href="#기초-지식" class="headerlink" title="기초 지식"></a>기초 지식</h5><ol>
<li><p>워크 플로우 관리 도구</p>
<p>워크 플로우 관리 도구의 주요 역할은, 정기적으로 태스크를 실행하고 비정상적인 상태를 감지하여 해결을 돕는 것이다.</p>
<p>ex) Airflow, Azkaban, Digdag, Luigi, Oozie</p>
</li>
<li><p>태스크</p>
<p>데이터 파이프라인의 실행 과정에서 데이터를 잇달아 이동하면서 정해진 처리를 반복하는데, 이때 실행되는 개별 처리이다.</p>
</li>
<li><p>기본 기능</p>
<ul>
<li><p>테스크를 정기적인 스케쥴로 실행하고 결과 통지</p>
</li>
<li><p>테스크 간의 의존 관계를 정하고 순서대로 빠지없이 실행</p>
</li>
<li><p>테스크의 실행 결과를 보관하고, 오류 발생하면 재실행 할 수 있도록 하기</p>
</li>
</ul>
</li>
<li><p>선언 형과 스크립트 형</p>
<ul>
<li>선언형 : XML 이나 YAML 등의 서식으로 워크플로우 기술</li>
<li>스크립트형 : 스크립트 언어로 워크플로우 정의</li>
</ul>
</li>
</ol>
<h5 id="오류로부터-복구-방법"><a href="#오류로부터-복구-방법" class="headerlink" title="오류로부터 복구 방법"></a>오류로부터 복구 방법</h5><p>모든 오류를 사전에 예상하는 것은 불가능하기 때문에, 오류 발생 가능성을 고려하여 대처 방법을 결정해야한다.</p>
<ol>
<li><p>Retry</p>
<p>재시도를 반복해도 문제가 없는 태스크라면, 1회나 2회의 재시도를 실행해도 좋다.</p>
<p>그러나, 그 이상은 재시도가 아니라 올바른 문제 해결 방법을 찾아야한다.</p>
</li>
<li><p>Backfill</p>
<p>플로우 전체를 처음부터 다시 실행한다. 다음 상황에 사용한다.</p>
<ul>
<li>태스크의 실패가 며칠 동안이나 계속된 후에 이를 모아서 재시도 하고 싶을 때</li>
<li>새롭게 만든 워크 플로우를 과거로 거슬라 올라가 실행하고 싶을 때</li>
</ul>
</li>
</ol>
<h5 id="재실행의-안정성을-위한-두가지-방법"><a href="#재실행의-안정성을-위한-두가지-방법" class="headerlink" title="재실행의 안정성을 위한 두가지 방법"></a>재실행의 안정성을 위한 두가지 방법</h5><ol>
<li><p>원자성 조작 (Atomic Operation)</p>
<p>예를 들어, INSERT 문 2회를 호출하는 태스크가 있다고 하자.</p>
<p>첫 번째의 INSERT 가 종료되고 오류가 발생하면 태스크를 재실행하면 동일한 데이터가 다시 쓰이게 될 수 있다.</p>
<p>이 문제를 회피하기 위해, 각 태스크가 <code>시스템에 변경을 가하는 것을 한 번만 할 수 있도록</code> 하는 것이다.</p>
<p>쓰기가 필요한 수 만큼 테스크를 나누는 것이다. </p>
<p>하지만, 태스크 구현상의 버그 등으로 원자성 조작 직후에 문제가 발생하면 원자성 조작 자체는 성공했어도 워크 플로우 관리 도구에서는 오류로 여길 수 있다.</p>
</li>
<li><p>멱등한 조작</p>
<p>더 확실한 방법은, <code>동일한 태스크를 여러 번 실행해도 동일한 결과</code>가 되도록 하는 것이다.</p>
<p>예를 들어 분산 스토리지에 파일을 업로드할 때, </p>
<ul>
<li>매번 새로운 파일명을 만들 경우 데이터를 추가 (append) 하는 것이고, </li>
<li>동일 파일명으로 덮어쓰면 치환 (replace)하는 것이다. 치환은 반복해도 결과가 변하지 않으므로 멱등하다.</li>
</ul>
</li>
</ol>
<h5 id="데이터-추가"><a href="#데이터-추가" class="headerlink" title="데이터 추가"></a>데이터 추가</h5><ol>
<li><p>멱등한 추가</p>
<p>과거의 모든 데이터를 치환하면 멱등하지만 부하가 커진다. 그래서, Table Partitioning 이 필요하다.</p>
<p>예를 들면 테이블을 1일마다 또는 1시간 마다 파티션으로 분할하고 파티션 단위로 치환하는 것이다.</p>
<p>파티션의 모든 데이터를 삭제할 때, TRUNCATE 문이나 INSESRT OVERWRITER 문 등을 사용할 수 있다.</p>
<p>ex) Hive 는 파티셔닝 지원, Amazon Redshift 는 파티셔닝을 지원하지 않아 UNION ALL 사용</p>
</li>
<li><p>원자성을 지닌 추가</p>
<p>하나의 테이블에 여러번 데이터를 써넣는 경우, 중간 테이블을 이용해 마지막에 목적 테이블에 한 번 추가한다.</p>
<p>즉, 전반 부분에서는 중간 테이블을 만들기 위해 테이블을 치환하므로 멱등하다.</p>
<p>그러나 마지막에 INSESRT 는 단순히 추가이므로 전체로서는 멱등하지 않다.</p>
<p>단, 마지막에 쓰기를 1회만 실시하므로 이것은 원자성을 지닌 조작이다. </p>
<p>그래서 플로우가 실패해도 아무것도 쓰이지 않아 실패한 태스크를 재실행해도 복구가 완료된다.</p>
</li>
</ol>
<h5 id="워크-플로우-전체를-멱등하게-하기"><a href="#워크-플로우-전체를-멱등하게-하기" class="headerlink" title="워크 플로우 전체를 멱등하게 하기"></a>워크 플로우 전체를 멱등하게 하기</h5><p>재실행의 안정성을 위해서는, 멱등하게 구현해야한다.</p>
<p><img src="/image/big_data_workflow_idemponent.png" alt></p>
<h5 id="Task-Queue-자원의-소비량-컨트롤"><a href="#Task-Queue-자원의-소비량-컨트롤" class="headerlink" title="Task Queue : 자원의 소비량 컨트롤"></a>Task Queue : 자원의 소비량 컨트롤</h5><p>대량의 테스크를 동시 실행하면 서버에 과부하가 걸리므로 어느 정도 제한 해야한다.</p>
<p>워크 플로우 관리 도구는, 태스크의 크기나 동시 실행 수를 변화시켜 자원의 소비량을 조정해 모든 태스크가 원활하게 실행되도록 할 수 있다. </p>
<p>이 때, Job Queue 또는 Task Queue 를 사용할 수 있다. </p>
<p>모든 태스크는 큐에 저장되고 일정 수의 워커 프로세스가 순서대로 꺼내며 병렬화가 실현된다.</p>
<h2 id="2-배치-형-데이터-플로우"><a href="#2-배치-형-데이터-플로우" class="headerlink" title="2. 배치 형 데이터 플로우"></a>2. 배치 형 데이터 플로우</h2><h5 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h5><p><img src="/image/big_data_workflow_mapreduce.png" alt></p>
<p>데이터 처리 첫 번째 단계를 Map, 그 결과를 모아서 집계하는 두 번째 단계를 Reduce 라고 한다.</p>
<p>이렇게 Map 과 Reduce 를 반복하면서 목적하는 결과를 얻을 때 까지 계속 데이터를 변화하는 구조가 MapReduce 이다.</p>
<p>MapReduce 는 Map 과 Reduce 의 하나의 사이클이 끝나지 않으면 다음 처리로 이동하지 않는다. 즉, 하나의 사이클에서 다음 사이클로 이동할 때 까지 대기 시간이 발생한다.</p>
<h5 id="데이터-플로우"><a href="#데이터-플로우" class="headerlink" title="데이터 플로우"></a>데이터 플로우</h5><p>이전의 MapReduce 를 사용한 데이터 처리에서는, MapReduce 프로그램을 워크플로우의 태스크로 등록해 다단계의 복잡한 데이터 처리를 할 수 있었다.</p>
<p>현재는, 다단계의 데이터 처리를 분산 시스템 내부에서 실행할 수 있다. 이것을 데이터 플로우라고 한다. </p>
<p>ex) 데이터 플로우를 위한 프레임워크 :  Google Cloud Dataflow, Apache Spark, Apache Flick</p>
<h5 id="MapReduce-를-대신할-세로운-프레임워크"><a href="#MapReduce-를-대신할-세로운-프레임워크" class="headerlink" title="MapReduce 를 대신할 세로운 프레임워크"></a>MapReduce 를 대신할 세로운 프레임워크</h5><p>세로운 프레임워크의 공통 특징은 DAG (Direct Acyclic Graph) 이다.</p>
<p>다음 두 가지 성질이 있다.</p>
<ol>
<li>방향성 : 노드와 노드가 화살표로 연결</li>
<li>비순환 : 화살표를 따라가도 동일 노드로 돌아오지 않음</li>
</ol>
<p>DAG 관점에서 MapReduce 와 데이터 플로우의 차이는,</p>
<ol>
<li><p>MapReduce</p>
<p>MapReduce 도 Map 과 Reduce 의 두 종류 노드로 이루어진 DAG 라 생각할 수 있다. </p>
<p>하지만, 하나의 노드에서 처리가 끝나지 않으면 다음 처리로 진행할 수 없다.</p>
</li>
<li><p>데이터플로우</p>
<p>DAG 를 구성하는 노드가 모두 동싱 병행으로 실행된다.</p>
<p>처리가 끝난 데이터는 네트워크를 거쳐 차례대로 전달된다. </p>
<p>먼저 데이터 파이프라인 전체를 DAG 로 조립한 뒤 실행해서, 내부 스캐쥴러가 분산 시스템에 효과적인 실행 계획을 세운다.</p>
</li>
</ol>
<h5 id="데이터-플로우와-워크플로우-조합하기"><a href="#데이터-플로우와-워크플로우-조합하기" class="headerlink" title="데이터 플로우와 워크플로우 조합하기"></a>데이터 플로우와 워크플로우 조합하기</h5><p>테스크를 정기적으로 실행하거나 실패한 테스크를 기록하여 복구하는 것은, 데이터플로우가 아니라 워크 플로우의 관리가 필요하다. 따라서, 데이터 플로우의 프로그램도 워크 플로우의 일부로 실행되는 하나의 태스크로 고려될 수 있다.</p>
<ol>
<li><p>데이터를 읽어들이는 플로우</p>
<p><img src="/image/big_data_workflow_store.png" alt></p>
<p>데이터 플로우로부터 읽어 들일 데이터는 성능적으로 안정된 분산 스토리지에 배치해야한다. 외부의 데이터 소스에서 데이터를 읽어들일 때는 읽기 속도에 한계가 있으므로 데이터 플로우를 사용한다고 해도 빨라진다고 단언할 수 없다.</p>
<p><img src="/image/big_data_workflow_after_store.png" alt></p>
<p>분산스토리지로 데이터 복사가 완료되면 데이터 플로우로 처리한다.</p>
</li>
<li><p>데이터를 써서 내보내는 워크플로우</p>
<p>데이터 플로우 안에서 대량의 데이터를 외부에 전송해서는 안된다. 왜냐하면,</p>
<ul>
<li><p>쓰기 작업에 오래 걸리면, 실행이 완료되지 않아 자원을 계속해서 소비 할 수 있다.</p>
</li>
<li><p>최악의 경우, 쓰기 작업이 실패해 처음부터 다시 데이터 처리를 재실행 해야 할 수 있다.</p>
</li>
</ul>
<p>그래서, 데이터 플로우는 CSV 파일과 같이 취합하기 쉬운 형식으로 분산 스토리지에 넣는 것 까지한다. </p>
<p>외부 시스템에 데이터를 전송하는 것은 워크 플로우의 역할이다. </p>
<ul>
<li><p>벌크 형 전송 도구를 사용해 태스크를 구현하거나</p>
</li>
<li><p>외부 시스템쪽에 파일을 읽어들이도록 지시한다.</p>
</li>
</ul>
<p><img src="/image/big_data_workflow_write.png" alt></p>
</li>
</ol>
<h5 id="데이터-플로우와-SQL-을-나누어-사용하기"><a href="#데이터-플로우와-SQL-을-나누어-사용하기" class="headerlink" title="데이터 플로우와 SQL 을 나누어 사용하기"></a>데이터 플로우와 SQL 을 나누어 사용하기</h5><p><img src="/image/big_data_workflow_sql.png" alt></p>
<ol>
<li><p>SQL을 MPP 데이터베이스에서 실행</p>
<p>데이터웨어하우스의 파이프라인 </p>
<p>로드되는 데이터를 만드는 부분까지가 데이터 플로의 역할</p>
</li>
<li><p>SQL을 분산 시스템 상의 쿼리 엔진에서 실행 </p>
<p>데이터마트의 파이프라인</p>
<p>구조화된 데이터를 만드는 부분까지가 데이터플로우의 역할</p>
</li>
</ol>
<h2 id="3-스트리밍-형-데이터-플로우"><a href="#3-스트리밍-형-데이터-플로우" class="headerlink" title="3. 스트리밍 형 데이터 플로우"></a>3. 스트리밍 형 데이터 플로우</h2><h5 id="배치-처리와-스트림-처리"><a href="#배치-처리와-스트림-처리" class="headerlink" title="배치 처리와 스트림 처리"></a>배치 처리와 스트림 처리</h5><p><img src="/image/big_data_workflow_stream.png" alt></p>
<ol>
<li><p>배치 처리</p>
<p>도달한 데이터를 우선 분산 스토리지에 보관한다.</p>
<p>데이터가 영속적으로 보관되기 때문에 몇 번이고 재실행 가능하다. </p>
<p>집계 효율이 높은 열 지향 스토리지를 구축할 수 있다. </p>
<p>실행 시에 데이터 양이 정해지기 때문에 유한 데이터 (bounded data)</p>
</li>
<li><p>스트림 처리</p>
<p>데이터 도달과 동시에 처리가 시작된다.</p>
<p>재실행하는 것은 고려하지 않는다.</p>
<p>처리한 결과는 시계열 데이터에 적합한 데이터 스토어에 보관하거나 실시간 시스템에 전송한다.</p>
<p>제한 없이 데이터가 보내지기 때문에 무한 데이터 (unbounded data)</p>
<p>ex) Spark Streaming</p>
</li>
</ol>
<h5 id="스트림-처리에-의한-1차-집계"><a href="#스트림-처리에-의한-1차-집계" class="headerlink" title="스트림 처리에 의한 1차 집계"></a>스트림 처리에 의한 1차 집계</h5><p><img src="/image/big_data_workflow_stream_first.png" alt></p>
<p>분산 스토리지에도 성능 상이나 비용 상의 한계가 있다.</p>
<p>데이터 양이 많아 한계를 넘어서면, 스트림 처리를 사용해 흐름량을 줄일 수 있다.</p>
<h5 id="스트림-처리의-두-가지-문제에-대한-대처"><a href="#스트림-처리의-두-가지-문제에-대한-대처" class="headerlink" title="스트림 처리의 두 가지 문제에 대한 대처"></a>스트림 처리의 두 가지 문제에 대한 대처</h5><p>스트림 처리의 문제 두 가지가 있다.</p>
<ol>
<li><p>틀린 결과를 어떻게 수정할 것인가</p>
<p>새롭게 도달한 데이터만 처리한다.</p>
</li>
<li><p>늦게 전송된 데이터 취급을 어떻게 할 것인가</p>
<p>집계가 종료된 후에 도착한 데이터가 있어서, 스트림 처리의 결과가 부정확해질 수 있다.</p>
</li>
</ol>
<p>이 문제 해결을 위해, 스트림 처리와 별개로 배치 처리를 실행시켜 배치 처리의 결과가 옳다고 할 수 있다.</p>
<p>예를 들어, 일별 보고서를 속보 값으로 하고 월별 보고서를 확정값으로 분류하는 것이다.</p>
<p>이를 발전 시킨 방법이 람다 아키텍쳐, 람다 아키텍쳐를 단순화한 카파 아키텍쳐가 있다.</p>
<ol>
<li><p>람다</p>
<p><img src="/image/big_data_workflow_lamda.png" alt></p>
<p>세 레이어로 구성된다.</p>
<ul>
<li><p>배치 레이어</p>
<p>모든 데이터는 배치 레이어에서 처리한다. 대규모 배치 처리를 위해 실행하며 1회 처리가 오래 걸린다.</p>
</li>
<li><p>서빙 레이어</p>
<p>배치 처리 결과는 서빙 레이어를 통해 접근한다. 응답이 빠른 데이터베이스를 설치해서 집계 결과를 바로 추출한다. </p>
<p>서빙 레이어에서 얻어진 결과를 배치 뷰 라고 한다. 정기적으로 업데이트 되지만 실시간 정보는 얻을 수 없다.</p>
</li>
<li><p>스피드 레이어</p>
<p>스피드 레이어에서 얻은 결과를 실시간 뷰라고 한다. 배치 뷰가 업데이트 될 동안에만 이용되고 오래된 데이터를 순서대로 삭제된다.</p>
</li>
</ul>
<p>배치뷰와 실시간 뷰를 조합시키는 형태로 쿼리를 실행한다. 최근 24시간 집계 결과는 실시간 뷰를 참고하고 그 이전 데이터는 배치뷰를 이용할 수 있다. </p>
<p>실시간 뷰의 결과는 나중에 배치 뷰로 치환된다. 그래서 스트림 처리가 정확하지 않아도 길게 보면 문제가 없다.</p>
</li>
<li><p>카파</p>
<p>람다 아키텍쳐는 스피드 레이어와 배치 레이어가 모두 같은 처리를 구현하고 있으므로 번거롭다.</p>
<p>그래서, 카파 아키테쳐는 스피드 레이어만 남긴다. 대신, 메세지 브로커의 데이터 보관 기한을 길게하여 문제 발생시 메세지 배송 시간을 과거로 다시 설정한다. 그러면 과거의 데이터가 다시 스트림 처리로 흘러 들어 실질적으로 재실행이 이루어진다.</p>
<p>문제점은, 부하가 높아진다는 것이다. 대량의 과거 데이터를 흘려보내면 평상시와 비교해 몇 배의 자원을 소비하기 때문이다. 클라우드 서비스 보급에 그런 자원을 확보하는 것이 어렵지 않으므로 필요에 따라 스트림 처리를 다시 하는것이 간단하는 것이 카파 아키텍쳐의 주장이다.</p>
</li>
</ol>
<h5 id="Out-of-Order-의-데이터-처리"><a href="#Out-of-Order-의-데이터-처리" class="headerlink" title="Out of Order 의 데이터 처리"></a>Out of Order 의 데이터 처리</h5><p><img src="/image/big_data_workflow_out_of_order.png" alt></p>
<p>스트림 처리를 할때 늦게 도달한 메세지, 즉 프로세스 시간과 이벤트 시간의 차이는, 이벤트 시간 윈도윙으로 해결한다.</p>
<p>즉, 이벤트 시간에 의해 윈도우를 나누는 것이다. </p>
<p>메세지가 배송된 데이터는 무작위 순이기 때문에 적절히 순서를 바꿔 집계 결과를 업데이트해야한다.</p>
<p>데이터가 도달할 때마다 해당하는 윈도우를 재집계한다. 데이터를 무한히 계속 보관할 수 없으므로 일정 이상 늦게 온 데이터는 무시한다.</p>
<hr>
<p>빅데이터를 지탱하는 기술 &lt;니시다 케이스케&gt;</p>

                    
                        

                    
                    
                        <p>
                            <a href="/2020/01/05/big-data-chapter5/#post-footer" class="postShorten-excerpt_link link">
                                Comment and share
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a class="link-unstyled" href="/2020/01/02/big-data-chapter4/">
                            [빅데이터를 지탱하는 기술] 4장_빅데이터 축적
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2020-01-02T00:00:00+09:00">
	
		    Jan 02, 2020
    	
    </time>
    
        <span>in </span>
        
    <a class="category-link" href="/categories/big-data/">Big Data</a>


    
</div>

            </div>
            
                <div class="postShorten-content">
                    <h2 id="1-벌크-형과-스트리밍-형의-데이터-수집"><a href="#1-벌크-형과-스트리밍-형의-데이터-수집" class="headerlink" title="1. 벌크 형과 스트리밍 형의 데이터 수집"></a>1. 벌크 형과 스트리밍 형의 데이터 수집</h2><p>데이터 수집 방법으로 두 가지 방법이 있다. </p>
<p>이 챕터에서는 각각의 방법으로, 분산 스토리지에 데이터가 저장되기 까지의 흐름을 정리한다.</p>
<ol>
<li>벌크 형 </li>
<li>스트리밍 형</li>
</ol>
<h5 id="객체-스토리지와-데이터-수집"><a href="#객체-스토리지와-데이터-수집" class="headerlink" title="객체 스토리지와 데이터 수집"></a>객체 스토리지와 데이터 수집</h5><p>빅데이터는 확장성이 높은 분산 스토리지에 저장된다. 분산 스토리지로,</p>
<ol>
<li><p>분산형 데이터베이스</p>
</li>
<li><p>대량으로 파일을 저장하는 객체 스토리지</p>
<p>객체 스토리지는 다수의 컴퓨터를 사용해 파일을 여러 디스크에 복사해서 데이터 중복화 및 부하 분산을 실현한다.</p>
<p>객체 스토리지의 구조는 데이터 양이 많을 때는 우수하지만, 소량의 데이터에 대해서는 비효율적이다.</p>
<p>하둡의 HDFS, 클라우드 서비스의 Amazon S3 가 대표적이다.</p>
</li>
</ol>
<h5 id="데이터-수집"><a href="#데이터-수집" class="headerlink" title="데이터 수집"></a>데이터 수집</h5><p>데이터 수집이란, 수집한 데이터를 가공해 집계 효율이 좋은 분산 스토리지를 만드는 일련의 프로세스이다. </p>
<p>작은 데이터는 적당히 모아서 하나의 큰 파일로 만들어 효율을 높이는데 도움이 된다. </p>
<p>파일이 지나치게 크면, 네트워크 전송 시간이 오래 걸려 오류 발생률이 높다. </p>
<h5 id="벌크-형-데이터-전송"><a href="#벌크-형-데이터-전송" class="headerlink" title="벌크 형 데이터 전송"></a>벌크 형 데이터 전송</h5><p><img src="/image/big_data_bulk_data.png" alt></p>
<p>전통적인 데이터 웨어하우스에서는 주로 벌크 형 방식으로 데이터베이스나 파일 서버 또는 웹 서비스 등에서 각각의 방식 (SQL, API …) 으로 정리해 데이터를 추출한다.</p>
<p>처음부터 분산 스토리지에 데이터가 저장되어 있지 않으면 데이터 전송을 위한 ETL 서버를 설치한다. </p>
<p>데이터 전송의 신뢰성이 중요하면 벌크형 도구를 사용하는 것이 좋다.</p>
<h5 id="파일-사이즈의-적정화"><a href="#파일-사이즈의-적정화" class="headerlink" title="파일 사이즈의 적정화"></a>파일 사이즈의 적정화</h5><p>ETL 프로세스는 하루마다 또는 한시간 마다의 간격으로 정기적인 실행을 하므로 그 동안 축적된 데이터는 하나로 모인다.</p>
<p>데이터 양이 많을 떄는 한 달씩이나 하루 단위로 전송하도록 작은 태스크로 분해해 한 번의 태스크 실행이 커지지 않도록 조정해야한다. </p>
<p>워크 플로우 관리 도구를 사용하면 쉽게 관리 할 수 있다.</p>
<h5 id="스트리밍-형의-데이터-전송"><a href="#스트리밍-형의-데이터-전송" class="headerlink" title="스트리밍 형의 데이터 전송"></a>스트리밍 형의 데이터 전송</h5><p><img src="/image/big_data_message_delivery.png" alt></p>
<p>계속해서 전송되어 오는 작은 데이터를 취급하기 위한 데이터 전송이다.</p>
<p>이러한 데이터 전송은 다수의 클라이언트에서 계속 작은 데이터가 전송된다. 이러한 데이터 전송 방식이 메세지 배송 (Message Delivery) 이다. </p>
<p>보내온 메세지를 저장하는 방법으로,</p>
<ol>
<li><p>NoSQL 데이터베이스</p>
<p>Hive 와 같은 쿼리 엔진으로 NoSQL 데이터베이스에 연결해 데이터를 읽을 수 있다. </p>
</li>
<li><p>Message Queue</p>
<p>데이터를 일정 간격으로 꺼내고 모아서 분산 스토리지에 저장한다.</p>
</li>
</ol>
<h5 id="웹-브라우저에서-메세지-배송"><a href="#웹-브라우저에서-메세지-배송" class="headerlink" title="웹 브라우저에서 메세지 배송"></a>웹 브라우저에서 메세지 배송</h5><p><img src="/image/big_data_message_web_browser.png" alt></p>
<ol>
<li><p>상주형 로그 수집 소프트웨어</p>
<p>자체 개발한 웹 애플리케이션 등에서는 웹 서버 안에서 메세지를 만들어서 배송한다. 전송 효율을 높이기 위해 서버상에서 일단 데이터를 축적해 놓고 나중에 모아서 보내는 경우가 있다. 이 때, Fluentd 나 Logstash 같은 상주형 로그 수집 소프트웨어가 자주 사용된다.</p>
</li>
<li><p>웹 이벤트 추적</p>
<p>자바스크립트를 이용해 웹 브라우에서 직접 메세지를 보내는 경우도 있다.</p>
</li>
</ol>
<h5 id="모바일-앱에서-메세지-배송"><a href="#모바일-앱에서-메세지-배송" class="headerlink" title="모바일 앱에서 메세지 배송"></a>모바일 앱에서 메세지 배송</h5><p><img src="/image/big_data_message_mobile.png" alt></p>
<ol>
<li><p>MBaaS</p>
<p>모바일 앱에서는 서버를 직접 마련하는 것이 아니라, MBaaS (Mobile Backend as a Serivce) 라는 백엔드의 각종 서비스를 이용할 수 있다. </p>
</li>
<li><p>SDK</p>
<p>모바일 앱이 오프라인이 되었을 때는 발생한 이벤트를 SDK 내부에 축적하고 온라인 상태 되었을 때 모아서 보낼 수 있다.</p>
</li>
</ol>
<h5 id="디바이스에서-메세지-배송"><a href="#디바이스에서-메세지-배송" class="headerlink" title="디바이스에서 메세지 배송"></a>디바이스에서 메세지 배송</h5><p><img src="/image/big_data_message_device.png" alt></p>
<p>MQTT (MQ Telemetry Transport) 는 TCP/IP 를 이용하여 데이터 전송하는 프로토콜 중 하나이다. 일반적으로 Pub/Sub 메세지 배송 구조이다. </p>
<h5 id="메세지-배송의-공통화"><a href="#메세지-배송의-공통화" class="headerlink" title="메세지 배송의 공통화"></a>메세지 배송의 공통화</h5><p>메세지가 처음 생성되는 기기를 클라이언트, 해당 메세지를 먼저 받는 서버를 프론트엔드라고 한다.</p>
<p>프론트 엔드는 단지 데이터를 받는 것에 전념하고, 그 이후의 문제는 백엔드의 공통 시스템에 맡길 수 있다.</p>
<h2 id="2-성능-신뢰성-메세지-배송의-트레이드오프"><a href="#2-성능-신뢰성-메세지-배송의-트레이드오프" class="headerlink" title="2. 성능, 신뢰성 : 메세지 배송의 트레이드오프"></a>2. 성능, 신뢰성 : 메세지 배송의 트레이드오프</h2><p>이 챕터는 메세지 브로커를 중심으로 메세지 배송 구조와 한계를 정리한다.</p>
<h5 id="메세지-브로커"><a href="#메세지-브로커" class="headerlink" title="메세지 브로커"></a>메세지 브로커</h5><p>메세지 배송에 의해 보내진 데이터를 분산 스토리지에 저장할 때, 데이터 양이 적을 때는 문제가 되지 않지만 쓰기의 빈도가 증가하면 디스크 성능의 한계에 도달해 더 쓸 수 없게 될 우려가 있다.</p>
<p>대량의 메세지를 안정적으로 받기 위해서는 빈번한 쓰기에도 견딜 수 있는 성능이 높고, 필요에 따라 성능을 얼마든지 올릴 수 있는 스토리지가 필요하다.</p>
<p>분산 스토리지가 반드시 이 성격을 가질 수 있다고 할 수 없기 때문에, 메세지를 일시적으로 축적하는 중산층이 설치된다. 이것이 메세지 브로커이다.</p>
<p>ex) Apache Kafka, Amazon Kinesis</p>
<h5 id="push-형-pull-형"><a href="#push-형-pull-형" class="headerlink" title="push 형, pull 형"></a>push 형, pull 형</h5><p>송신 측의 제어로 데이터를 보내는 방식을 push 형, 수신 측 주도로 데이터를 가져오는 것을 pull 형이라고 한다.</p>
<p>메세지 브로커에 데이터를 push 하는 것을 producer, pull 하는 것을 consumer 라고 한다.</p>
<p>push 형의 메세지 배송은 모두 메세지 브로커에 집중 시키고 거기에서 일정한 빈도로 꺼낸 데이터를 분산 스토리지에 기록한다.</p>
<p>또한, pull 형의 메세지 배송은 파일 사이즈 적정화에도 도움이 된다. consumer 는 메세지 브로커로부터 일정한 간격으로 데이터를 취해 적당히 모아진 데이터를 분산 스토리지에 저장한다.</p>
<h5 id="메세지-라우팅"><a href="#메세지-라우팅" class="headerlink" title="메세지 라우팅"></a>메세지 라우팅</h5><p>메세지 브로커에 써넣은 데이터는 다수의 다른 consumer 에서 읽을 수 있다. 이를 통해 메세지가 복사되어 데이터를 여러 경로로 분기 시킬 수 있다. 이것이 메세지 라우팅이다.</p>
<p>예를 들어, 메세지 일부를 실시간 장애 감지를 사용하면서, 같은 메세지를 장기적인 데이터 분석을 위한 분산 스토리지에 저장하는 것도 가능하다.</p>
<h5 id="메세지-배송-신뢰성-문제와-세-가지-설계-방식"><a href="#메세지-배송-신뢰성-문제와-세-가지-설계-방식" class="headerlink" title="메세지 배송 신뢰성 문제와 세 가지 설계 방식"></a>메세지 배송 신뢰성 문제와 세 가지 설계 방식</h5><p>대부분의 경우 다음 중 하나를 보장하도록 설계된다.</p>
<ol>
<li><p>at most once</p>
<p>메세지는 한 번만 전송된다. 도중에 전송 실패로 사라질 가능성이 있다.</p>
</li>
<li><p>exactly once</p>
<p>메세지는 손실 되거나 중복 없이 한 번만 전달된다.</p>
<p>네트워크 상에 두 개의 노드가 있는 경우 양쪽의 통신 내용을 보장하기 위해 coorninator 가 필요하다. 문제가 생기면 송신 측과 수신 측 모두 서로의 정보를 코디네이터에게 전달해서 문제가 발생하면 코디네이터의 지시에 따라 해결할 수 있다.</p>
<p>그러나 분산 시스템에서는 코디네이터와의 통신이 끊길 수 있고 코데네이터가 정지될 수도 있다. 따라서 코디네이터의 부재 시에 어덯게 할 것인지에 대한 consensus 가 필요하다. 보통, 단시간 장애 가능성은 받아 들인다.</p>
<p>또한, 코디네이터의 판단에만 따르고 있으면 시간이 너무 소요된다. </p>
<p>그래서 메세지 배송 시스템에서는 코디네이터를 도입하지 않고 at least once 를 따른다. </p>
</li>
<li><p>at least once</p>
<p>메세지는 확실히 전달된다. 단, 같은 것이 여러번 전달될 가능성이 있다.</p>
<p>메세지가 재전송되어도 그것을 없앨 수 있는 구조가 있으면 보기에 중복이 없는 것처럼 할 수 있다. 이러한 구조를 ‘중복 제거’ 라고 한다. </p>
<p>예를 들어, TCP 는 메세지 수신 확인을 위해 ‘ack’ 플래그를 도입했다. 메세지 재전송에 의한 중복이 발생하지만, 모든 TCP 패킷에서는 이것을 식별하는 시퀀스 번호를 이용해 중복 제거가 이뤄진다.</p>
<p>대부분의 메세지 배송 시스템은 at least once 를 보장하는 한편, 중복 제거는 이용자에게 맡기고 있어서 TCP/IP 처럼 자동으로 중복을 제거해주지 않는다. (ex) Apache Kafka, Apache Flume, Logstash</p>
</li>
</ol>
<h5 id="중복-제거는-높은-비용의-오퍼레이션"><a href="#중복-제거는-높은-비용의-오퍼레이션" class="headerlink" title="중복 제거는 높은 비용의 오퍼레이션"></a>중복 제거는 높은 비용의 오퍼레이션</h5><p>중복 제거 방법으로 다음과 같은 방법이 있다.</p>
<ol>
<li><p>오프셋 이용</p>
<p>각 메세지에는 파일 안의 시작 위치 (오프셋) 를 붙인다.</p>
<p>메세지가 중복되어도 같은 파일의 같은 장소를 덮어쓸 뿐이므로 문제되지 않는다.</p>
<p>벌 크형 데이터 전송과 같이 데이터양이 고정된 경우에 사용한다.</p>
</li>
<li><p>고유 ID 이용</p>
<p>모든 메세지에 UUID 등의 고유 ID 를 지정한다.</p>
<p>메세지가 늘어남에 따라 ID 가 증가하므로 그것을 어떻게 관리하느냐가 문제이다.</p>
<p>스트리밍 형의 메세지 배송에서 자주 사용된다. </p>
</li>
</ol>
<h5 id="End-to-End-신뢰성"><a href="#End-to-End-신뢰성" class="headerlink" title="End to End 신뢰성"></a>End to End 신뢰성</h5><p>클라이언트가 생성한 메세지를 최종 도달 지점인 분산 스토리지에 기록하는 단계에서 중복 없는 상태로 해야한다.</p>
<p>중간에 한 부분이라도 at most once 가 있으면 메세지를 빠뜨릴 가능성이 있고, at least once 가 있으면 중복될 수 있다. </p>
<p>신뢰성이 높은 메세지 배송을 실현하려면 중간 경로를 모두 at least once 로 통일한 후 클라이언트 상에서 모든 메세지에 고유 ID 를 포함하도록 하고 경로의 말단에서 중복 제거를 실행해야한다.</p>
<h5 id="고유-ID-를-사용한-중복-제거-방법"><a href="#고유-ID-를-사용한-중복-제거-방법" class="headerlink" title="고유 ID 를 사용한 중복 제거 방법"></a>고유 ID 를 사용한 중복 제거 방법</h5><p>두가지 방법이 있다.</p>
<ol>
<li><p>분산 스토리지로 NoSQL 데이터베이스 사용</p>
<p>Cassandra 나 Elasticsearch 등은 데이터를 쓸 대 고유 ID 를 지정하게 되어 있어 동일한 ID 의 데이터는 덮어쓴다.</p>
</li>
<li><p>SQL</p>
<p>보내온 데이터는 일단 그대로 객체 스토리지 등에 저장하고, 나중에 읽어 들이는 단계에서 중복을 제거한다. </p>
<p>Hive 와 같은 배치형 쿼리 엔진에서 실행할 수 있다.</p>
</li>
</ol>
<h5 id="데이터-수집-파이프라인"><a href="#데이터-수집-파이프라인" class="headerlink" title="데이터 수집 파이프라인"></a>데이터 수집 파이프라인</h5><p><img src="/image/big_data_stream_pipeline.png" alt></p>
<p>일련의 프로세스를 거쳐 마지막으로 데이터를 구조화해서 열 지향 스토리지로 변환함으로써, 장기간의 데이터 분석에 적합한 스토리가 완성된다. 이것인 데이터 수집 파이프라인이다.</p>
<p>실제로 어떤 파이프라인을 만들지는 요구사항에 따라 다르므로, 필요에 따라 시스템을 조합한다. </p>
<p>예를 들어, 쓰기 성능에 불안감이 없으면 메세지 브로커가 불필요 하므로 클라이언트에서 직접 NoSQL 데이터베이스에 데이터를 써도 된다. 중복이 허용된다면 중복 제거를 생략할 수 있다.</p>
<h5 id="중복을-고려한-시스템-설계"><a href="#중복을-고려한-시스템-설계" class="headerlink" title="중복을 고려한 시스템 설계"></a>중복을 고려한 시스템 설계</h5><p>스트리밍 형의 메세지 배송 방식에서는 중간에 중복 제거 방식을 도입하지 않으면 중복 가능성이 있다고 생각하면 된다.</p>
<p>신뢰성이 중시되는 경우에는 스트리밍 형의 메세지 배송을 피하는 것이 좋다.</p>
<p>예를 들어, 과금 데이터같은 오차가 불허용 되는 경우 트랜잭션 처리르 지원하는 데이터베이스에 직접 애플리케이션이 기록해야한다. 그 후에 벌크 형의 데이터 전송을 함으로써 중복도 결손도 확실히 피해야한다.</p>
<h2 id="3-TODO"><a href="#3-TODO" class="headerlink" title="3. TODO"></a>3. TODO</h2><h5 id="ㅇㅇㅇ"><a href="#ㅇㅇㅇ" class="headerlink" title="ㅇㅇㅇ"></a>ㅇㅇㅇ</h5><p>팩트 테이블 작성 방법으로,</p>
<ol>
<li><p>추가</p>
<p>새로 도착한 데이터만을 증분으로 추가</p>
</li>
<li><p>치환</p>
<p>과거 데이터를 포함하여 테이블 전체 치환</p>
</li>
</ol>
<h5 id="테이블-파티셔닝"><a href="#테이블-파티셔닝" class="headerlink" title="테이블 파티셔닝"></a>테이블 파티셔닝</h5><p>위의 ‘추가’ 방법은 다음 문제가 있다.</p>
<ol>
<li>추가에 실패한것을 알아채지 못하면, 팩트 테이블의 일부에 결손</li>
<li>추가를 잘못해서 여러번 실행하면, 일부 중복</li>
<li>나중에 팩트 테이블 다시 만들고 싶으면, 관리 복잡</li>
</ol>
<p>그래서 파티셔닝이 필요하다.</p>
<p>하나의 테이블을 여러 물리적인 파티션으로 나눠서 파티션 단위로 정리하여 데이터를 쓰거나 삭제하는 것이다.</p>
<h5 id="집계-테이블"><a href="#집계-테이블" class="headerlink" title="집계 테이블"></a>집계 테이블</h5><p>팩트 테이블을 어느 정도 모아서 집계하면 데이터의 양이 줄어든다. 이것은 집계 테이블이라고 한다.</p>
<p>각 칼럼이 취하는 값의 범위란, 카디널리티이다. ‘성별’ 과 같이 취할 수 있는 값이 적은 것은 카디널리티가 작은 것이다.</p>
<p>집계 테이블을 작게 하려면 모든 칼럼의 카디널리티를 줄여야한다.</p>
<h5 id="스냅샷-테이블-이력-테이블"><a href="#스냅샷-테이블-이력-테이블" class="headerlink" title="스냅샷 테이블, 이력 테이블"></a>스냅샷 테이블, 이력 테이블</h5><p>마스터 데이터처럼 업데이트 될 가능성이 있는 테이블은,</p>
<p>정기적으로 테이블을 통째로 저장하는 스탭샷 테이블, 또는 변경 내용만을 저장하는 이력 테이블로 관리할 수 있다.</p>
<h5 id="디멘전을-추가하여-비정규화-테이블-완성시키기"><a href="#디멘전을-추가하여-비정규화-테이블-완성시키기" class="headerlink" title="디멘전을 추가하여 비정규화 테이블 완성시키기"></a>디멘전을 추가하여 비정규화 테이블 완성시키기</h5><p>팩트 테이블과 디멘젼 테이블을 결합하여 비정규화 테이블을 만든다.</p>
<hr>
<p>빅데이터를 지탱하는 기술 &lt;니시다 케이스케&gt;</p>

                    
                        

                    
                    
                        <p>
                            <a href="/2020/01/02/big-data-chapter4/#post-footer" class="postShorten-excerpt_link link">
                                Comment and share
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a class="link-unstyled" href="/2019/12/30/big-data-chapter1/">
                            [빅데이터를 지탱하는 기술] 1장_빅데이터 기초 지식
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2019-12-30T00:00:00+09:00">
	
		    Dec 30, 2019
    	
    </time>
    
        <span>in </span>
        
    <a class="category-link" href="/categories/big-data/">Big Data</a>


    
</div>

            </div>
            
                <div class="postShorten-content">
                    <h2 id="1-빅데이터의-정착"><a href="#1-빅데이터의-정착" class="headerlink" title="1.빅데이터의 정착"></a>1.빅데이터의 정착</h2><h5 id="빅데이터-기술의-요구-Hadoop-과-NoSQL-의-대두"><a href="#빅데이터-기술의-요구-Hadoop-과-NoSQL-의-대두" class="headerlink" title="빅데이터 기술의 요구 : Hadoop 과 NoSQL 의 대두"></a>빅데이터 기술의 요구 : Hadoop 과 NoSQL 의 대두</h5><p>세계 곳곳에서 엑세스 되는 시스템 증가로, 전통적인 관계형 데이터베이스로는 취급 할 수 없는 데이터가 쌓이게 되었다.</p>
<p>그래서 다른 구조가 필요했다.</p>
<ol>
<li><p>Hadoop </p>
<p>다수의 컴퓨터에서 대량의 데이터 처리</p>
</li>
<li><p>NoSQL Database </p>
<p>빈번한 읽기/ 쓰기 및 분산처리가 강점</p>
</li>
</ol>
<h5 id="분산-시스템의-비즈니스-이용-개척-데이터-웨어하우스와의-공존"><a href="#분산-시스템의-비즈니스-이용-개척-데이터-웨어하우스와의-공존" class="headerlink" title="분산 시스템의 비즈니스 이용 개척 : 데이터 웨어하우스와의 공존"></a>분산 시스템의 비즈니스 이용 개척 : 데이터 웨어하우스와의 공존</h5><p><img src="/image/bigdata_datawarehouse.png" alt></p>
<p>위 그림처럼, 확장성이 뛰어난 Hadoop 에 데이터 처리를 맡겨 데이터 웨어하우스의 부하를 줄이고 있다.</p>
<h5 id="직접-할-수-있는-데이터-분석-폭-확대"><a href="#직접-할-수-있는-데이터-분석-폭-확대" class="headerlink" title="직접 할 수 있는 데이터 분석 폭 확대"></a>직접 할 수 있는 데이터 분석 폭 확대</h5><p>‘여러 컴퓨터에서 분산 처리한다’ 는 빅데이터의 특징으로 하드웨어를 준비하고 관리하는게 어려웠다. </p>
<p>하지만, 클라우드 시대에서는 필요한 자원 확보가 쉬워서 얼마든지 빅데이터를 이용할 수 있다.</p>
<h5 id="데이터-디스커버리의-기초-지식"><a href="#데이터-디스커버리의-기초-지식" class="headerlink" title="데이터 디스커버리의 기초 지식"></a>데이터 디스커버리의 기초 지식</h5><ol>
<li><p>데이터 디스커버리</p>
<p>대화형으로 데이터를 시각화하여 가치있는 정보를 찾으려고하는 프로세스</p>
</li>
<li><p>BI 도구</p>
<p>데이터 디스커버리를 위한 셀프 서비스용 시각화 시스템</p>
</li>
</ol>
<h2 id="2-빅데이터-시대의-데이터-분석-기반"><a href="#2-빅데이터-시대의-데이터-분석-기반" class="headerlink" title="2. 빅데이터 시대의 데이터 분석 기반"></a>2. 빅데이터 시대의 데이터 분석 기반</h2><p>빅데이터 기술이 기존 데이터 웨어하우스와 다른 점은,</p>
<p>다수의 분산 시스템을 조합하여 확장성이 뛰어난 데이터 처리 구조를 만든다는 것이다.</p>
<h5 id="데이터-파이프라인"><a href="#데이터-파이프라인" class="headerlink" title="데이터 파이프라인"></a>데이터 파이프라인</h5><p><img src="/image/bigdata_data_pipeline.png" alt></p>
<p>차례대로 전달해다가는 데이터로 구성된 시스템이다. 데이터 파이프라인의 기본적인 흐름은,</p>
<ol>
<li>데이터를 모아서 축적</li>
<li>데이터 마트 구성</li>
<li>시각화 도구</li>
</ol>
<h5 id="데이터-수집"><a href="#데이터-수집" class="headerlink" title="데이터 수집"></a>데이터 수집</h5><p>데이터 파이프라인은 데이터를 모으는 부분부터 시작한다. 수집 방법은,</p>
<ol>
<li><p>벌크형</p>
<p>이미 어딘가에 있는 데이터를 정리해서 추출</p>
<p>ex ) 데이터베이스와 파일 서버 등에서 정기적으로 데이터 수집</p>
</li>
<li><p>스트리밍형</p>
<p>차례대로 생성되는 데이터를 끊임없이 보냄</p>
<p>ex) 모바일 어플리케이션, 임베디드 장비</p>
</li>
</ol>
<h5 id="스트림-처리와-배치처리"><a href="#스트림-처리와-배치처리" class="headerlink" title="스트림 처리와 배치처리"></a>스트림 처리와 배치처리</h5><ol>
<li><p>스트림 처리</p>
<p>스트리밍 형 방법으로 받은 데이터를 실시간으로 처리.</p>
<p>장기적인 데이터 분석에는 적합하지 않음.</p>
</li>
<li><p>배치 처리</p>
<p>정리된 데이터를 효율적으로 가공하기 위한 처리.</p>
<p>장기적인 데이터 분석을 위해 대량의 데이터를 저장하고 처리하는데 적합한 분산 시스템이 필요.</p>
</li>
</ol>
<h5 id="분산-스토리지"><a href="#분산-스토리지" class="headerlink" title="분산 스토리지"></a>분산 스토리지</h5><p>여러 컴퓨터와 디스크로 구성된 스토리지 시스템이다. 데이터 저장 방법으로,</p>
<ol>
<li><p>객체 스토리지</p>
<p>한 덩어리로 모인 데이터에 이름을 부여해서 파일로 저장.</p>
<p>ex ) Amazon S3</p>
</li>
<li><p>NoSQL 데이터베이스</p>
<p>많은 데이터를 읽고 쓰기에 유리.</p>
</li>
</ol>
<h5 id="분산-데이터-처리"><a href="#분산-데이터-처리" class="headerlink" title="분산 데이터 처리"></a>분산 데이터 처리</h5><p>분산 스토리지에 저장된 데이터를 처리하기 위해, 분산 데이터 처리 프레임워크가 필요하다. ex) MapReduce</p>
<p>주 역할은, 나중에 분석하기 쉽도록 데이터를 가공해서 그 결과를 외부 데이터베이스에 저장하는 것이다.</p>
<p>빅데이터를 SQL 로 집계하는 방법으로,</p>
<ol>
<li><p>쿼리 엔진</p>
<p>Hive, 대화형 쿼리엔진</p>
</li>
<li><p>데이터 웨어하우스 제품</p>
<p>ETL. </p>
<p>데이터를 추출하고 가공한후, 데이터 웨어하우스에 로드한다.</p>
</li>
</ol>
<h5 id="워크플로우-관리"><a href="#워크플로우-관리" class="headerlink" title="워크플로우 관리"></a>워크플로우 관리</h5><p>데이터파이프라인이 복잡해지면, 한곳에서 제어하지 않으면 전체 움직임 파악이 어렵다.</p>
<h5 id="데이터-웨어하우스와-데이터-마트"><a href="#데이터-웨어하우스와-데이터-마트" class="headerlink" title="데이터 웨어하우스와 데이터 마트"></a>데이터 웨어하우스와 데이터 마트</h5><p><img src="/image/bigdata_data_pipeline_warehouse.png" alt></p>
<ol>
<li><p>데이터 소스</p>
<p>RDB 나 로그 등을 저장하는 파일 서버</p>
</li>
<li><p>ETL 플로세스</p>
<p>데이터 소스에 보존된 raw data 를 추출하고 필요에 따라 가공한 후 데이터 웨어하우스에 저장하기까지의 흐름</p>
</li>
<li><p>데이터 마트</p>
<p>데이터웨어 하우스에서 필요한 데이터만을 추출하여 데이터마트를 구축</p>
</li>
</ol>
<h5 id="데이터-레이크"><a href="#데이터-레이크" class="headerlink" title="데이터 레이크"></a>데이터 레이크</h5><p><img src="/image/bigdata_data_pipeline_lake.png" alt></p>
<p>모든 데이터를 원래의 형태로 추적해두고 나중에 필요에 따라 가공하는 구조가 필요하다.</p>
<p>이 데이터 축적 장소가 데이터 레이크이다. 분산 스토리지가 데이터 레이크로 이용된다. </p>
<p>데이터 레이크의 데이터를 가공하기 위해 MapReduce 같은 분산 데이터 처리 기술이 필요하다.</p>
<h5 id="데이터-분석-기반을-단계적으로-발전시키기"><a href="#데이터-분석-기반을-단계적으로-발전시키기" class="headerlink" title="데이터 분석 기반을 단계적으로 발전시키기"></a>데이터 분석 기반을 단계적으로 발전시키기</h5><ol>
<li><p>데이터 엔지니어</p>
<p>시스템의 구축 및 운용, 자동화</p>
</li>
<li><p>데이터 분석가</p>
<p>데이터에서 가치있는 정보 추출</p>
</li>
</ol>
<h5 id="확증적-데이터-분석과-탐색적-데이터-분석"><a href="#확증적-데이터-분석과-탐색적-데이터-분석" class="headerlink" title="확증적 데이터 분석과 탐색적 데이터 분석"></a>확증적 데이터 분석과 탐색적 데이터 분석</h5><ol>
<li><p>확증적 데이터 분석</p>
<p>가설을 세우고 검증.</p>
<p>통계학적 모델링에 의한 데이터 분석.</p>
</li>
<li><p>탐색적 데이터 분석</p>
<p>데이터를 보며 의미를 읽어냄.</p>
<p>데이터를 시각화하여 사람의 힘으로 의미를 읽어냄</p>
</li>
</ol>
<hr>
<p>빅데이터를 지탱하는 기술 &lt;니시다 케이스케&gt;</p>

                    
                        

                    
                    
                        <p>
                            <a href="/2019/12/30/big-data-chapter1/#post-footer" class="postShorten-excerpt_link link">
                                Comment and share
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a class="link-unstyled" href="/2019/12/30/big-data-chapter2/">
                            [빅데이터를 지탱하는 기술] 2장_빅데이터 탐색
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2019-12-30T00:00:00+09:00">
	
		    Dec 30, 2019
    	
    </time>
    
        <span>in </span>
        
    <a class="category-link" href="/categories/big-data/">Big Data</a>


    
</div>

            </div>
            
                <div class="postShorten-content">
                    <h2 id="1-크로스-집계"><a href="#1-크로스-집계" class="headerlink" title="1. 크로스 집계"></a>1. 크로스 집계</h2><h5 id="크로스-집계"><a href="#크로스-집계" class="headerlink" title="크로스 집계"></a>크로스 집계</h5><p><img src="/image/bigdata_cross_table.png" alt></p>
<ol>
<li><p>크로스 테이블</p>
<p>행과 열이 교차하는 부분에 숫자 데이터가 들어감</p>
</li>
<li><p>트랜젝션 테이블</p>
<p>행방향으로만 증가하고, 열방향으로는 데이터가 증가하지 않음</p>
</li>
<li><p>크로스 집계</p>
<p>트레젝션 테이블에서 크로스 테이블로 변환하는 과정. </p>
<p>피봇 테이블을 이용해서 할 수 있다.</p>
</li>
</ol>
<h5 id="룩업-테이블"><a href="#룩업-테이블" class="headerlink" title="룩업 테이블"></a>룩업 테이블</h5><p>트랜젝션 테이블의 ‘상품 ID’ 를 사용해서 ‘상품명’ 과 ‘상품 카테고리’ 참고할 때 사용되는 것이, 룩업 테이블이다.</p>
<p>상품 정보를 하나의 테이블로 정리해두면 나중에 속성을 추가하거나 변경하는 것도 간단하다.</p>
<h2 id="2-열-지향-스토리지"><a href="#2-열-지향-스토리지" class="headerlink" title="2. 열 지향 스토리지"></a>2. 열 지향 스토리지</h2><h5 id="처리량과-지연-시간"><a href="#처리량과-지연-시간" class="headerlink" title="처리량과 지연 시간"></a>처리량과 지연 시간</h5><ol>
<li><p>처리량 ( throughput )</p>
<p>일정 시간에 처리할 수 있는 데이터의 양.</p>
<p>배치 처리 등 대규모 데이터 처리에서 중요시.</p>
</li>
<li><p>지연 ( latency )</p>
<p>데이터 처리가 끝날 때 까지의 대기 시간.</p>
<p>애드 혹 데이터 분석에서 중요시.</p>
</li>
</ol>
<h5 id="데이터-처리의-지연"><a href="#데이터-처리의-지연" class="headerlink" title="데이터 처리의 지연"></a>데이터 처리의 지연</h5><p>데이터 처리의 응답이 빠르면, ‘지연이 적다’ 라고 한다. </p>
<ol>
<li><p>메모리</p>
<p>모든 데이터를 메모리에 올리는 것이다.</p>
</li>
<li><p>RDB</p>
<p>만일, 한 레코드의 크기가 500 바이트라고 하면, 천만 레코드의 경우 5 GB 가 된다. </p>
<p>이 정도면, MySQL 이나 PostgreSQL 같은 일반적인 RDB 가 데이터 마트로 적합하다. </p>
<p>RDB는 원래 지연이 적고 많은 클라이언트가 접속해도 성능이 나빠지지 않으므로 많은 사용자가 사용하는 실제 운영 환경의 데이터 마트로 적합하다.</p>
<p>하지만, RDB 는 메모리가 부족하면 급격히 성능이 저하된다.</p>
</li>
</ol>
<h5 id="‘압축’-‘분산’-에-의해-지연-줄이기"><a href="#‘압축’-‘분산’-에-의해-지연-줄이기" class="headerlink" title="‘압축’, ‘분산’ 에 의해 지연 줄이기"></a>‘압축’, ‘분산’ 에 의해 지연 줄이기</h5><p>데이터를 가능한 작게 ‘압축’ 하고 여러 디스크에 ‘분산’ 함으로써 데이터 로드에 따른 지연을 줄일 수 있다. </p>
<p>분산된 데이터를 읽기 위해서는 멀티 코어를 활용해 디스크 I/O 를 병렬 처리하는 것이 효과적이다. </p>
<p>이런 아키텍쳐를 MPP (Massive Parallel Processing) 라고 한다. </p>
<p>대량 데이터를 분석하기 위해 데이터베이스에 널리 사용되고 있다. </p>
<p>ex ) Amazon Redshift, Google BigQuery</p>
<h5 id="행-지향-열-지향-데이터베이스"><a href="#행-지향-열-지향-데이터베이스" class="headerlink" title="행 지향, 열 지향 데이터베이스"></a>행 지향, 열 지향 데이터베이스</h5><ol>
<li><p>행 지향 데이터베이스</p>
<p>레코드 단위로 읽고 쓰기에 최적화.</p>
<p>테이블의 각 행을 하나의 덩어리로 디스크에 저장.</p>
<p>새 레코드 추가할 때마다 파일의 끝에 데이터를 쓸 뿐이여서 빠르게 추가 가능.</p>
<p>데이터 검색을 고속화하기 위해 인덱스 사용.</p>
<p>데이터 분석에서는 어떤 칼럼 사용될지 미리 알 수 없으므로, 인덱스를 작성해도 도움이 되지 않음.</p>
<p>ex ) Oracble, MySQL</p>
</li>
<li><p>열 지향 데이터베이스</p>
<p>칼럼 단위의 집계에 최적화.</p>
<p>데이터를 미리 칼럼 단위로 정리해서 필요한 칼럼만을 로드하여 디스크 I/O 를 줄임.</p>
<p>같은 칼럼에는 종종 유사한 데이터가 나열되어서 데이터 압축 효율도 우수.</p>
<p>ex ) Teradata, Amazon Redshift</p>
</li>
</ol>
<h5 id="MPP-데이터베이스"><a href="#MPP-데이터베이스" class="headerlink" title="MPP 데이터베이스"></a>MPP 데이터베이스</h5><ol>
<li><p>행 지향 데이터베이스</p>
<p>하나의 쿼리는 하나의 스레드에서 실행.</p>
<p>하나의 쿼리가 충분히 짧은 시간에 끝나는 것으로 가정하므로 하나의 쿼리를 분산 처리하는 상황은 가정하지 않음.</p>
</li>
<li><p>열 지향 데이터베이스</p>
<p>디스크에서 대량의 데이터를 읽기 때문에 한 번의 쿼리 실행 시간이 길다.</p>
<p>멀티 코어를 활용해서 고속화 하는것이 좋음.</p>
</li>
</ol>
<p>MPP 에서는 하나의 쿼리를 다수의 태스크로 분해하고, 이를 가능한 한 병렬로 수행한다.</p>
<p>예를 들어,</p>
<ol>
<li>1억 래코드로 이루어진 테이블의 합계를 계산하기 위해</li>
<li>10만 레코드로 구분하여 1000 개의 테스크로 나눈다.</li>
<li>각 테스크는 각각 독립적으로 10 만 레코드의 합계를 집계해서 </li>
<li>마지막 모든 결과를 모아 총 합계를 계산한다.</li>
</ol>
<p>MPP 를 사용한 데이터 집계는 CPU 코어수에 비례해서 고속화된다.</p>
<p>단, 디스크로부터의 로드가 병목 현상이 발생하지 않도록 데이터가 고르게 분산되어 있어야한다. </p>
<h2 id="3-애드-혹-분석과-시각화-도구"><a href="#3-애드-혹-분석과-시각화-도구" class="headerlink" title="3. 애드 혹 분석과 시각화 도구"></a>3. 애드 혹 분석과 시각화 도구</h2><ol>
<li>Jupyter Notebook</li>
<li>Redash</li>
<li>Superset</li>
<li>Kibana</li>
</ol>
<h2 id="4-데이터-마트의-기본-구조"><a href="#4-데이터-마트의-기본-구조" class="headerlink" title="4. 데이터 마트의 기본 구조"></a>4. 데이터 마트의 기본 구조</h2><h5 id="다차원-모델과-OLAP-큐브"><a href="#다차원-모델과-OLAP-큐브" class="headerlink" title="다차원 모델과 OLAP 큐브"></a>다차원 모델과 OLAP 큐브</h5><ol>
<li><p>RDB</p>
<p>표 형식으로 모델링된 데이터를 SQL 로 집계한다.</p>
</li>
<li><p>OLAP</p>
<p>다차원 모델의 데이터 구조를, MDX (Multidimensional Exrepssions) 등의 쿼리 언어로 집계한다.</p>
</li>
</ol>
<p>데이터 분석을 위해 만들어진 다차원의 데이터를 OLAP 큐브라고 한다. OLAP 큐브를 크로스 집계하는 구조가 OALP 이다.</p>
<p>컴퓨터 성능이 높지 않을 때는, 크로스 집계의 모든 조합을 데이터 베이스 안에 캐쉬해두고, 쿼리가 실행되면 이미 집계된 결과를 반환하는 구조였다.</p>
<p>최근에는 MPP 데이터베이스와 인 메모리 데이터베이스로, 사전에 계산해 둘 필요가 없다. MPP 데이터베이스에 다차원 모델의 개념이 없기 때문에, 이를 대신해 ‘비정규화 테이블’ 을 준비한다. 비정규화 테이블을 BI 도구에서 열어서 기존의 OLAP 과 동등한 시각화를 실현할 수 있다.</p>
<h5 id="트렌젝션-마스터-테이블"><a href="#트렌젝션-마스터-테이블" class="headerlink" title="트렌젝션, 마스터 테이블"></a>트렌젝션, 마스터 테이블</h5><p><img src="/image/bigdata_rdb_table.png" alt></p>
<ol>
<li><p>트랜젝션 테이블</p>
<p>시간과 함께 생성되는 데이터들을 기록</p>
</li>
<li><p>마스터 테이블</p>
<p>트랜젝션에서 참고되는 각종 정보를 기록</p>
</li>
</ol>
<h5 id="팩트-디맨젼-테이블"><a href="#팩트-디맨젼-테이블" class="headerlink" title="팩트, 디맨젼 테이블"></a>팩트, 디맨젼 테이블</h5><ol>
<li><p>팩트 테이블</p>
<p>트랜젝션 테이블 처럼, 사실이 기록된 것.</p>
<p>집계의 기반이 되는 숫자 데이터 등.</p>
</li>
<li><p>디멘젼 테이블</p>
<p>마스터 테이블 처럼, 참고되는 마스터 데이터.</p>
<p>데이터를 분류하기 위한 속성 값.</p>
</li>
</ol>
<h5 id="스타-스키마"><a href="#스타-스키마" class="headerlink" title="스타 스키마"></a>스타 스키마</h5><p><img src="/image/bigdata_star_scheme.png" alt></p>
<p>데이터 마트를 만들때는, 팩트 테이블을 중심으로 여러 디멘젼 테이블을 결합하는 것이 좋다.</p>
<p>스타 스키마를 사용하는 이유는,</p>
<ol>
<li><p>단순하고 이해하기 쉬워 데이터 분석이 쉽다.</p>
</li>
<li><p>성능 상의 이유</p>
<p>데이터 양이 증가하면 팩트 테이블은 디멘젼 테이블보다 훨씬 커져, 팩트 테이브이 메모리 용량을 초과한 시점에 디스크 I/O 가 발생하고 그 대기 시간으로 쿼리의 지연으로 이어진다. </p>
<p>그래서, 팩트 테이블에는 id 와 같은 키만을 남겨두고 그 이외의 나머지는 디멘젼 테이블로 옮긴다.</p>
</li>
</ol>
<h5 id="비정규화-테이블"><a href="#비정규화-테이블" class="headerlink" title="비정규화 테이블"></a>비정규화 테이블</h5><p>스타 스키마는 과거의 이야기이다. 성능 상의 문제는 열 지향 스토리지에 의해 해결된다.</p>
<p>MPP 데이터베이스와 같은 열 지향 스토리지의 보급으로, 칼럼의 수가 아무리 늘어나도 성능에 영향이 없다. </p>
<p>그래서, 처음부터 팩트 테이블에 모든 칼럼을 포함하고 쿼리의 실행 시에는 테이블 결합을 하지 않는 것이 간단하다. </p>
<p>스타 스키마에 비정규화를 진행해 모든 테이블을 결합한 팩트 테이블을 비정규화 테이블이라고 한다.</p>
<h5 id="테이블-추상화"><a href="#테이블-추상화" class="headerlink" title="테이블 추상화"></a>테이블 추상화</h5><p><img src="/image/bigdata_dimension.png" alt></p>
<p>비정규화 테이블을 준비했으면, 다차원 모델에 의해 추상화한다.</p>
<p>다차원 모델은 칼럼을 디멘젼과 측정값으로 분류한다. </p>
<ol>
<li><p>디멘젼</p>
<p>주로 날짜 및 문자열. </p>
<p>크로스 집계의 행이나 열로 사용</p>
</li>
<li><p>측정값</p>
<p>주로 숫자값.</p>
</li>
</ol>
<hr>
<p>빅데이터를 지탱하는 기술 &lt;니시다 케이스케&gt;</p>

                    
                        

                    
                    
                        <p>
                            <a href="/2019/12/30/big-data-chapter2/#post-footer" class="postShorten-excerpt_link link">
                                Comment and share
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a class="link-unstyled" href="/2019/12/30/big-data-chapter3/">
                            [빅데이터를 지탱하는 기술] 3장_빅데이터 분산처리
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2019-12-30T00:00:00+09:00">
	
		    Dec 30, 2019
    	
    </time>
    
        <span>in </span>
        
    <a class="category-link" href="/categories/big-data/">Big Data</a>


    
</div>

            </div>
            
                <div class="postShorten-content">
                    <h2 id="1-대규모-분산-처리의-프레임워크"><a href="#1-대규모-분산-처리의-프레임워크" class="headerlink" title="1. 대규모 분산 처리의 프레임워크"></a>1. 대규모 분산 처리의 프레임워크</h2><p>비구조화 데이터를 읽어 들여 열 지향 스토리지로 변환하는 과정에서, 데이터의 가공 및 압축을 위해 많은 컴퓨터 리소스가 소비된다. </p>
<p>그래서 사용하는 것이 Hadoop, Spark 같은 분산 처리 프레임워크다.</p>
<h5 id="구조화-데이터-비구조화-데이터-스키마리스-데이터"><a href="#구조화-데이터-비구조화-데이터-스키마리스-데이터" class="headerlink" title="구조화 데이터, 비구조화 데이터, 스키마리스 데이터"></a>구조화 데이터, 비구조화 데이터, 스키마리스 데이터</h5><ol>
<li><p>구조화 데이터</p>
<p>스키마가 명확하게 정의된 데이터.</p>
<p>기존의 데이터 웨어하우스에서는 항상 구조화 데이터로 축적하는 것이 일반적이었다.</p>
</li>
<li><p>비구조화 데이터</p>
<p>스키마가 없는 데이터.</p>
<p>이 상태로는 SQL 로 제대로 집계할 수 없다.</p>
</li>
<li><p>스키마리스 데이터</p>
<p>CSV, JSON, XML 등의 데이터는 서식은 정해져 있지만, 칼럼 수나 데이터 형은 명확하지 않다.</p>
</li>
</ol>
<h5 id="데이터-구조화의-파이프라인"><a href="#데이터-구조화의-파이프라인" class="headerlink" title="데이터 구조화의 파이프라인"></a>데이터 구조화의 파이프라인</h5><p><img src="/image/structured_data.png" alt></p>
<p>분산 스토리지에 수집된 데이터는 명확한 스키마를 갖지 않아 그대로는 SQL 로 집계할 수 없다. </p>
<p>그래서, 먼저 스키마를 명확하게 한 테이블 형식으로 변환해야한다.</p>
<p>구조화된 데이터는 데이터 압축률을 높이기 위해 열 지향 스토리지에 저장한다. </p>
<h5 id="열-지향-스토리지의-작성"><a href="#열-지향-스토리지의-작성" class="headerlink" title="열 지향 스토리지의 작성"></a>열 지향 스토리지의 작성</h5><p>Hadoop 의 열 지향 스토리지는,</p>
<ol>
<li><p>Apache ORC</p>
<p>처음에 스키마를 정한 후 데이터를 저장</p>
</li>
<li><p>Apache Parquet</p>
<p>스키마리스에 가까운 데이터 구조로 되어 있어서 JSON 같은 데이터도 그대로 저장</p>
</li>
</ol>
<h5 id="Hadoop"><a href="#Hadoop" class="headerlink" title="Hadoop"></a>Hadoop</h5><p><img src="/image/big_data_hadoop.png" alt></p>
<p>단일 소프트웨어가 아니라 분산 시스템을 구성하는 다수의 소프트웨어로 이루어진 집합체이다.</p>
<p>기본 구성 요소는,</p>
<ol>
<li><p>분산 파일 시스템</p>
<p>HDFS.</p>
<p>다수의 컴퓨터에 파일을 복사하여 중복성을 높이는 특징이 있다.</p>
</li>
<li><p>리소스 관리자</p>
<p>YARN, Mesos.</p>
<p>YARN 은 애플리케이션이 사용하는 CPU 코어와 메모리를 컨테이너라는 단위로 관리한다.</p>
<p>Hadoop 에서 분산 애플리케이션을 실행하면 YARN 이 클러스터 전체의 부하를 보고 비어 있는 호스트부터 컨테이너를 할당한다.</p>
<p>어느 애플리케이션에 얼마만큼의 리소스를 할당할 지 관리해서 모든 애플리케이션이 실행되도록 제어한다.</p>
</li>
<li><p>분산 데이터 처리</p>
<p>MapReduce, Tez.</p>
<p>MapReduce 도 YARN 위에서 동작하는 분산 애플리케이션 중 하나이다.</p>
</li>
</ol>
<h5 id="쿼리-엔진"><a href="#쿼리-엔진" class="headerlink" title="쿼리 엔진"></a>쿼리 엔진</h5><p><img src="/image/big_data_hive_mr.png" alt></p>
<p>하둡에서는 다수의 쿼리 엔진이 개발되었다. 총칭해서 SQL-on-Hadoop 이라고 한다.</p>
<p>SQL 등의 쿼리 언어에 의한 데이터 집계가 목적이면, 이를 위해 설계된 쿼리 엔진을 사용한다.</p>
<p>Apache Hive 가 대표적이다. 쿼리를 자동으로 MapReduce 프로그램으로 변환하는 소프트웨어이다.</p>
<p>시간이 걸리는 배치 처리에는 적합하나, 애드 혹 쿼리를 여러 번 실행하는데는 부적합하다. </p>
<p>왜냐하면 위 그림처럼, 스테이지가 바뀔 때 대기 시간이 있기 때문이다.</p>
<p><img src="/image/big_data_hive_tez.png" alt></p>
<p>Apache Tez 는 Hive 를 가속화하기 위해 개발되었다. 기존의 MapReduce 를 대체할 목적이다.</p>
<p>Hive on MR 은, 1회의 MapReduce 스테이지가 끝날 때까지 다음의 처리를 진행할 수 없다.</p>
<p>Hive on Tez 는, 위 그림처럼 스테이지의 종료를 기다리지 않고 데이터를 차례대로 후속 처리에 전달하여 쿼리 전체 실행 시간을 단축한다.</p>
<h5 id="대화형-쿼리엔진"><a href="#대화형-쿼리엔진" class="headerlink" title="대화형 쿼리엔진"></a>대화형 쿼리엔진</h5><p><img src="/image/big_data_presto.png" alt></p>
<p>Apache Impala 와 Presto 가 대표적이다.</p>
<p>YARN 과 같은 리소스 관리자를 사용하지 않고, SQL 의 실행만으로 분산처리를 구현한다.</p>
<p>순간 최대 속도를 높이기 위해 모든 오버 헤드가 제거되어, 사용할 수 있는 리소스를 최대한 활용하여 쿼리를 실행한다.</p>
<h5 id="Spark"><a href="#Spark" class="headerlink" title="Spark"></a>Spark</h5><p><img src="/image/big_data_spark.png" alt></p>
<p>MapReduce, Tez 모두 데이터 처리 과정에서 만들어진 중간 데이터를 디스크에 기록한다.</p>
<p>Spark 는 대량의 메모리를 활용하여 고속화를 실현한다.</p>
<p>Hadoop 을 대체하는 것이 아니라, MapReduce 를 대체하는 존재다.</p>
<h2 id="2-쿼리-엔진"><a href="#2-쿼리-엔진" class="headerlink" title="2. 쿼리 엔진"></a>2. 쿼리 엔진</h2><p><img src="/image/big_data_hive_presto.png" alt></p>
<h5 id="데이터-마트-구축의-파이프라인"><a href="#데이터-마트-구축의-파이프라인" class="headerlink" title="데이터 마트 구축의 파이프라인"></a>데이터 마트 구축의 파이프라인</h5><ol>
<li><p>Hive</p>
<p>분산 스토리지에 저장된 데이터를 구조화하고 열 지향 스토리지 형식으로 저장</p>
</li>
<li><p>Presto</p>
<p>완성한 구조화 데이터를 결합, 집계하고 비정규화 테이블로 만든 데이터 마트에 써서 보냄</p>
</li>
</ol>
<h5 id="Hive-에-의한-구조화-데이터-작성"><a href="#Hive-에-의한-구조화-데이터-작성" class="headerlink" title="Hive 에 의한 구조화 데이터 작성"></a>Hive 에 의한 구조화 데이터 작성</h5><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; CREATE EXTERNAL TABLE access_log_csv (...)</span><br></pre></td></tr></table></figure>

<p>CSV 파일을 읽어들여 외부 테이블을 정의한다.</p>
<p>외부테이블이란, Hive 의 외부에 있는 특정 파일을 참고해 마치 거기에 테이블이 존재하는 것처럼 읽어 들이기 위해 지정한다.</p>
<p>쿼리를 실행할 때마다 매번 텍스트를 읽어들이기 때문에 느리다. 그래서 열 지향 스토리지로 변환해야한다.</p>
<h5 id="열-지향-스토리지로의-변환"><a href="#열-지향-스토리지로의-변환" class="headerlink" title="열 지향 스토리지로의 변환"></a>열 지향 스토리지로의 변환</h5><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; CREATE TABLE access_log_orc STROED as ORC as SELECT ..</span><br></pre></td></tr></table></figure>

<p>텍스트 데이터를 열 지향 스토리지로 변환함으로써 데이터의 집계가 크게 고속화된다.</p>
<h5 id="Hive-로-비정규화-테이블-작성하기"><a href="#Hive-로-비정규화-테이블-작성하기" class="headerlink" title="Hive 로 비정규화 테이블 작성하기"></a>Hive 로 비정규화 테이블 작성하기</h5><p>데이터 구조화가 완료되면 데이터 마트를 구축해야한다. 즉, 테이블을 결합 및 집약해서 ‘비정규화 테이블’ 을 만든다.</p>
<p>Preso 와 같은 대화형 쿼리 엔진, Hive 같은 배치형 쿼리 엔진을 사용할 수 있다. 시간이 걸리는 배치 처리는 Hive 를 사용해야한다.</p>
<p>비정규화 테이블을 만드는 데 오랜 시간이 걸리므로, 가능한 효율적인 쿼리를 작성해야한다. </p>
<ol>
<li><p>서브 쿼리 안에서 레코드 수 줄이기</p>
<p>서브 쿼리 안에서 팩트 테이블을 작게 해야한다.</p>
<p>데이터의 양의 감소 시킨 후에 테이블을 결합하는 것이 쿼리 실행 시간을 단축시킨다.</p>
</li>
<li><p>데이터 편향 피하기</p>
<p>분산 시스템의 성능을 발휘하기 위해서, 모든 노드에 데이터가 균등하게 분산되도록 해야한다.</p>
</li>
</ol>
<h5 id="대화형-쿼리-엔진-Presto-구조"><a href="#대화형-쿼리-엔진-Presto-구조" class="headerlink" title="대화형 쿼리 엔진 Presto 구조"></a>대화형 쿼리 엔진 Presto 구조</h5><p>쿼리 실행의 지연을 감소시키는 목적으로 개발된 것이 대화형 쿼리 엔진이다.</p>
<p>Presto 의 특징은,</p>
<ol>
<li><p>플러그인 가능한 스토리지</p>
<p>다양한 데이터 소스를 테이블로 참고할 수 있다.</p>
<p>ex) 하나의 쿼리 안에서 분산 스토리지 상의 팩트 테이블과 MySQL 의 마스터 테이블을 조인할 있다.</p>
</li>
<li><p>CPU 처리의 최적화</p>
<p>코드의 실행을 멀티 스레드화되어 단일 머신에서 수백 태스크나 병렬로 실행된다.</p>
<p>그래서, CPU 이용 효율이 높다.</p>
</li>
<li><p>인 메모리 처리에 의한 고속화</p>
<p>모든 데이터 처리는 메모리 상에서 실시하고 메모리가 부족하면 여유가 생길 때까지 기다리거나 오류로 실패한다.</p>
</li>
</ol>
<h5 id="데이터-분석의-프레임워크-선택하기"><a href="#데이터-분석의-프레임워크-선택하기" class="headerlink" title="데이터 분석의 프레임워크 선택하기"></a>데이터 분석의 프레임워크 선택하기</h5><ol>
<li><p>MPP Database</p>
<p>비정규화 테이블을 고속으로 집계하는 데에 최적</p>
</li>
<li><p>Hive</p>
<p>데이터 양에 좌우되지 않는 쿼리 엔진</p>
</li>
<li><p>Presto</p>
<p>속도 중시, 대화식으로 특화된 쿼리 엔진</p>
</li>
<li><p>Spark</p>
<p>분산 시스템을 사용한 프로그래밍 환경.</p>
<p>ETL 프로세스에서 SQL 에 이르기 까지의 일련의 흐름을 하나의 데이터 파이프라인으로 기술 가능.</p>
</li>
</ol>
<h2 id="3-데이터-마트의-구축"><a href="#3-데이터-마트의-구축" class="headerlink" title="3. 데이터 마트의 구축"></a>3. 데이터 마트의 구축</h2><p>분산 시스템이 준비되면 시각화를 위해 데이터 마트를 만든다.</p>
<h5 id="팩트-테이블"><a href="#팩트-테이블" class="headerlink" title="팩트 테이블"></a>팩트 테이블</h5><p>팩트 테이블 작성 방법으로,</p>
<ol>
<li><p>추가</p>
<p>새로 도착한 데이터만을 증분으로 추가</p>
</li>
<li><p>치환</p>
<p>과거 데이터를 포함하여 테이블 전체 치환</p>
</li>
</ol>
<h5 id="테이블-파티셔닝"><a href="#테이블-파티셔닝" class="headerlink" title="테이블 파티셔닝"></a>테이블 파티셔닝</h5><p>위의 ‘추가’ 방법은 다음 문제가 있다.</p>
<ol>
<li>추가에 실패한것을 알아채지 못하면, 팩트 테이블의 일부에 결손</li>
<li>추가를 잘못해서 여러번 실행하면, 일부 중복</li>
<li>나중에 팩트 테이블 다시 만들고 싶으면, 관리 복잡</li>
</ol>
<p>그래서 파티셔닝이 필요하다.</p>
<p>하나의 테이블을 여러 물리적인 파티션으로 나눠서 파티션 단위로 정리하여 데이터를 쓰거나 삭제하는 것이다.</p>
<h5 id="집계-테이블"><a href="#집계-테이블" class="headerlink" title="집계 테이블"></a>집계 테이블</h5><p>팩트 테이블을 어느 정도 모아서 집계하면 데이터의 양이 줄어든다. 이것은 집계 테이블이라고 한다.</p>
<p>각 칼럼이 취하는 값의 범위란, 카디널리티이다. ‘성별’ 과 같이 취할 수 있는 값이 적은 것은 카디널리티가 작은 것이다.</p>
<p>집계 테이블을 작게 하려면 모든 칼럼의 카디널리티를 줄여야한다.</p>
<h5 id="스냅샷-테이블-이력-테이블"><a href="#스냅샷-테이블-이력-테이블" class="headerlink" title="스냅샷 테이블, 이력 테이블"></a>스냅샷 테이블, 이력 테이블</h5><p>마스터 데이터처럼 업데이트 될 가능성이 있는 테이블은,</p>
<p>정기적으로 테이블을 통째로 저장하는 스탭샷 테이블, 또는 변경 내용만을 저장하는 이력 테이블로 관리할 수 있다.</p>
<h5 id="디멘전을-추가하여-비정규화-테이블-완성시키기"><a href="#디멘전을-추가하여-비정규화-테이블-완성시키기" class="headerlink" title="디멘전을 추가하여 비정규화 테이블 완성시키기"></a>디멘전을 추가하여 비정규화 테이블 완성시키기</h5><p>팩트 테이블과 디멘젼 테이블을 결합하여 비정규화 테이블을 만든다.</p>
<hr>
<p>빅데이터를 지탱하는 기술 &lt;니시다 케이스케&gt;</p>

                    
                        

                    
                    
                        <p>
                            <a href="/2019/12/30/big-data-chapter3/#post-footer" class="postShorten-excerpt_link link">
                                Comment and share
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    <div class="pagination-bar">
    <ul class="pagination">
        
        
        <li class="pagination-number">page 1 of 1</li>
    </ul>
</div>

</section>



                <footer id="footer" class="main-content-wrap">
    <span class="copyrights">
        Copyrights &copy; 2020 junhee.ko. All Rights Reserved.
    </span>
</footer>

            </div>
            
        </div>
        


    
        
    

<div id="about">
    <div id="about-card">
        <div id="about-btn-close">
            <i class="fa fa-times"></i>
        </div>
        
            <img id="about-card-picture" src="/assets/images/profile.jpg" alt="Author&#39;s picture"/>
        
            <h4 id="about-card-name">junhee.ko</h4>
        
            <div id="about-card-bio"><p>Always Learning</p>
</div>
        
        
            <div id="about-card-job">
                <i class="fa fa-briefcase"></i>
                <br/>
                <p>Engineer</p>

            </div>
        
        
            <div id="about-card-location">
                <i class="fa fa-map-marker-alt"></i>
                <br/>
                Incheon
            </div>
        
    </div>
</div>

        
        
<div id="cover" style="background-image:url('/assets/images/cover.jpg');"></div>
        <!--SCRIPTS-->
<script src="/assets/js/jquery.js"></script>
<script src="/assets/js/jquery.fancybox.js"></script>
<script src="/assets/js/thumbs.js"></script>
<script src="/assets/js/tranquilpeak.js"></script>
<!--SCRIPTS END-->



    </body>
</html>
