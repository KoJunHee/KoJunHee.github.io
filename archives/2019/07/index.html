
<!DOCTYPE html>
<html lang="en">
    
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="junhee.ko">
    <title>Archives: 2019/7 - junhee.ko</title>
    <meta name="author" content="junhee.ko">
    
    
    
    <script type="application/ld+json">{}</script>
    <meta name="description" content="always learning">
<meta property="og:type" content="blog">
<meta property="og:title" content="junhee.ko">
<meta property="og:url" content="https://kojunhee.github.io/archives/2019/07/index.html">
<meta property="og:site_name" content="junhee.ko">
<meta property="og:description" content="always learning">
<meta property="og:locale" content="en">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="junhee.ko">
<meta name="twitter:description" content="always learning">
    
    
        
    
    
        <meta property="og:image" content="https://kojunhee.github.io/assets/images/profile.jpg"/>
    
    
    
    
    <!--STYLES-->
    <link rel="stylesheet" href="/assets/css/all.css">
    <link rel="stylesheet" href="/assets/css/jquery.fancybox.css">
    <link rel="stylesheet" href="/assets/css/thumbs.css">
    <link rel="stylesheet" href="/assets/css/tranquilpeak.css">
    <!--STYLES END-->
    

    
</head>

    <body>
        <div id="blog">
            <!-- Define author's picture -->


    
        
            
        
    

<header id="header" data-behavior="2">
    <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
    <div class="header-title">
        <a class="header-title-link" href="/ ">junhee.ko</a>
    </div>
    
        
            <a  class="header-right-picture "
                href="#about">
        
        
            <img class="header-picture" src="/assets/images/profile.jpg" alt="Author&#39;s picture"/>
        
        </a>
    
</header>

            <!-- Define author's picture -->



        
    

<nav id="sidebar" data-behavior="2">
    <div class="sidebar-container">
        
            <div class="sidebar-profile">
                <a href="/#about">
                    <img class="sidebar-profile-picture" src="/assets/images/profile.jpg" alt="Author&#39;s picture"/>
                </a>
                <h4 class="sidebar-profile-name">junhee.ko</h4>
                
                    <h5 class="sidebar-profile-bio"><p>Always Learning</p>
</h5>
                
            </div>
        
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link "
                             href="/ "
                            
                            title="Home"
                        >
                    
                        <i class="sidebar-button-icon fa fa-home" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Home</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link "
                             href="/all-categories"
                            
                            title="Categories"
                        >
                    
                        <i class="sidebar-button-icon fa fa-bookmark" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Categories</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link "
                             href="/all-archives"
                            
                            title="Archives"
                        >
                    
                        <i class="sidebar-button-icon fa fa-archive" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Archives</span>
                    </a>
            </li>
            
        </ul>
        
            <ul class="sidebar-buttons">
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link " href="https://github.com/kojunhee" target="_blank" rel="noopener" title="GitHub">
                    
                        <i class="sidebar-button-icon fab fa-github" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">GitHub</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link " href="https://facebook.com/kojunheee" target="_blank" rel="noopener" title="Facebook">
                    
                        <i class="sidebar-button-icon fab fa-facebook" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Facebook</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link " href="https://www.linkedin.com/in/junheeko" target="_blank" rel="noopener" title="LinkedIn">
                    
                        <i class="sidebar-button-icon fab fa-linkedin" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">LinkedIn</span>
                    </a>
            </li>
            
                <li class="sidebar-button">
                    
                        <a  class="sidebar-button-link " href="mailto:junheee.ko@gmail.com" target="_blank" rel="noopener" title="Mail">
                    
                        <i class="sidebar-button-icon fa fa-envelope" aria-hidden="true"></i>
                        <span class="sidebar-button-desc">Mail</span>
                    </a>
            </li>
            
        </ul>
        
    </div>
</nav>

            
            <div id="main" data-behavior="2"
                 class="
                        hasCoverMetaIn
                        ">
                
    <section class="postShorten-group main-content-wrap">
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a class="link-unstyled" href="/2019/07/16/rdd/">
                            [스파크2 프로그래밍] 2장_RDD
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2019-07-16T00:00:00+09:00">
	
		    Jul 16, 2019
    	
    </time>
    
        <span>in </span>
        
    <a class="category-link" href="/categories/spark/">Spark</a>


    
</div>

            </div>
            
                <div class="postShorten-content">
                    <h3 id="2-1-RDD"><a href="#2-1-RDD" class="headerlink" title="2.1 RDD"></a>2.1 RDD</h3><p>이번 장의 목표 : 데이터 모델로서의 추상적인 RDD 가 아닌, 프로그램 작성을 위한 API 관점에서 RDD 를 이해</p>
<h4 id="2-1-1-들어가기에-앞서"><a href="#2-1-1-들어가기에-앞서" class="headerlink" title="2.1.1 들어가기에 앞서"></a>2.1.1 들어가기에 앞서</h4><p>RDD 다루기 전에 알아야 할 것</p>
<ol>
<li><p>스파크 클러스터</p>
<p>클러스터 환경에서 동작하는 프로그램 작성할 때는 데이터가 여러 서버에 나눠져 병렬로 처리됩니다.</p>
</li>
<li><p>분산데이터로서의 RDD</p>
<p>RDD 는 회복력을 가진 분산 데이터 집합입니다.</p>
</li>
<li><p>불변성</p>
<p>한번 만들어진 RDD 는 어떤 경우에도 변경되지 않습니다.</p>
</li>
<li><p>파티션</p>
<p>RDD 데이터는 클러스터를 구성하는 여러 서버에 나누어서 저장됩니다. 스파크는 분할된 데이터를 파티션이라는 단위로 관리합니다.</p>
</li>
<li><p>HDFS</p>
</li>
<li><p>Job 과 Executor</p>
<p>스파크 프로그램을 실행하는 것을 스파크 잡을 실행한다고 합니다. 하나의 잡은 클러스터에서 병렬로 처리되고, 각 서버마다 익스큐터라는 프로세스가 생성됩니다. 각자 할당된 파티션을 처리합니다.</p>
</li>
<li><p>드라이버 프로그램</p>
<p>드라이버란, 스파크 컨텍스트를 생성하고 그 인스턴스를 포함하는 있는 프로그램입니다.</p>
</li>
<li><p>트랜스포메이션과 액선</p>
<p>트랜스포메이션은 RDD 의 형태를 변형하는 연산입니다. 액선은 어떤 동작을 수행해 그 결과로서 RDD 가 아닌 다른 타입의 결과를 변환하는 연산입니다.</p>
</li>
<li><p>지연 동작과 최적화</p>
<p>트랜스포메이션 연산은 RDD 를 사용하는 다른 액션 연산이 호출될때까지는 실제 트랜스포메이션을 수행하지 않습니다. 따라서, 실행 계획의 최적화가 가능합니다. <strong>사용자가 입력한 변환 연산들을 즉시 수행하지 않고 모아뒀다가 한 번에 실행함으로써 불필요한 네티워크 통신 비용을 줄일 수 있습니다.</strong></p>
</li>
<li><p>함수의 전달</p>
</li>
</ol>
<h4 id="2-1-2-스파크-컨텍스트-생성"><a href="#2-1-2-스파크-컨텍스트-생성" class="headerlink" title="2.1.2 스파크 컨텍스트 생성"></a>2.1.2 스파크 컨텍스트 생성</h4><p>스파크컨텍스트는 <strong>스파크 애플리케이션과 클러스터의 연결을 관리하는 객체</strong>로서 스파크 애플리케이션은 반드시 스파크 컨텍스트를 생성해야합니다. 클러스터 마스터 정보와 애플리케이션 이름은 반드시 지정해야하는 필수정보입니다.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SparkConf conf = <span class="keyword">new</span> SparkConf().setMaster(<span class="string">"local[*]"</span>).setAppName(<span class="string">"RDDCreateSample"</span>);</span><br><span class="line">JavaSparkContext sc = <span class="keyword">new</span> JavaSparkContext(conf);</span><br></pre></td></tr></table></figure>

<h4 id="2-1-3-RDD-생성"><a href="#2-1-3-RDD-생성" class="headerlink" title="2.1.3 RDD 생성"></a>2.1.3 RDD 생성</h4><p>RDD 생성 방법 두가지가 있습니다.</p>
<ol>
<li><p>드라이버 프로그램의 컬렉션 객체 이용</p>
<p>컬렉션 객체는 자바나 파이썬의 경우에는 리스트 타입을 사용합니다.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">JavaRDD&lt;String&gt; rdd = sc.parallelize(Arrays.asList(<span class="string">"a"</span>,<span class="string">"b"</span>,<span class="string">"c"</span>,<span class="string">"d"</span>,<span class="string">"e"</span>));</span><br></pre></td></tr></table></figure>
</li>
<li><p>파일과 같은 외부 데이터 이용</p>
<p>스파크는 내부적으로 하둡의 입력 및 출력 기능을 사용하므로 하둡이 다룰 수 있는 모든 입출력 유형을 다룰 수 있습니다.</p>
<p>파일의 각 줄은 한 개의 RDD 구성요소가 됩니다. 파일을 읽어들이는 과정은 하둡의 TextInputFormat 을 이용합니다. </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">JavaRDD&lt;String&gt; rdd = sc.textFile(<span class="string">"&lt;spark_home_dir&gt;/README.md"</span>);</span><br></pre></td></tr></table></figure>

</li>
</ol>
<h4 id="2-1-4-RDD-기본-액션"><a href="#2-1-4-RDD-기본-액션" class="headerlink" title="2.1.4 RDD 기본 액션"></a>2.1.4 RDD 기본 액션</h4><h5 id="2-1-4-1-collect"><a href="#2-1-4-1-collect" class="headerlink" title="2.1.4.1 collect"></a>2.1.4.1 collect</h5><p>RDD 의 모든 원소를 모아서 배열로 돌려줍니다. 반환 타입이 RDD 가 아닌 배열이므로 이 연산은 액션에 속하는 연산입니다. RDD 에 있는 모든 요소들이 collect 연산을 호출한 서버의 메모리에 수집됩니다. 따라서 충분한 메모리 공간이 확보되어야합니다.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">JavaRDD&lt;Integer&gt; rdd = sc.parallelize(Arrays.asList(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>));</span><br><span class="line">List&lt;Integer&gt; result = rdd.collect();</span><br><span class="line"><span class="keyword">for</span> (Integer i : result) System.out.println(i);</span><br></pre></td></tr></table></figure>

<h5 id="2-1-4-2-count"><a href="#2-1-4-2-count" class="headerlink" title="2.1.4.2 count"></a>2.1.4.2 count</h5><p>RDD 구성하는 전체 요소 개수 반환합니다.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">JavaRDD&lt;Integer&gt; rdd = sc.parallelize(Arrays.asList(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>));</span><br><span class="line"><span class="keyword">long</span> result = rdd.count();</span><br><span class="line">System.out.println(result);</span><br></pre></td></tr></table></figure>

<h4 id="2-1-5-RDD-트랜스포메이션"><a href="#2-1-5-RDD-트랜스포메이션" class="headerlink" title="2.1.5 RDD 트랜스포메이션"></a>2.1.5 RDD 트랜스포메이션</h4><p><strong>기존 RDD 를 이용해 새로운 RDD 를 생성</strong>하는 연산입니다.</p>
<ul>
<li>Map 연산<ul>
<li>요소간의 mapping 을 정의한 함수를 RDD 에 속하는 모든 요소에 적용해 새로운 RDD 를 생성</li>
</ul>
</li>
<li>그룹화 연산<ul>
<li>특정 조건에 따라 요소를 그룹화 하거나 특정 함수를 적용</li>
</ul>
</li>
<li>집합 연산<ul>
<li>RDD 에 포함된 요소를 하나의 집합으로 간주할 때 서로 다른 RDD 간에 합집합, 교집합 등을 계산</li>
</ul>
</li>
<li>파티션 연산<ul>
<li>RDD 의 파티션 개수를 조정</li>
</ul>
</li>
<li>필터, 정렬 연산<ul>
<li>특정 조건을 만족하는 요소만 선택하거나 각 요소를 정해진 기준에 따라 정렬</li>
</ul>
</li>
</ul>
<h4 id="2-1-6-RDD-액션"><a href="#2-1-6-RDD-액션" class="headerlink" title="2.1.6 RDD 액션"></a>2.1.6 RDD 액션</h4><p>RDD 메서드 중에서 <strong>결과값이 정수나 리스트, 맵 등 RDD가 아닌 다른 타입</strong>인 것들입니다. </p>
<p>트렌스포메이션에 속하는 메서드는 느긋한 평가 방식을 사용합니다. 즉, 호출한다고 즉시 실행되는 것이 아니라 액션으로 분류되는 메서드가 호출되어야하만 비로소 실행됩니다. 액션 메서드를 호출하는 시점이 돼서야 비로소 그동안 쌓여있던 ~개의 트렌스포메이션 연산이 순차적으로 시작됩니다.</p>
<p><strong>주의할점은, 액션 메서드를 여러번 호출하면 트렌스포메이션 메서드도 여러번 실행됩니다.</strong> 예를 들어, rdd1 이라는 RDD 에 map() 연산을 적용해 rdd2 라는 RDD 를 만들었다고 할때, rdd2 의 액션 메서드를 두번 호출하면 map() 연산도 두번 실행됩니다. 따라서, 반복 수행 성능을 개선하기 위해 캐쉬를 적절히 사용하고, 코드 작성시 반복 수행 가능성을 염두해야합니다.</p>
<h4 id="2-1-7-RDD-데이터-불러오기와-저장하기"><a href="#2-1-7-RDD-데이터-불러오기와-저장하기" class="headerlink" title="2.1.7 RDD 데이터 불러오기와 저장하기"></a>2.1.7 RDD 데이터 불러오기와 저장하기</h4><p>스파크는 하둡 API 를 기반으로 다양한 데이터 포맷과 파일 시스템을 지원합니다.</p>
<ul>
<li>파일 포맷<ul>
<li>텍스트 파일 / JSON / 하둡의 시퀀스 파일 / csv …</li>
</ul>
</li>
<li>파일 시스템<ul>
<li>로컬 파일 시스템 / HDFS / AWS 의 S3 / 오픈스택의 Swift …</li>
</ul>
</li>
</ul>
<h5 id="2-1-7-1-텍스트-파일"><a href="#2-1-7-1-텍스트-파일" class="headerlink" title="2.1.7.1 텍스트 파일"></a>2.1.7.1 텍스트 파일</h5><p>스파크는 다양한종류의 파일 시스템을 다룰수 있기 때문에 파일의 경로를 지정하는 방법도 파일 시스템의 종류에 따라 다릅니다.</p>
<ul>
<li>로컬파일 시스템<ul>
<li>file:///path</li>
</ul>
</li>
<li>HDFS<ul>
<li>hdfs://master:prot/path/..</li>
</ul>
</li>
<li>S3<ul>
<li>S3n://bucket/path</li>
</ul>
</li>
</ul>
<p><strong>주의할점은, 스파크가 클러스터를 이루는 다수의 서버 상에서 동작하기 때문에,  위에서 지정한 경로는 클러스터를 구성하는모든 서버에서 동일하게 접근 가능해야합니다.</strong> 따라서, 로컬 파일 시스템의경로를 데이터 위치로 지정하면 클러스터를 구성하는 모든 서버에서 “file:///data/sample.txt” 라는 경로를 통해 지정한 파일로 접근할 수 있어야합니다.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">JavaRdd&lt;Integer&gt; rdd = sc.parallelize(fillToN(<span class="number">1000</span>),  <span class="number">3</span>); <span class="comment">// 0~1000 까지의 숫자로 구성, 3개 파티션</span></span><br><span class="line">Class codec =. org.apache.hadoop.io.compress.GzipCodec.class;</span><br><span class="line"></span><br><span class="line"><span class="comment">// save</span></span><br><span class="line">rdd.saveAsTextFile(<span class="string">"&lt;path_to_save&gt;/sub1"</span>);</span><br><span class="line">rdd.saveAsTextFile(<span class="string">"&lt;path_to_save&gt;/sub2"</span>,  codec);</span><br><span class="line"></span><br><span class="line"><span class="comment">// load</span></span><br><span class="line">JavaRDD&lt;String&gt; rdd2 = sc.textFile(<span class="string">"&lt;path_to_save&gt;/sub1"</span>);</span><br></pre></td></tr></table></figure>

<h5 id="2-1-7-2-Object-File"><a href="#2-1-7-2-Object-File" class="headerlink" title="2.1.7.2 Object File"></a>2.1.7.2 Object File</h5><p>텍스트 파일을 사용하는 것과. 크게 다르지 않습니다. 다만, RDD 에 포함된 데이터를 오프젝트 파일로 다루기 위해서는 각 요소(오브젝트) 가 자바의 Serializable 인터페이스를 구현하고 있어야합니다. 그리고, 저장된 RDD 의 타입이 RDD[Int]  였다면, 이 파일으 읽어서 생성한 RDD 도 동일한 RDD[Int] 타입입니다.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">JavaRdd&lt;Integer&gt; rdd = sc.parallelize(fillToN(<span class="number">1000</span>),  <span class="number">3</span>); <span class="comment">// 0~1000 까지의 숫자로 구성, 3 개 파티션</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// save</span></span><br><span class="line">rdd.saveAsObjectFile(<span class="string">"&lt;path_to_save&gt;/sub_path"</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// load</span></span><br><span class="line">JavaRDD&lt;Integer&gt; rdd2 = sc.objectFile(<span class="string">"&lt;path_to_save&gt;/sub_path"</span>);</span><br><span class="line">System.out.println(rdd2.take(<span class="number">10</span>));</span><br></pre></td></tr></table></figure>

<h5 id="2-1-7-3-시퀀스-파일"><a href="#2-1-7-3-시퀀스-파일" class="headerlink" title="2.1.7.3 시퀀스 파일"></a>2.1.7.3 시퀀스 파일</h5><p>키와 값으로 구성된 데이터를 저장하는 이진 파일 포맷입니다. 하둡에서 자주 사용되는 대표적인 파일 포맷입니다. 시퀀스 파일로다루고자 하는 RDD의 데이터는 하둡의 Wriable 인터페이스를 구현하고 있어야합니다.</p>
<h4 id="2-1-8-클러스터-환경에서의-공유-변수"><a href="#2-1-8-클러스터-환경에서의-공유-변수" class="headerlink" title="2.1.8 클러스터 환경에서의 공유 변수"></a>2.1.8 클러스터 환경에서의 공유 변수</h4><p>하둡이나 스파크와 같이 클러스터 환경에서 동작하는 애플리케이션은 하나의 잡을 수행하기 위해 클러스터에 속한 다수의 서버에서 여러 개의 프로세스를 실행하므로 모든 프로세스가 공유할 수 있는 자원을 관리하기 쉽지 않습니다. <strong>이러한 프레임워크는 다수의 프로세스가 공유할 수 있는 읽기 자원과 쓰기 자원을 설정할 수 있도록 지원합니다.</strong></p>
<ul>
<li>하둡<ul>
<li>분산캐시 / 카운터</li>
</ul>
</li>
<li>스파크<ul>
<li>브로드캐스트 변수 / 어큐뮬레이텨</li>
</ul>
</li>
</ul>
<ol>
<li><p>브로드캐스트 변수</p>
<p>스파크 잡이 실행되는 동안 클러스터 내의 모든 서버에서 공유할 수 있는 읽기 전용 자원을 설정할 수 있는 변수입니다.</p>
<ul>
<li>먼저 공유하고자 하는 데이터를 포함하는 오브젝트를 생성</li>
</ul>
</li>
</ol>
<ul>
<li><p>이 오브젝트를 스파크컨텍스트의 broadcast() 메서드의 인자로 지정해 해당 메서드를 실행</p>
<ul>
<li><p>이렇게 생성된 브로드캐스트 변수를 사용할때는 생성한 브로드캐스트 변수의 value() 메서드를 통해 접근</p>
<p>클러스터 간에 공유할 변수가 있다고 해서 무조건 브로드캐스트 변수를 사용해야하는 것은 아닙니다. <strong>액션 연산을 수행할때 동일한 스테이지 내에서 실행되는 태스크 간에는 필요한 변수를 자동으로 브로드캐스트 변수를 이용해서 전달</strong>하기 때문에 명시적으로 브로드 캐스트 변수를 지정하지않아도 됩니다. </p>
</li>
</ul>
</li>
</ul>
<ol start="2">
<li><p>어큐뮬레이터</p>
<p>쓰기 동작을 위한것입니다. 클러스터 내의 모든 서버가 공유하는 쓰기 공간을 제공함으로써 <strong>각 서버에서 발생하는 특정 이벤트의 수를 세거나 관찰하고 싶은 정보를 모아두는 용도로 활용할 수 있습니다.</strong> </p>
<p>어큐뮬레이터를 생성하려면 org.apache.spark.util.AccumulatorV2 클래스를 상속받은 클래스를 정의하고, 이 클래스의 인스턴스를 생성합니다. 그리고 생성한 어큐뮬레이터 인스턴스를 스파크컨텍스트가 제공하는 register() method 를 이용해 등록합니다. </p>
<p>어큐뮬레이터를 사용할 때는 두 가지를 기억해야합니다.</p>
<p>첫 째, 어큐뮬레이터를 증가시키는 동작은 클러스터의 모든 데이터 처리 프로세스에서 가능하지만 데이터를 읽는 동작은 드라이버 프로그램 내에서만 가능합니다. 즉, RDD 의 트랜스포메이션이나 액션 연산 내부에는 어큐뮬레이터의 값을 증가시킬뿐 그 값을 참조해서 사용하는 것은 불가능합니다. </p>
<p>둘 째, 일부러 의도한 특별한 목적이없는 한 어큐뮬레이터는 액션 연산을 수행하는 메서드에서만 사용해야합니다. 왜냐하면 트렌스포매이션 연산은 액션 연산과 달리 하나의 잡 내에서 필요에 따라 수차례 반복 실행될 수 있기 때문입니다. 따라서 map(), flatmap() 과 같은 트랜스포메이션 연산 내용에 어큐뮬레이터의 값을 증가시키는 코드가 포함될 경우 정확하지 않은 데이터가 집계 될 수 있습니다.</p>
</li>
</ol>

                    
                        

                    
                    
                        <p>
                            <a href="/2019/07/16/rdd/#post-footer" class="postShorten-excerpt_link link">
                                Comment and share
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a class="link-unstyled" href="/2019/07/01/spark-cluster/">
                            [스파크2 프로그래밍] 3장_클러스터 환경
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2019-07-01T00:00:00+09:00">
	
		    Jul 01, 2019
    	
    </time>
    
        <span>in </span>
        
    <a class="category-link" href="/categories/spark/">Spark</a>


    
</div>

            </div>
            
                <div class="postShorten-content">
                    <h3 id="3-1-클러스터-환경"><a href="#3-1-클러스터-환경" class="headerlink" title="3.1 클러스터 환경"></a>3.1 클러스터 환경</h3><p>이번 장의 목표 : 분산 처리를 위한 시스템 아키텍처와, 그와 관련된 다양한 설정 및 매개변수를 이해하는 것.</p>
<p>스파크에서는 클러스터 자원을 관리해주는 역할을 하는 컴포넌트 클래스를 클러스터 매니저라고 합니다. 2.3.0 버젼에서는 네 종류의 클러스터 매니저가 사용되고 있습니다.</p>
<h4 id="3-1-1-클러스터-모드와-컴포넌트"><a href="#3-1-1-클러스터-모드와-컴포넌트" class="headerlink" title="3.1.1 클러스터 모드와 컴포넌트"></a>3.1.1 클러스터 모드와 컴포넌트</h4><p>스파크 클러스터는 <strong>드라이버 / 클러스터 매니저 / 익스큐터 / 워커 노드</strong>의 조합.</p>
<p>클러스터란, 여러 대의 서버가 네트워크를 통해 연결되어 마치 하나의 서버인 것처럼 동작하는 방식을 의미합니다. 전체 서버의 자원과 동작을 세밀하고 효율적으로 제어할 수 있는 별도 모듈을 클러스터 매니저라고 부릅니다.</p>
<p>스파크에서는  추상화된 클러스터 모델을 제공함으로써 사용하는 클러스터의 종류에 상관없이 일관된 방법으로 프로그램을 작성하고 클러스터를 관리할 수 있게 지원하고 있습니다.</p>
<p>“스파크 애플리케이션을 실행했다” 라고 하는 말은, 드라이버 프로그램에 있는 메인 함수를 실행해 스파크컨텍스트를 생성하고, 이를 이용해 각 워커 노드에 익스큐터 프로세스를 구동시켜 작업을 수행했다라는 뜻입니다. 즉, 익스큐터 하나가 사용할 자원(CPU 나 메모리) 을 정한뒤, 작업 실행 요청이 발생할 때마다 필요한 수만큼의 익스큐터를 할당하는 방식으로 자원을 할당합니다.</p>
<p>사용가능한 스파크컨텍스트가 준비돼 있다는 것은 클러스터 메니저와의 연동을 포함해서, 스파크 애플리케이션이 동작하는 데 필요한 다수의 서비스가 준비돼 있다는 의미이며, 이렇게 생성된 스파크컨텍스트를 이용해 RDD 나 브로드캐스트 또는 어큐뮬레이터 변수를 생성하고 사용할수 있음을 의미하는 것입니다.</p>
<p>쇼핑몰 방문자의 방문 로그를 분석하는 작업을 한다고 가정하고 작업을 수행하는 절차를 보겠습니다.</p>
<ol>
<li>드라이버 프로그램이 포함된 애플리케이션 코드를 작성</li>
<li>코드를 빌드하고 jar 나 zip 파일 등으로 패키징</li>
<li>생선한 패키지 파일을 스파크에서 제공하는 spark-submit 셸을 이용해 클러스터에 배포하고 실행</li>
<li>스파크 애플리케이션의 드라이버 프로그램이 실행되면 스파크컨텍스트가 생성되면서 클러스터 매니저와 연동되어 각 클러스터 서버에 작업을 처리하기 위한 프로세스를 생성. 이때 작업에 필요한 서버를 워커노드라고 하며, 각 워커노드에 생성된 프로세스를 익스큐터.</li>
<li>익스큐터가 생성되면 드라이버 프로그램은 작성된 프로그램에 의해 트렌스포메이션과 액션을 수행. 트렌스포메이션 연산이 호출할 때는 실제 작업을 수행하지 않고 액션 여산이 호출될 때만 실제 작업을 수행하느데, 이 작업 단위를 Job. 즉, 잡은 액션 연산의 수만큼 생성.</li>
<li>생성된 잡은 실제로 수행될 때 스테이지라는 단계로 나누어 실행. 스테이지를 나누는 기준이 되는 것은 데이터 셔플 필요 여부. 즉, 각 서버에 있는 데이터를 네트워크를 통해 다른 서버로 재배치해야 하는지 여부. 셔플이 발생하면 네트워크를 통해 대량의 데이터를 정렬하고 전송하는 등의 부하가 발생해 전체 작업 성능에 좋지 않은 영향을 끼치기 때문. 따라서, 데이터를 이동하지 않는 상태에서 처리할 수 있는 연산을 최대한 같은 스테이지로 묶어 처리하면 셔플 발생을 최소화.</li>
<li>각 스테이지는 여러 개의 태스크로 나눠진 후 분산처리를 위해 여러 익스큐터에 할당되며, 이 태스크가 실제 익스큐터에 전달되는 작업의 단위. 이 때, 익스큐터는 두 가지 역할 수행. 하나는 할당받은 테스크를 처리. 다른 하나는 이미 처리된 데이터를 나중에 빠르게 재사용할 수 있게 메모리에 저장.</li>
</ol>
<h4 id="3-1-2-클러스터-모드를-위한-시스템-구성"><a href="#3-1-2-클러스터-모드를-위한-시스템-구성" class="headerlink" title="3.1.2 클러스터 모드를 위한 시스템 구성"></a>3.1.2 클러스터 모드를 위한 시스템 구성</h4><p>일반적으로, 별도의 서버에 애플리케이션을 배포한 뒤 해당 서버에서 드라이버 프로그램을 구동하고 실제 데이터 처리는 스파크 클러스터에서 수행되게 하는 방법을 사용합니다. 이렇게, <strong>클러스터에 작업을 요청하는 서버를 배치 서버 또는 클라이언트 서버라고 부릅니다.</strong> </p>
<p>다음은 클러스터 구성에 필요한 서버의 종류입니다.</p>
<ol>
<li><p>로컬 개발 서버</p>
</li>
<li><p>애플리케이션 실행 서버</p>
<p>spark-submit, spark-shell 등의 스크립트를 이용해 스파크 어플리케이션을 맨 처음 실행하는 서버.</p>
</li>
<li><p>클러스터 서버</p>
<p>클러스터 구성에 참여하는 서버. 클러스터 운영을 위한 마스터 서버의 역할을 수행하거나, 실제 데이터를 처리하고 필요에 따라 저장하는 워커 노드의 역할을 수행하는 서버입니다. </p>
</li>
</ol>
<h4 id="3-1-3-드라이버-프로그램과-디플로이-모드"><a href="#3-1-3-드라이버-프로그램과-디플로이-모드" class="headerlink" title="3.1.3 드라이버 프로그램과 디플로이 모드"></a>3.1.3 드라이버 프로그램과 디플로이 모드</h4><p>모든 스파크 어플리케이션에는 스파크컨텍스트를 생성하는 코드가 포함돼 있는데, 이 부분이 포함된 프로그램을 가리켜 드라이버 프로그램이라고 합니다. 클러스터에서 실행할 때는 클러스터 매니저에게 애플리케이션 실행을 요청합니다. (“제출한다” 라고 합니다.)</p>
<p>작업 요청을 받은 클러스터 매니저는 필요한 자원을 할당하고 작업을 수행하는데, 클러스터 매니저마다 다른 형태로 애플리케이션을 실행시킬 수 있습니다. 이처럼 서로 다른 실행 모드를 ‘디플로이 모드’ 라고 합니다. ‘클라이언트 디플로이 모드’ 와 ‘클러스터 디플로이 모드’ 가 있습니다.</p>
<p><strong>클라이언트 디플로이 모드란, 애플리케이션을 실행한 프로세스 내부에서 드라이버 프로그램을 구동하는 것</strong>으로, 드라이버 프로그램은 작업을 요청한 클라이언트 서버 프로세스에 포함되어 실행됩니다. 따라서 스파크 어플리케이션을 실행했던 콘솔을 닫아 버리거나 기타 다른 방법으로 프로세스를 중지시키면 스파크컨텍스트도 함께 종료되면서 수행 중이던 모든 스파크 잡이 중지 됩니다.</p>
<p><strong>클러스터 디폴로이 모드란, 애플리케이션을 실행한 프로세스는 클러스터 매니저에게 작업 실행만 요청하고 즉시 종료되며, 실제 드라이버 프로그램의 실행은 클러스터 내부에서 실행되는 것</strong>을 의미합니다. 클러스터 매니저에게 잡이 전달되고 최초 어플리케이션을 실행했던 콘솔들 닫아 버리거나 기타 다른 방법으로 프로세스를 중지시켜도 전체 스파크 어플리케이션의 동작에는 영향을 끼치지 않습니다.</p>
<h3 id="3-2-클러스터-매니저"><a href="#3-2-클러스터-매니저" class="headerlink" title="3.2 클러스터 매니저"></a>3.2 클러스터 매니저</h3><p>스파크의 클러스터 모드를 구성하는 컴포넌트. 중 하나로 여러 대의 서버로 구성된 클러스터 환경에서 다수의 어플리케이션이 함께 구동될 수 있게 어플리케이션 간의 CPU 나 메모리, 디스크와 같은 컴퓨팅 자원을 관리해주는 역할을 합니다. 하둡의 Yarn 이나 아파치 Mesos 등이 있습니다.</p>
<h4 id="3-2-1-스탠드얼론-클러스터-매니저"><a href="#3-2-1-스탠드얼론-클러스터-매니저" class="headerlink" title="3.2.1 스탠드얼론 클러스터 매니저"></a>3.2.1 스탠드얼론 클러스터 매니저</h4><p>스파크나 하둡과 같이 클러스터 환경에서 동작하는 대부분의 프레임워크는 실행 모드라는 개념을 가지고 있습니다. 즉, 개발 및 테스트를 위해서는 1대의 단독 서버 혹은 개인 PC 에서 애플리케이션을 실행하고, 실 서비스에서는 여러 서버로 구성된 클러스터 환경에서 동일한 어플리케이션을 실행할 수 있는 것입니다.</p>
<h5 id="3-2-1-1-개요"><a href="#3-2-1-1-개요" class="headerlink" title="3.2.1.1 개요"></a>3.2.1.1 개요</h5><p>스탠드얼론 클러스터 매니저는 마스터/슬레이브 개념으 도입해 <strong>하나의 마스터 인스턴스와 다수의 슬레이브 인스턴스로 클러스터를 구성</strong>합니다. 이를 스파크의 클러스터 컴포넌트 모넬 관점에서 보면, 마스터 인스턴스가 클러스터 매니저 컴포넌트에 해당하고 슬레이브 인스턴스는 워커 노드에 해당합니다.</p>
<p>마스터는 클러스터 매니저의 역할을 담당해서 <strong>클라이언트의 요청을 받아 필요한 서버 자원을 할당하고 슬레이브의 작업 실행을 관리하는 기능을 수행</strong>합니다. 슬레이브는 Worker 의 역학을 담당하면서 <strong>Executor 와 Task 를 실행해 데이터에 대한 실제 처리와 저장</strong>을 수행합니다.</p>
<p>클러스터를 시작하는 방법은, 마스터 인스턴스를 구동한 뒤에. 마스터의 접속 주소를 슬레이브 인스턴스의 실행 인자로 전달하면서 슬레이브 프로세스를 구동시킵니다. 스파크 어플리케이션을 동작시키는 경우에는 마스터 서버의 주소를 maseter 속성 값으로 지정해서 실행합니다.</p>
<h5 id="3-2-1-2-설치"><a href="#3-2-1-2-설치" class="headerlink" title="3.2.1.2 설치"></a>3.2.1.2 설치</h5><p>스탠드얼론 클러스터 매니저를 사용하려면 클러스터를 구성하는 모든 서버에 스파크가 설치되어 있어야합니다.</p>
<p>설치가 끝나면 먼저 마스터 인스턴스를 실행한 후 슬레이브 인스턴스를 실행합니다. 실행 스크립트를 이용하려면, 마스터와 슬레이브 프로세스가 실행된 서버 간에 패스워드 없이 SSH 접속이 가능하도록 설정해야합니다.</p>
<h5 id="3-2-1-3-클러스터-매니저-실행"><a href="#3-2-1-3-클러스터-매니저-실행" class="headerlink" title="3.2.1.3 클러스터 매니저 실행"></a>3.2.1.3 클러스터 매니저 실행</h5><p>마스터 서버에 접속한 뒤 스파크 홈 아래에 있는 sbin 디렉토리로 이동합니다. 이 디렉토리에는 스탠드얼론 클러스터 매니저의 실행과 종료를 위한 다수의 실행 스크립트가 있습니다.</p>
<ul>
<li>마스터 인스턴스와 슬레이브 인스터스를 개별적으로 실행할 때 사용할 수 있는 스크립트</li>
<li>마스터 서버를 비롯한 다수의 슬레이브 인스턴스를 한번에 실행하거나 종료할 때 사용하는 스크립트</li>
</ul>
<h5 id="3-2-1-4-애플리케이션-실행-서버-준비"><a href="#3-2-1-4-애플리케이션-실행-서버-준비" class="headerlink" title="3.2.1.4. 애플리케이션 실행 서버 준비"></a>3.2.1.4. 애플리케이션 실행 서버 준비</h5><p>이제 클러스터 매니저를 이용해 원하는 작업을 실행해볼 차례입니다. 작업을 실행하는 방법은 세 가지가 있는데, 그 전에 애플리케이션을 배포해서 실행할 서버를 결정해야합니다. 클러스터를 구성하는 서버 중 하나를 사용할 수도 있고 별도의 서버를 사용할 수 있는데 일반적으로 별도의 서버를 사용합니다. </p>
<h5 id="3-2-1-5-애플리케이션-실행"><a href="#3-2-1-5-애플리케이션-실행" class="headerlink" title="3.2.1.5 애플리케이션 실행"></a>3.2.1.5 애플리케이션 실행</h5><p>스파크 셸 / pyspark / spark-submit 세 가지 방법이 있습니다.</p>
<h6 id="3-2-1-5-1-스파크-셸"><a href="#3-2-1-5-1-스파크-셸" class="headerlink" title="3.2.1.5.1 스파크 셸"></a>3.2.1.5.1 스파크 셸</h6><p>컴파일이나 배포 과정을 거치지 않고 셸에서 직접 코드를 입력하고 그 결과를 즉시 확인할 수 있는 인터랙티브한 개발환경을 제공함으로써 코드의 작성과 디버깅을 손쉽게 할 수 있습니다.</p>
<p>스파크 셸도 일종의 스파크 어플리케이션이기 때문에 마스터 정보를 전달해야합니다.  클러스터 마스터 URL 이 ‘spark://svr01:7077’ 이면, 애플리케이션 실행 서버에서 아래와 같이 실행합니다.</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ./bin/spark-shell --master spark://svr01:7077</span><br></pre></td></tr></table></figure>

<h6 id="3-2-1-5-2-pyspark"><a href="#3-2-1-5-2-pyspark" class="headerlink" title="3.2.1.5.2 pyspark"></a>3.2.1.5.2 pyspark</h6><p>스파크 셸과 같은 기능을 수행하며 파이썬 언어를 사용하는 경우에 사용할 수 있습니다.</p>
<h6 id="3-2-1-5-3-spark-submit"><a href="#3-2-1-5-3-spark-submit" class="headerlink" title="3.2.1.5.3 spark-submit"></a>3.2.1.5.3 spark-submit</h6><p>스파크 어플리케이션을 실행하는데 필요한 각종 설정 값을 명확하고 일관된 방식으로 정의할 수 있기 때문에, 자바 스칼라 파이썬 등의 언어로 작성된 어플리케이션을 동일한 방법으로 실행가능합니다.</p>
<h5 id="3-2-1-6-디플로이-모드"><a href="#3-2-1-6-디플로이-모드" class="headerlink" title="3.2.1.6 디플로이 모드"></a>3.2.1.6 디플로이 모드</h5><p>디플로이 모드를 지정하는 방법은 클러스터 매니저의 종류에 따라 다를수 있는데 스탠드얼론 매니저를 사용할 경우 –deploy-mode 옵션을 사용해 cluster 와 client 모드 중 하나를 지정할 수 있습니다.</p>
<h5 id="3-2-1-7-주요-설정"><a href="#3-2-1-7-주요-설정" class="headerlink" title="3.2.1.7 주요 설정"></a>3.2.1.7 주요 설정</h5><h5 id="3-2-1-8-HA"><a href="#3-2-1-8-HA" class="headerlink" title="3.2.1.8 HA"></a>3.2.1.8 HA</h5><p>스탠드얼론 클러스터 모드는 하나의 마스터 + 다수의 워쿼 로 구성됩니다. 마스터는 각 워커에 작업을 지시하고, 작업 수행 상태를 모니터링하다가 워커 중 하나에 문제가 생기면, 그 워카가 수행하던 작업을 다른 워커에 전달해서 전체 작업이 문제 없이 처리되게 합니다. 하지만 워커가 아닌 마스터에 문제가 생기면 작업은 복구하지 못하고 실패합니다.</p>
<p>스탠드얼론 클러스터 모드는 주키퍼를 사용해 다수의 마스터 서버를 동일한 클러스터의 마스터로 지정하고, 문제가 발생할 경우 다른 마스터로 전환할 수 있게 함으로써 단일 마스터 서버 운영으로 인한 장애 발생 가능성을 낮출 수 있습니다.</p>
<p>#####3.2.1.9 단일 노드 복구</p>
<p>로컬 디렉토리의 특정 위치에 클러스터의 상태 정보를 저장해뒀다가 장애가 발생하면 저장된 정보를 이용해 다시 예전 상태를 복구하는 방식입니다. </p>
<h4 id="3-2-2-아파치-매소스"><a href="#3-2-2-아파치-매소스" class="headerlink" title="3.2.2 아파치 매소스"></a>3.2.2 아파치 매소스</h4><h4 id="3-2-3-얀"><a href="#3-2-3-얀" class="headerlink" title="3.2.3 얀"></a>3.2.3 얀</h4><p>하둡에서 제공하는 클러스터 자원 관리 서비스입니다. 얀의 등장 배경을 살펴봅시다.</p>
<p>하둡은 잡 트랙커와 테스크 트래커 프로세스를 이용해서 하둡의 대표적인 애플리케이션인 맵리듀스 어플리케이션을 실행하는 방법을 사용하고 있었습니다. 두 프로세스는 마스터와 슬레이브 관계로, 하나의 잡 트레커가 다수의 태스크 트레커를 관리하는 형태로 동작했습니다. 클러스터에서 수행되는 모든 잡은 잡 틀래커 프로세스를 통해 처리됐습니다.</p>
<p>하지만 잡 트래커는 전체 클러스터에서 하나만 실행됐기 때문에 <strong>하나의 클러스터에서 여러 개의 에플리케이션이 실행될 경우 하나의 잡 트래커가 전체 어플리케이션의 자원 할당, 실행 제어, 모니터링, 히스토리 관리에 이르는 모든 처리를 수행해야하는 문제</strong>가 있었습니다.</p>
<p>결국 이렇게 하나의 마스터 프로세스에 의존하는 배치 프로세싱 모델은 마스터 프로세스의 한계가 전체 클러스터의 한계로 이어지는 결과를 가져왓습니다.</p>
<p>얀은 이러한 기존 맵리듀스 프레임워크의 문제점을 개선하기 위해 제안된 것으로, <strong>잡 트래러가 가지고 있던 자원 관리와 작업처리 모니터링 및 히스토리 관리 기능을 각각 별개의 서비스로 분리</strong>한 것입니다. </p>
<h5 id="3-2-3-1-개요"><a href="#3-2-3-1-개요" class="headerlink" title="3.2.3.1 개요"></a>3.2.3.1 개요</h5><p>크게 봤을 때, 얀은 <strong>클라이언트 프로그램 / 리소스 메니저 / 노드 매니저 / 애플리케이션 마스터 / 컨테이너</strong> 등의 컴포넌트로 나눠볼 수 있습니다.</p>
<p>얀 어플리케이션 실행 과정은 다음과 같습니다.</p>
<ol>
<li>얀은 전체 크러스터의 자원을 관리하는 리소스 매니저와 각 노드의 자원을 관리하는 노드 매니저라는 두 종류의 데몬 프로세스로 구성돼있습니다. 노드 매니저는 클러스터를 구성하는각 노드에서 동작하는 데몬으로 해당 노드의 자원을 관리하고 노드가 보유하고 있는 자원 현황을 주기적으로 리소스 메니저에게 보고해서 리소트 메니저가 전체 클러스터의 자원현황을 알 수 있게 합니다. 리소스 매니저는 노드 매니저로부터 각 노드의 리소스 현황을 보고 받고 이를 관리하며 클러스터 내의 모든 어플리케이션의 실행에 필요한 자원을 할당하고 관리합니다.</li>
<li>클라이언트 프로그램은 리소스 매니저에게 어플리케이션 (==어플리케이션 마스터) 를 실행해달라고 요청하는 프로그램입니다. 일반적으로 클라이언트 프로그램을 실행하는 서버는 클러스터에 속하지 않는 별도의 외부서버입니다.</li>
<li>클라이언트 프로그램으로부터 어플리케이션 실행 요청을 받은 리소스 매니저는 노드 매니저 중에서 어플리케이션 마스터를 실행할 수 있는, 가용 자원이 있는 노드 매니저를 찾아서 어플리케이션 마스터의 실행을 요청합니다. 실행된 어플리케이션 마스터는 리소스 매니저에게 등록하는 절차를 거치며, 리소스 매니저는 이렇게 등록된 어플리케이션 마스터를 통해 전체 리소스를 관리합니다.</li>
<li>리소스 매니저로부터 어플리케이션 마스터 실행 요청을 받은 노드 매니저는 어플리케이션 마스터 생성에 필요한 자원을 컨테이너라는 단위로 할당하고 컨테이너에 할당된 자원 (CPU 나 메모리) 를 이용해 어플리케이션 마스터를 실행한 뒤 자원 할당 결과를 리소스 메니저에게 보고합니다.</li>
<li>어플리케이션 마스터가 실행되면 해당 어플이케이션에서 필요한 작업을 수행합니다. </li>
</ol>
<p>스파크의 클러스터 컴포넌트 모델과 얀의 컴포넌트 모델은 어떤 관계가 있을까?</p>
<ol>
<li>클라이언트 프로그램이 실행되면서 얀 리소스 매니저에게 애플리케이션을 실행해 줄것을 요청하면 리로스 매니저가 적절한 노드 매니저 하나를 선택해 애플리케이션 마스터를 실행. 이때 어플리케이션 마스터는 스파크 애플리케이션을 위해 작성된 것으로 클러스터 디플로이 방식이면 드라이버 프로그램이 같은 프로세스 내에서 수행.</li>
<li>애플리케이션 마스터는 리소스 매니저에게 스파크 애플리케이션 실행에 필요한 자원을 요청해 이를 수행시킬 노드 목록을 전달받고, 해당 노드 매니저에게 필요한 자원 할당 및 프로세스 실행 요청.</li>
<li>애플리케이션 마스터로부터 애플리케이션 프로세스 실행 요청을 받은 노드 매니저들은 필요한 자원은 담고 있는 컨테이너를 할당하고 요청받은 애플리케이션 프로세스 실행. 실행되는 애플리케이션 프로세스가 곧 스파크의 익스큐터.</li>
<li>익스큐터가 실행되면 스파크 드라이버 프로그램이 생성된 익스큐터 프로세스를 이용해 스파크의 테스트 수행.</li>
</ol>
<h5 id="3-2-3-2-설치"><a href="#3-2-3-2-설치" class="headerlink" title="3.2.3.2 설치"></a>3.2.3.2 설치</h5><h5 id="3-2-3-3-스파크-잡-실행"><a href="#3-2-3-3-스파크-잡-실행" class="headerlink" title="3.2.3.3 스파크 잡 실행"></a>3.2.3.3 스파크 잡 실행</h5><p>다른 클러스터 매니저와 같습니다. 다만, 클러스터 마스터 URL 을 직접 지정하는 방법이 다릅니다.</p>
<h6 id="3-2-3-3-1-스파크-쉘"><a href="#3-2-3-3-1-스파크-쉘" class="headerlink" title="3.2.3.3.1 스파크 쉘"></a>3.2.3.3.1 스파크 쉘</h6><p>마스터에 대한 접속 정보를 하둡의 설정 파일을 통해 읽어드리므로, –master 매개변수에 그냥 ‘yarn’ 이라고만 입력하고 대신 하둡의 설정파일 (core-site.xml, yarn-site.xml 등) 이 있는 디렉토리 경로를 ‘HADOOP_CONF_DIR’ 또는 ‘YARN_CONF_DIR’ 이라는 환경변수로 등록해야합니다.</p>
<h5 id="3-2-3-3-2-pyspark"><a href="#3-2-3-3-2-pyspark" class="headerlink" title="3.2.3.3.2 pyspark"></a>3.2.3.3.2 pyspark</h5><h5 id="3-2-3-3-3-spark-submit"><a href="#3-2-3-3-3-spark-submit" class="headerlink" title="3.2.3.3.3 spark-submit"></a>3.2.3.3.3 spark-submit</h5><h5 id="3-2-3-4-디플로이-모드"><a href="#3-2-3-4-디플로이-모드" class="headerlink" title="3.2.3.4 디플로이 모드"></a>3.2.3.4 디플로이 모드</h5><p>다른 클러스터 매니저와 크게 다르지 않아서, –deploy-mode 매개변수의 값으로 client 나 cluster 를 지정합니다.</p>
<p>클라이언트 디플로이 모드이면, 얀 클라이언트 프로그램에서 실행되는 드라이버가 애플리케이션 동작을 제어하고 얀의 어플리케이션 마스터는 단순히 노드 매니저에게 필요한 자원을 요청하는 역할을 합니다.</p>
<h5 id="3-2-3-5-얀-컨테이너-로그-설정"><a href="#3-2-3-5-얀-컨테이너-로그-설정" class="headerlink" title="3.2.3.5 얀 컨테이너 로그 설정"></a>3.2.3.5 얀 컨테이너 로그 설정</h5><p>스파크 어플리케이션이 실행되면 드라이버 프로그램이 제공하는 (드라이버 프로그램이 생성한 스파크 컨텍스트가 제공하는) 모니터링 페이지를 통해 해당 어플리케이션의 모니터링 및 디버깅에 필요한 각종 정보를 확인할 수 있습니다.</p>
<h4 id="3-2-4-히스토리-서버와-매트릭스"><a href="#3-2-4-히스토리-서버와-매트릭스" class="headerlink" title="3.2.4 히스토리 서버와 매트릭스"></a>3.2.4 히스토리 서버와 매트릭스</h4><p>스파크컨텍스트가 제공하는 모니터링 페이지는 애플리케이션이 실행 중일 때만 접속가능합니다.</p>
<p>스파크에서는 이렇게 애플리케이션이 종료된 후에도 과거 이벤트 로그를 활용해 어플리케이션에 대한 정보를 볼 수 있게 하는 히스토리 서버를 제공합니다.</p>
<p>“–master” 옵션은 스파크가 사용할 <strong>클러스터의 마스터 정보를 지정하는 옵션</strong>입니다. 사용하는 클러스터 마스터 ( 혹은 메니저) 정보를 지정하는 옵션입니다.</p>
<p>만약 클러스터가 아닌 단일서버에서 동작시킬 경우에 “local” 이라고 입력합니다. 이 경우, 스파크 잡은 하나의 서버에서 하나의 스레드만 이용해서 동작합니다. 따라사 여러개의 스레들르 이용하려면 “local[2]” 처럼 지정합니다. 스레드 두 개를 사용한다는 의미입니다. “local[*]” 는 사용 가능한 모든 스레드를 사용합니다.</p>

                    
                        

                    
                    
                        <p>
                            <a href="/2019/07/01/spark-cluster/#post-footer" class="postShorten-excerpt_link link">
                                Comment and share
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    
    <article class="postShorten postShorten--thumbnailimg-bottom">
        <div class="postShorten-wrap">
            
            <div class="postShorten-header">
                <h1 class="postShorten-title">
                    
                        <a class="link-unstyled" href="/2019/07/01/spark-config/">
                            [스파크2 프로그래밍] 4장_스파크 설정
                        </a>
                    
                </h1>
                <div class="postShorten-meta">
    <time datetime="2019-07-01T00:00:00+09:00">
	
		    Jul 01, 2019
    	
    </time>
    
        <span>in </span>
        
    <a class="category-link" href="/categories/spark/">Spark</a>


    
</div>

            </div>
            
                <div class="postShorten-content">
                    <ul>
<li>애플리캐이션 단위로 설정<ul>
<li>Spark Properties 사용</li>
</ul>
</li>
<li>각 서버 단위로 설정<ul>
<li>서버의 환경 변수를 이용해 등록</li>
</ul>
</li>
</ul>
<h3 id="4-1-스파크-프로퍼티"><a href="#4-1-스파크-프로퍼티" class="headerlink" title="4.1 스파크 프로퍼티"></a>4.1 스파크 프로퍼티</h3><p>스파크 프로퍼티는 개별 애플리캐이션 실행관 관련된 설정값을 정의하는 곳입니다. 스파크 컨텍스트를 생성할 때 사용했던 SparkConf 인스턴스나 자바 시스템 프로퍼티를 이용해 등록 가능합니다.</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> sparkConf = <span class="keyword">new</span> <span class="type">SparkCont</span>().setAppName(<span class="string">"myApp"</span>)</span><br><span class="line"><span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(sparkConf)</span><br></pre></td></tr></table></figure>

<p>SparkConf 클래스는 스파크 애플리캐이션 실행관 관련된 다양한 설정 정보를 키와 값 형태로 등록할수 있는 함수(set / get) 을 제공합니다. 애플리캐이션 이름과 같이 반드시 지정해야 하는 주요 속성에 대해서는 setMaster, setAppName 과 같은 별도의 메서드를 제공합니다.</p>
<p>SparkConf 를 이용하는 것의 문제점은 애플리캐이션의 비즈니스 로직과는 직접 관련이 없는 익스큐터의 메모리 설정이나 코어 수 할당관 관련된 부분이 항상 프로그램 코드에 포함돼 있어야 한다는 것입니다. 그래서, 프로그램이 실행되는 시점에 동적으로 필요한 설정값을 설정할수 있는 두 가지 방법이 있습니다.</p>
<ol>
<li><p>spark-shell / spar-submit</p>
<p>스크립트 실행시 사전에 지정된 형식에 따라 명령행 옵션을 이용해 원하는 설정값을 지정합니다.</p>
</li>
<li><p>설정 정보가 담긴 파일 사용</p>
<p>스파크 홈의 conf 디렉터리 아래에 spark-defaults.conf 파일을 만들고 이 파일에 설정 정보를 등록해 두면 스파크 쉘이나 sprak-submit 스크립트가 해당 파일의 내용을 읽습니다. </p>
</li>
</ol>
<h3 id="4-2-환경변수"><a href="#4-2-환경변수" class="headerlink" title="4.2 환경변수"></a>4.2 환경변수</h3><p>각 서버 단위로 적용돼야 하는 환경 정보는 각 서버의 환경 변수를 이용해 등록할 수 있습니다. 예를 들어, 자바의 설치 경로와 같은 정보가 서버별로 다르게 설정돼 있다면 환경변수를 이용해 해당 서버의정보를 변경할 수 있습니다. 환경 변수 ex )</p>
<ul>
<li>JAVA_HOME : 자바 설치 경로</li>
<li>SPARK_LOCAL_IP : 사용할 IP</li>
<li>SPARK_PUBLIC_DNS : 애플리케이션 호스트명</li>
<li>SPARK_CONF_DIR : spar-defaults.conf / spark-env.sh / log4j.properties 파일 등 설정 파일이 놓인 디렉토리 위치</li>
</ul>
<p>일부 환경 변수는 사용하는 클러스터 매니저의 종류에 따라 설정 방법이 다릅니다.</p>
<h3 id="4-3-로깅-설정"><a href="#4-3-로깅-설정" class="headerlink" title="4.3 로깅 설정"></a>4.3 로깅 설정</h3><p>스파크는 로깅 프레임워크로 log4j 를 사용합니다. 로깅 레벨을 변경하고 싶으면 스파크 홈의 conf 디렉토리 아래에 log4j.properties 파일을 생성하고 원하는 레벨로 설정하면 됩니다.</p>
<h3 id="4-4-스케쥴링"><a href="#4-4-스케쥴링" class="headerlink" title="4.4 스케쥴링"></a>4.4 스케쥴링</h3><p>하나의 애플리캐이션에 무조건 많은 CPU 와 대량의 메모리를 할당한다고 해서 원하는 속도가 나온다는 보장이 없습니다. 오히려, GC 발생과 과도한 IO, 네트워크, 프로세스 경항 등으로 인해 처리 속도가 더 나빠질 수 있습니다.</p>
<p>이번 절에서는 스파크 애플리캐이션을 수행할 때 클러스터 자원을 각 자원에 적절히 분배해서 사용하는 방법을 정리합니다.</p>
<p>하나의 클러스터에서 여러 작업이 실행되는 경우는 두 가지 입니다.</p>
<ol>
<li>서로 다른 애플리캐이션이 동일한 클러스터에서 동시에 실행</li>
<li>하나의 애플리캐이션에서 여러 스레드를 이용해 다수의 잡을 동시에 실행</li>
</ol>
<h4 id="4-4-1-애플리캐이션-간의-자원-스케쥴링"><a href="#4-4-1-애플리캐이션-간의-자원-스케쥴링" class="headerlink" title="4.4.1 애플리캐이션 간의 자원 스케쥴링"></a>4.4.1 애플리캐이션 간의 자원 스케쥴링</h4><ol>
<li><p>애플리캐이션 단위로 고정된 자원을 할당해주는 고정 자원 할당 방식</p>
<p>각 애플리케이션별마다 할당된 자원을 미리 결정한뒤 애플리케이션이 실행되는 시점부터 종료되는 시점까지 해당 자원을 계속 점유하는 사용방식입니다. </p>
<p>스파크셸 이나 spark-submit 을 이용해 애플리케이션을 실행할 때 사용할 자원 정보를 지정할 수 있습니다.</p>
<p>만약, 실행되는 애플리케이션이 짧은 시간에 집중적으로 처리를 수행하는 애플리케이션이 아닌, 스파크 셸이나 웹 기반의 애플리케이션 처럼 장시간 동작하면서 사람 혹은 외부 프로스세가 제공하는 이벤트가 있을 때만 작업을 처리하는 형태로 동작하는 애플리케이션이라면 외부로부터의 명령을 대기하는 시간 동안 자원의 낭비가 발생합니다.</p>
<p>따라서, 작업을 수행하지 않고 외부의 작업 요청을 대기하는 동안에는 해당 자원을 회수해서 자원이 부족한 다른 애플리케이션에 추가로 할당하는 것이 합리적입니다.</p>
</li>
<li><p>애플리캐이션의 실행 상황에 따라 수시로 할당량을 조정해 주는 동적 자원 할당 방식</p>
<p>스탠드얼론 모드를 제외하고는 모두 별도의 셔플 서비스를 구동시킵니다. 왜냐하면, 동적 자원 할당 모드에서는 애플리케이션이 실행되고 있는 도중에 익스큐터가 스케쥴러에 의해 삭제될 수 있기 떄문입니다.</p>
<p>아직 리듀서가 읽어가지 않은 데이터를 갖고 있던 익스큐터가 스케쥴러에 의해 삭제되면 셔플 데이터가 유실되기 때문에 익스큐터가 삭제되더라도 해당 데이터를 유지하고 처리될 수 있게 별도의 셔플 프로세스를 설정하는 것입니다.</p>
</li>
</ol>
<h4 id="4-4-2-단일-애플리캐이션-내부에서의-자원-스케쥴링"><a href="#4-4-2-단일-애플리캐이션-내부에서의-자원-스케쥴링" class="headerlink" title="4.4.2 단일 애플리캐이션 내부에서의 자원 스케쥴링"></a>4.4.2 단일 애플리캐이션 내부에서의 자원 스케쥴링</h4><p>스파크컨텍스트는 기본적으로 멀티스레드 방식을 지원합니다. 하나의 스파크컨텍스트에서 다수의 액션 연산을 동시에 실행하더라도 문제가 없습니다. 하지만, 별도의 설정이 없다면 잡의 실행은 기본적으로 FIFO 방식입니다. 문제점은 먼저 시작되는 작업이 우선권을 얻어 자원을 모두 점유한 채 실핼됭 경우, 후속 작업은 이전 작업이 모두 완료되지 전까지 대기하고 있어야한다는 점입니다.</p>
<p>스파크는 그래서 FIFO 스케쥴러와 fail-scheduler 를 선택할 수 있는 옵션을 제공합니다. </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conf.set(<span class="string">"spark.scheduler.mode"</span>, <span class="string">"FAIR"</span>)</span><br></pre></td></tr></table></figure>

<p>페어 스케쥴링 방식을 사용하면, 모듭 잡은 동일한 자원을 번갈아가며 할당받습니다. 크기가 작은 잡과 수행 시간이 오래 걸리는 잡이 섞여 있을 때 크기가 작은 잡이 크기가 큰 잡을 기다리지 않고 빠른 처리가 가능합니다. 하지만 경우에 따라서는 중요한 작업과 덜 중요한 적업을 구분해서 자원 할당의 우선순위를 조정해야 하는 경우도 있습니다.</p>
<p>그래서, Pool 이라는 개념을 도입해 풀마다 스케쥴링 방식과 우선순위, 사용 가능한 자원 할당 수준을 다르게 설정한 뒤 각 잡을 특정 풀에 할당해 풀 단위로 작업을 관리할 수 있습니다.</p>

                    
                        

                    
                    
                        <p>
                            <a href="/2019/07/01/spark-config/#post-footer" class="postShorten-excerpt_link link">
                                Comment and share
                            </a>
                        </p>
                    
                </div>
            
        </div>
        
    </article>
    
    <div class="pagination-bar">
    <ul class="pagination">
        
        
        <li class="pagination-number">page 1 of 1</li>
    </ul>
</div>

</section>



                <footer id="footer" class="main-content-wrap">
    <span class="copyrights">
        Copyrights &copy; 2020 junhee.ko. All Rights Reserved.
    </span>
</footer>

            </div>
            
        </div>
        


    
        
    

<div id="about">
    <div id="about-card">
        <div id="about-btn-close">
            <i class="fa fa-times"></i>
        </div>
        
            <img id="about-card-picture" src="/assets/images/profile.jpg" alt="Author&#39;s picture"/>
        
            <h4 id="about-card-name">junhee.ko</h4>
        
            <div id="about-card-bio"><p>Always Learning</p>
</div>
        
        
            <div id="about-card-job">
                <i class="fa fa-briefcase"></i>
                <br/>
                <p>Engineer</p>

            </div>
        
        
            <div id="about-card-location">
                <i class="fa fa-map-marker-alt"></i>
                <br/>
                Incheon
            </div>
        
    </div>
</div>

        
        
<div id="cover" style="background-image:url('/assets/images/cover.jpg');"></div>
        <!--SCRIPTS-->
<script src="/assets/js/jquery.js"></script>
<script src="/assets/js/jquery.fancybox.js"></script>
<script src="/assets/js/thumbs.js"></script>
<script src="/assets/js/tranquilpeak.js"></script>
<!--SCRIPTS END-->



    </body>
</html>
